[
    {
        "label": "runpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "runpy",
        "description": "runpy",
        "detail": "runpy",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "getenv",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "getenv",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "getenv",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "getenv",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "get_package_share_directory",
        "importPath": "ament_index_python.packages",
        "description": "ament_index_python.packages",
        "isExtraImport": true,
        "detail": "ament_index_python.packages",
        "documentation": {}
    },
    {
        "label": "launch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "launch",
        "description": "launch",
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchContext",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchContext",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "LaunchDescription",
        "importPath": "launch",
        "description": "launch",
        "isExtraImport": true,
        "detail": "launch",
        "documentation": {}
    },
    {
        "label": "launch.actions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "launch.actions",
        "description": "launch.actions",
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "DeclareLaunchArgument",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "ExecuteProcess",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "TimerAction",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "ExecuteProcess",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "TimerAction",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "ExecuteProcess",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "DeclareLaunchArgument",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "OpaqueFunction",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "LogInfo",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "DeclareLaunchArgument",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "ExecuteProcess",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "TimerAction",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "ExecuteProcess",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "IncludeLaunchDescription",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "TimerAction",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "ExecuteProcess",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "DeclareLaunchArgument",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "DeclareLaunchArgument",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "OpaqueFunction",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "LogInfo",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "DeclareLaunchArgument",
        "importPath": "launch.actions",
        "description": "launch.actions",
        "isExtraImport": true,
        "detail": "launch.actions",
        "documentation": {}
    },
    {
        "label": "LaunchConfiguration",
        "importPath": "launch.substitutions",
        "description": "launch.substitutions",
        "isExtraImport": true,
        "detail": "launch.substitutions",
        "documentation": {}
    },
    {
        "label": "LaunchConfiguration",
        "importPath": "launch.substitutions",
        "description": "launch.substitutions",
        "isExtraImport": true,
        "detail": "launch.substitutions",
        "documentation": {}
    },
    {
        "label": "LaunchConfiguration",
        "importPath": "launch.substitutions",
        "description": "launch.substitutions",
        "isExtraImport": true,
        "detail": "launch.substitutions",
        "documentation": {}
    },
    {
        "label": "EnvironmentVariable",
        "importPath": "launch.substitutions",
        "description": "launch.substitutions",
        "isExtraImport": true,
        "detail": "launch.substitutions",
        "documentation": {}
    },
    {
        "label": "LaunchConfiguration",
        "importPath": "launch.substitutions",
        "description": "launch.substitutions",
        "isExtraImport": true,
        "detail": "launch.substitutions",
        "documentation": {}
    },
    {
        "label": "EnvironmentVariable",
        "importPath": "launch.substitutions",
        "description": "launch.substitutions",
        "isExtraImport": true,
        "detail": "launch.substitutions",
        "documentation": {}
    },
    {
        "label": "launch_ros.actions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "launch_ros.actions",
        "description": "launch_ros.actions",
        "isExtraImport": true,
        "detail": "launch_ros.actions",
        "documentation": {}
    },
    {
        "label": "PythonLaunchDescriptionSource",
        "importPath": "launch.launch_description_sources",
        "description": "launch.launch_description_sources",
        "isExtraImport": true,
        "detail": "launch.launch_description_sources",
        "documentation": {}
    },
    {
        "label": "PythonLaunchDescriptionSource",
        "importPath": "launch.launch_description_sources",
        "description": "launch.launch_description_sources",
        "isExtraImport": true,
        "detail": "launch.launch_description_sources",
        "documentation": {}
    },
    {
        "label": "PythonLaunchDescriptionSource",
        "importPath": "launch.launch_description_sources",
        "description": "launch.launch_description_sources",
        "isExtraImport": true,
        "detail": "launch.launch_description_sources",
        "documentation": {}
    },
    {
        "label": "PythonLaunchDescriptionSource",
        "importPath": "launch.launch_description_sources",
        "description": "launch.launch_description_sources",
        "isExtraImport": true,
        "detail": "launch.launch_description_sources",
        "documentation": {}
    },
    {
        "label": "PythonLaunchDescriptionSource",
        "importPath": "launch.launch_description_sources",
        "description": "launch.launch_description_sources",
        "isExtraImport": true,
        "detail": "launch.launch_description_sources",
        "documentation": {}
    },
    {
        "label": "PythonLaunchDescriptionSource",
        "importPath": "launch.launch_description_sources",
        "description": "launch.launch_description_sources",
        "isExtraImport": true,
        "detail": "launch.launch_description_sources",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "interp",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "interp",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "interp",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "interp",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "interp",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pow",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "atan2",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "degrees",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "asin",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pi",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "cos",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sin",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pow",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "atan2",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "degrees",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "asin",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pi",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "cos",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sin",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pow",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "atan2",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sqrt",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "degrees",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "asin",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "pi",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "cos",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sin",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "keras",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "keras",
        "description": "keras",
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "pathlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pathlib",
        "description": "pathlib",
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "image",
        "importPath": "tensorflow.keras.preprocessing",
        "description": "tensorflow.keras.preprocessing",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing",
        "documentation": {}
    },
    {
        "label": "img_to_array",
        "importPath": "tensorflow.keras.preprocessing.image",
        "description": "tensorflow.keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "load_img",
        "importPath": "tensorflow.keras.preprocessing.image",
        "description": "tensorflow.keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "img_to_array",
        "importPath": "tensorflow.keras.preprocessing.image",
        "description": "tensorflow.keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "load_img",
        "importPath": "tensorflow.keras.preprocessing.image",
        "description": "tensorflow.keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "img_to_array",
        "importPath": "tensorflow.keras.preprocessing.image",
        "description": "tensorflow.keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "load_img",
        "importPath": "tensorflow.keras.preprocessing.image",
        "description": "tensorflow.keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "to_categorical",
        "importPath": "tensorflow.keras.utils",
        "description": "tensorflow.keras.utils",
        "isExtraImport": true,
        "detail": "tensorflow.keras.utils",
        "documentation": {}
    },
    {
        "label": "to_categorical",
        "importPath": "tensorflow.keras.utils",
        "description": "tensorflow.keras.utils",
        "isExtraImport": true,
        "detail": "tensorflow.keras.utils",
        "documentation": {}
    },
    {
        "label": "to_categorical",
        "importPath": "tensorflow.keras.utils",
        "description": "tensorflow.keras.utils",
        "isExtraImport": true,
        "detail": "tensorflow.keras.utils",
        "documentation": {}
    },
    {
        "label": "Conv2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "MaxPool2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Conv2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "MaxPool2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Conv2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "MaxPool2D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "load_model function to load trained CNN model for Sign classification",
        "importPath": "tensorflow.keras.models import load_model #",
        "description": "tensorflow.keras.models import load_model #",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models import load_model #",
        "documentation": {}
    },
    {
        "label": "timeit",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "timeit",
        "description": "timeit",
        "detail": "timeit",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "config",
        "description": "config",
        "detail": "config",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "visualkeras",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "visualkeras",
        "description": "visualkeras",
        "detail": "visualkeras",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pygame",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pygame",
        "description": "pygame",
        "detail": "pygame",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "TransformStamped",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Point",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "TransformStamped",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Quaternion",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Pose",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Point",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Twist",
        "importPath": "geometry_msgs.msg",
        "description": "geometry_msgs.msg",
        "isExtraImport": true,
        "detail": "geometry_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "Node",
        "importPath": "rclpy.node",
        "description": "rclpy.node",
        "isExtraImport": true,
        "detail": "rclpy.node",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "CvBridge",
        "importPath": "cv_bridge",
        "description": "cv_bridge",
        "isExtraImport": true,
        "detail": "cv_bridge",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Range",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Range",
        "importPath": "sensor_msgs.msg",
        "description": "sensor_msgs.msg",
        "isExtraImport": true,
        "detail": "sensor_msgs.msg",
        "documentation": {}
    },
    {
        "label": "rclpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rclpy",
        "description": "rclpy",
        "detail": "rclpy",
        "documentation": {}
    },
    {
        "label": "Odometry",
        "importPath": "nav_msgs.msg",
        "description": "nav_msgs.msg",
        "isExtraImport": true,
        "detail": "nav_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Odometry",
        "importPath": "nav_msgs.msg",
        "description": "nav_msgs.msg",
        "isExtraImport": true,
        "detail": "nav_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Odometry",
        "importPath": "nav_msgs.msg",
        "description": "nav_msgs.msg",
        "isExtraImport": true,
        "detail": "nav_msgs.msg",
        "documentation": {}
    },
    {
        "label": "count",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "count",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "count",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "FuncAnimation",
        "importPath": "matplotlib.animation",
        "description": "matplotlib.animation",
        "isExtraImport": true,
        "detail": "matplotlib.animation",
        "documentation": {}
    },
    {
        "label": "concurrent.futures",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "SpawnEntity",
        "importPath": "gazebo_msgs.srv",
        "description": "gazebo_msgs.srv",
        "isExtraImport": true,
        "detail": "gazebo_msgs.srv",
        "documentation": {}
    },
    {
        "label": "SpawnEntity",
        "importPath": "gazebo_msgs.srv",
        "description": "gazebo_msgs.srv",
        "isExtraImport": true,
        "detail": "gazebo_msgs.srv",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_copyright.main",
        "description": "ament_copyright.main",
        "isExtraImport": true,
        "detail": "ament_copyright.main",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main_with_errors",
        "importPath": "ament_flake8.main",
        "description": "ament_flake8.main",
        "isExtraImport": true,
        "detail": "ament_flake8.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "main",
        "importPath": "ament_pep257.main",
        "description": "ament_pep257.main",
        "isExtraImport": true,
        "detail": "ament_pep257.main",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "Clock",
        "importPath": "rclpy.clock",
        "description": "rclpy.clock",
        "isExtraImport": true,
        "detail": "rclpy.clock",
        "documentation": {}
    },
    {
        "label": "Clock",
        "importPath": "rclpy.clock",
        "description": "rclpy.clock",
        "isExtraImport": true,
        "detail": "rclpy.clock",
        "documentation": {}
    },
    {
        "label": "Duration",
        "importPath": "rclpy.duration",
        "description": "rclpy.duration",
        "isExtraImport": true,
        "detail": "rclpy.duration",
        "documentation": {}
    },
    {
        "label": "Duration",
        "importPath": "rclpy.duration",
        "description": "rclpy.duration",
        "isExtraImport": true,
        "detail": "rclpy.duration",
        "documentation": {}
    },
    {
        "label": "serialize_message",
        "importPath": "rclpy.serialization",
        "description": "rclpy.serialization",
        "isExtraImport": true,
        "detail": "rclpy.serialization",
        "documentation": {}
    },
    {
        "label": "serialize_message",
        "importPath": "rclpy.serialization",
        "description": "rclpy.serialization",
        "isExtraImport": true,
        "detail": "rclpy.serialization",
        "documentation": {}
    },
    {
        "label": "serialize_message",
        "importPath": "rclpy.serialization",
        "description": "rclpy.serialization",
        "isExtraImport": true,
        "detail": "rclpy.serialization",
        "documentation": {}
    },
    {
        "label": "serialize_message",
        "importPath": "rclpy.serialization",
        "description": "rclpy.serialization",
        "isExtraImport": true,
        "detail": "rclpy.serialization",
        "documentation": {}
    },
    {
        "label": "serialize_message",
        "importPath": "rclpy.serialization",
        "description": "rclpy.serialization",
        "isExtraImport": true,
        "detail": "rclpy.serialization",
        "documentation": {}
    },
    {
        "label": "serialize_message",
        "importPath": "rclpy.serialization",
        "description": "rclpy.serialization",
        "isExtraImport": true,
        "detail": "rclpy.serialization",
        "documentation": {}
    },
    {
        "label": "Int32",
        "importPath": "example_interfaces.msg",
        "description": "example_interfaces.msg",
        "isExtraImport": true,
        "detail": "example_interfaces.msg",
        "documentation": {}
    },
    {
        "label": "Int32",
        "importPath": "example_interfaces.msg",
        "description": "example_interfaces.msg",
        "isExtraImport": true,
        "detail": "example_interfaces.msg",
        "documentation": {}
    },
    {
        "label": "Int32",
        "importPath": "example_interfaces.msg",
        "description": "example_interfaces.msg",
        "isExtraImport": true,
        "detail": "example_interfaces.msg",
        "documentation": {}
    },
    {
        "label": "Int32",
        "importPath": "example_interfaces.msg",
        "description": "example_interfaces.msg",
        "isExtraImport": true,
        "detail": "example_interfaces.msg",
        "documentation": {}
    },
    {
        "label": "rosbag2_py",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rosbag2_py",
        "description": "rosbag2_py",
        "detail": "rosbag2_py",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Float32",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Float32",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Float32",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Float32",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "String",
        "importPath": "std_msgs.msg",
        "description": "std_msgs.msg",
        "isExtraImport": true,
        "detail": "std_msgs.msg",
        "documentation": {}
    },
    {
        "label": "builtins",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "builtins",
        "description": "builtins",
        "detail": "builtins",
        "documentation": {}
    },
    {
        "label": "rosidl_parser.definition",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rosidl_parser.definition",
        "description": "rosidl_parser.definition",
        "detail": "rosidl_parser.definition",
        "documentation": {}
    },
    {
        "label": "string",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "string",
        "description": "string",
        "detail": "string",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.msg",
        "description": "custom_msg_cpp.msg",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.msg",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "importPath": "custom_msg.my_custom_msg",
        "description": "custom_msg.my_custom_msg",
        "isExtraImport": true,
        "detail": "custom_msg.my_custom_msg",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.srv",
        "description": "custom_msg_cpp.srv",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.srv",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint",
        "importPath": "custom_msg_cpp.srv",
        "description": "custom_msg_cpp.srv",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.srv",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint",
        "importPath": "custom_msg_cpp.srv",
        "description": "custom_msg_cpp.srv",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.srv",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "importPath": "custom_msg_cpp.srv",
        "description": "custom_msg_cpp.srv",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.srv",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint",
        "importPath": "custom_msg_cpp.srv",
        "description": "custom_msg_cpp.srv",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.srv",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint",
        "importPath": "custom_msg_cpp.srv",
        "description": "custom_msg_cpp.srv",
        "isExtraImport": true,
        "detail": "custom_msg_cpp.srv",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "Future",
        "importPath": "rclpy.task",
        "description": "rclpy.task",
        "isExtraImport": true,
        "detail": "rclpy.task",
        "documentation": {}
    },
    {
        "label": "Future",
        "importPath": "rclpy.task",
        "description": "rclpy.task",
        "isExtraImport": true,
        "detail": "rclpy.task",
        "documentation": {}
    },
    {
        "label": "Marker",
        "importPath": "visualization_msgs.msg",
        "description": "visualization_msgs.msg",
        "isExtraImport": true,
        "detail": "visualization_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Marker",
        "importPath": "visualization_msgs.msg",
        "description": "visualization_msgs.msg",
        "isExtraImport": true,
        "detail": "visualization_msgs.msg",
        "documentation": {}
    },
    {
        "label": "MarkerArray",
        "importPath": "visualization_msgs.msg",
        "description": "visualization_msgs.msg",
        "isExtraImport": true,
        "detail": "visualization_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Marker",
        "importPath": "visualization_msgs.msg",
        "description": "visualization_msgs.msg",
        "isExtraImport": true,
        "detail": "visualization_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Marker",
        "importPath": "visualization_msgs.msg",
        "description": "visualization_msgs.msg",
        "isExtraImport": true,
        "detail": "visualization_msgs.msg",
        "documentation": {}
    },
    {
        "label": "MarkerArray",
        "importPath": "visualization_msgs.msg",
        "description": "visualization_msgs.msg",
        "isExtraImport": true,
        "detail": "visualization_msgs.msg",
        "documentation": {}
    },
    {
        "label": "Duration",
        "importPath": "builtin_interfaces.msg",
        "description": "builtin_interfaces.msg",
        "isExtraImport": true,
        "detail": "builtin_interfaces.msg",
        "documentation": {}
    },
    {
        "label": "Duration",
        "importPath": "builtin_interfaces.msg",
        "description": "builtin_interfaces.msg",
        "isExtraImport": true,
        "detail": "builtin_interfaces.msg",
        "documentation": {}
    },
    {
        "label": "StaticTransformBroadcaster",
        "importPath": "tf2_ros.static_transform_broadcaster",
        "description": "tf2_ros.static_transform_broadcaster",
        "isExtraImport": true,
        "detail": "tf2_ros.static_transform_broadcaster",
        "documentation": {}
    },
    {
        "label": "StaticTransformBroadcaster",
        "importPath": "tf2_ros.static_transform_broadcaster",
        "description": "tf2_ros.static_transform_broadcaster",
        "isExtraImport": true,
        "detail": "tf2_ros.static_transform_broadcaster",
        "documentation": {}
    },
    {
        "label": "lru_cache",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "lru_cache",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Literal",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "akshare",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "akshare",
        "description": "akshare",
        "detail": "akshare",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "ABC",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "abstractmethod",
        "importPath": "abc",
        "description": "abc",
        "isExtraImport": true,
        "detail": "abc",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "WebotsLauncher",
        "importPath": "webots_ros2_driver.webots_launcher",
        "description": "webots_ros2_driver.webots_launcher",
        "isExtraImport": true,
        "detail": "webots_ros2_driver.webots_launcher",
        "documentation": {}
    },
    {
        "label": "WebotsLauncher",
        "importPath": "webots_ros2_driver.webots_launcher",
        "description": "webots_ros2_driver.webots_launcher",
        "isExtraImport": true,
        "detail": "webots_ros2_driver.webots_launcher",
        "documentation": {}
    },
    {
        "label": "WebotsController",
        "importPath": "webots_ros2_driver.webots_controller",
        "description": "webots_ros2_driver.webots_controller",
        "isExtraImport": true,
        "detail": "webots_ros2_driver.webots_controller",
        "documentation": {}
    },
    {
        "label": "WebotsController",
        "importPath": "webots_ros2_driver.webots_controller",
        "description": "webots_ros2_driver.webots_controller",
        "isExtraImport": true,
        "detail": "webots_ros2_driver.webots_controller",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "bin_dir",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "bin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len('bin') - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = '' or os.path.basename(base)\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in '../lib/python3.12/site-packages'.split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "base = bin_dir[: -len('bin') - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = '' or os.path.basename(base)\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in '../lib/python3.12/site-packages'.split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if '' else path)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "os.environ[\"PATH\"] = os.pathsep.join([bin_dir, *os.environ.get(\"PATH\", \"\").split(os.pathsep)])\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = '' or os.path.basename(base)\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in '../lib/python3.12/site-packages'.split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if '' else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV\"]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\nos.environ[\"VIRTUAL_ENV_PROMPT\"] = '' or os.path.basename(base)\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in '../lib/python3.12/site-packages'.split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if '' else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV_PROMPT\"]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV_PROMPT\"] = '' or os.path.basename(base)\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in '../lib/python3.12/site-packages'.split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if '' else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "prev_length",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "prev_length = len(sys.path)\nfor lib in '../lib/python3.12/site-packages'.split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if '' else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.path[:]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.real_prefix",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "sys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.prefix",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "peekOfCode": "sys.prefix = base",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.ROS2SDC_VENV.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.maze_solving_world.launch",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.maze_solving_world.launch",
        "peekOfCode": "def generate_launch_description():\n  package_dir=get_package_share_directory('self_driving_car_pkg')\n  world_file = os.path.join(package_dir,'worlds','maze_solving.world')\n  return LaunchDescription([\n        ExecuteProcess(\n            cmd=['gazebo', '--verbose',world_file, '-s', 'libgazebo_ros_factory.so'],\n            output='screen'),\n        Node(\n                package='self_driving_car_pkg',\n                executable='lights_spawner_maze.bash',",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.maze_solving_world.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.record_and_drive.launch",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.record_and_drive.launch",
        "peekOfCode": "def generate_launch_description():\n  return LaunchDescription([\n        Node(\n                package='self_driving_car_pkg',\n                executable='video_recording_node',\n                name='video_recorder',\n                output='screen'),\n        Node(\n                package='teleop_twist_keyboard',\n                executable='teleop_twist_keyboard',",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.record_and_drive.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.test_laneFollow.launch",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.test_laneFollow.launch",
        "peekOfCode": "def generate_launch_description():\n    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n    pkg_share_dir = get_package_share_directory('self_driving_car_pkg')\n    model_pkg_share_dir = get_package_share_directory('self_driving_car_pkg_models')\n    models_share_dir = os.pathsep + os.path.join(model_pkg_share_dir, 'models')\n    if 'GAZEBO_MODEL_PATH' in os.environ:\n        os.environ['GAZEBO_MODEL_PATH'] += models_share_dir\n    else:\n        os.environ['GAZEBO_MODEL_PATH'] =  models_share_dir\n    print(os.environ['GAZEBO_MODEL_PATH'])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.test_laneFollow.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.world_gazebo.launch",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.world_gazebo.launch",
        "peekOfCode": "def generate_launch_description():\n    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n    pkg_share_dir = get_package_share_directory('self_driving_car_pkg')\n    model_pkg_share_dir = get_package_share_directory('self_driving_car_pkg_models')\n    models_share_dir = os.pathsep + os.path.join(model_pkg_share_dir, 'models')\n    if 'GAZEBO_MODEL_PATH' in os.environ:\n        os.environ['GAZEBO_MODEL_PATH'] += models_share_dir\n    else:\n        os.environ['GAZEBO_MODEL_PATH'] =  models_share_dir\n    print(os.environ['GAZEBO_MODEL_PATH'])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.launch.world_gazebo.launch",
        "documentation": {}
    },
    {
        "label": "OnHueLowChange",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):\n    global Sat_Low",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnLitLowChange",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):\n    global Sat_Low\n    Sat_Low = val\n    MaskExtract()\ndef OnHueLowChange_Y(val):\n    global Hue_Low_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnSatLowChange",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnSatLowChange(val):\n    global Sat_Low\n    Sat_Low = val\n    MaskExtract()\ndef OnHueLowChange_Y(val):\n    global Hue_Low_Y\n    Hue_Low_Y = val\n    MaskExtract()\ndef OnHueHighChange_Y(val):\n    global Hue_High_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnHueLowChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueLowChange_Y(val):\n    global Hue_Low_Y\n    Hue_Low_Y = val\n    MaskExtract()\ndef OnHueHighChange_Y(val):\n    global Hue_High_Y\n    Hue_High_Y = val\n    MaskExtract()\t\ndef OnLitLowChange_Y(val):\n    global Lit_Low_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnHueHighChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueHighChange_Y(val):\n    global Hue_High_Y\n    Hue_High_Y = val\n    MaskExtract()\t\ndef OnLitLowChange_Y(val):\n    global Lit_Low_Y\n    Lit_Low_Y = val\n    MaskExtract()\ndef OnSatLowChange_Y(val):\n    global Sat_Low_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnLitLowChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnLitLowChange_Y(val):\n    global Lit_Low_Y\n    Lit_Low_Y = val\n    MaskExtract()\ndef OnSatLowChange_Y(val):\n    global Sat_Low_Y\n    Sat_Low_Y = val\n    MaskExtract()\ndef MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnSatLowChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnSatLowChange_Y(val):\n    global Sat_Low_Y\n    Sat_Low_Y = val\n    MaskExtract()\ndef MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))\n    mask_Y = clr_segment(HLS,(Hue_Low_Y,Lit_Low_Y ,Sat_Low_Y),(Hue_High_Y,255,255))#Combine 6ms\n    mask_Y_ = mask_Y != 0\n    dst_Y = src * (mask_Y_[:,:,None].astype(src.dtype))\n    mask_ = mask != 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "MaskExtract",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))\n    mask_Y = clr_segment(HLS,(Hue_Low_Y,Lit_Low_Y ,Sat_Low_Y),(Hue_High_Y,255,255))#Combine 6ms\n    mask_Y_ = mask_Y != 0\n    dst_Y = src * (mask_Y_[:,:,None].astype(src.dtype))\n    mask_ = mask != 0\n    dst = src * (mask_[:,:,None].astype(src.dtype))\n    if (config.debugging_Lane and config.debugging and config.debugging_L_ColorSeg):\n        cv2.imshow('[Segment_Colour_final] mask',dst)\n        cv2.imshow('[Segment_Colour_final] mask_Y',dst_Y)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "clr_segment",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def clr_segment(HSL,lower_range,upper_range):\n    # 2. Performing Color Segmentation on Given Range\n    lower = np.array( [lower_range[0],lower_range[1] ,lower_range[2]] )\n    upper = np.array( [upper_range[0]    ,255     ,255])\n    mask = cv2.inRange(HSL, lower, upper)\n    # 3. Dilating Segmented ROI's\n    kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(3,3))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)\n    return mask\ndef LaneROI(frame,mask,minArea):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "LaneROI",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def LaneROI(frame,mask,minArea):\n    # 4a. Keeping only Midlane ROI of frame\n    frame_Lane = cv2.bitwise_and(frame,frame,mask=mask)#Extracting only RGB from a specific region\n    # 4b. Converting frame to grayscale\n    Lane_gray = cv2.cvtColor(frame_Lane,cv2.COLOR_BGR2GRAY) # Converting to grayscale\n    # 4c. Keep Only larger objects\n    Lane_gray_opened = BwareaOpen(Lane_gray,minArea) # Getting mask of only objects larger then minArea\n    Lane_gray = cv2.bitwise_and(Lane_gray,Lane_gray_opened)# Getting the gray of that mask\n    Lane_gray_Smoothed = cv2.GaussianBlur(Lane_gray,(11,11),1) # Smoothing out the edges for edge extraction later\n    # 4d. Keeping only Edges of Segmented ROI    ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OuterLaneROI",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OuterLaneROI(frame,mask,minArea):\n    Outer_Points_list=[]\n    # 5a. Extracted OuterLanes Mask And Edge\n    frame_Lane = cv2.bitwise_and(frame,frame,mask=mask)#Extracting only RGB from a specific region\n    Lane_gray = cv2.cvtColor(frame_Lane,cv2.COLOR_BGR2GRAY)# Converting to grayscale\n    Lane_gray_opened = BwareaOpen(Lane_gray,minArea) # Getting mask of only objects larger then minArea\n    Lane_gray = cv2.bitwise_and(Lane_gray,Lane_gray_opened)# Getting the gray of that mask\n    Lane_gray_Smoothed = cv2.GaussianBlur(Lane_gray,(11,11),1)# Smoothing out the edges for edge extraction later\n    Lane_edge = cv2.Canny(Lane_gray_Smoothed,50,150, None, 3) # Extracting the Edge of Canny\n    # 5b. Kept Larger OuterLane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Segment_Colour",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def Segment_Colour(frame,minArea):\n    \"\"\" Segment Lane-Lines (both outer and middle) from the road lane\n    Args:\n        frame (numpy nd array): Prius front-cam view\n        minArea (int): minimum area of an object required to be considered as a valid object\n    Returns:\n        numpy 2d array: Edges of white mid-lane\n        numpy 2d array: Mask  of white  mid-lane\n        numpy 2d array: Edges of yellow outer-lane\n        numpy 2d array: Edges of outer-lane (Seperated to get inner side later)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_Low",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_Low = 0\nLit_Low = 225\nSat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Lit_Low",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Lit_Low = 225\nSat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Sat_Low",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Sat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_Low_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_High_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Lit_Low_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Lit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Sat_Low_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Sat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Distance_",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "ApproxDistBWCntrs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])\n    cY_cmp = int(M_cmp[\"m01\"] / M_cmp[\"m00\"])\n    minDist=Distance_((cX,cY),(cX_cmp,cY_cmp))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "RetLargestContour",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def RetLargestContour(gray):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "Estimate_MidLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def Estimate_MidLane(BW,MaxDistance):\n    \"\"\"Estimate the mid-lane trajectory based on the detected midlane (patches) mask\n    Args:\n        BW (numpy_1d_array): Midlane (patches) mask extracted from the GetLaneROI()\n        MaxDistance (int): max distance for a patch to be considered part of the midlane \n                                      else it is noise\n    Returns:\n        numpy_1d_array: estimated midlane trajectory (mask)\n    \"\"\"\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "IsPathCrossingMid",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "def IsPathCrossingMid(Midlane,Mid_cnts,Outer_cnts):\n\tis_Ref_to_path_Left = 0\n\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "GetYellowInnerEdge",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "def GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:\n\t\tOuterLanes (numpy_1d_array): detected outerlane\n\t\tMidLane (numpy_1d_array): estimated midlane trajectory\n\t\tOuterLane_Points (list): points one from each side of detected outerlane\n\tReturns:\n\t\tnumpy_1d_array: outerlane (side) closest to midlane\n\t\tlist[List[tuple]]: refined contours of outerlane\n\t\tlist[List[tuple]]: refined contours of midlane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tis_Ref_to_path_Left",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tis_Ref_to_path_Left = 0\n\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tRef_To_Path_Image",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMidlane_copy",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tTraj_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tis_Ref_to_path_Left",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left\n\telse:\n\t\treturn False,is_Ref_to_path_Left\ndef GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t#Distance_And_Midlane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left\n\telse:\n\t\treturn False,is_Ref_to_path_Left\ndef GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:\n\t\tOuterLanes (numpy_1d_array): detected outerlane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOffset_correction",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOffset_correction = 0\n\t#Container for storing/returning closest Outer Lane\n\tOuter_Lanes_ret= np.zeros(OuterLanes.shape,OuterLanes.dtype)\n\t# 1. Extracting Mid and OuterLane Contours\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:\n\t\tNoOuterLane_before=False\n\t# 3. Setting the first contour of Midlane as Refrence\n\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:\n\t\tNoOuterLane_before=False\n\t# 3. Setting the first contour of Midlane as Refrence\n\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):\n\t\tRef = tuple(Mid_cnts[0][0][0])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tRef",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):\n\t\tRef = tuple(Mid_cnts[0][0][0])\n\t# 4. >>>>>>>>>>>>>> Condition 1 : if Both Midlane and Outlane is detected <<<<<<<<<<<<<\n\t# 4. [len(OuterLane_Points)==2)]\n\tif  ( Mid_cnts and (len(OuterLane_Points)==2)):\n\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tRef",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tRef = tuple(Mid_cnts[0][0][0])\n\t# 4. >>>>>>>>>>>>>> Condition 1 : if Both Midlane and Outlane is detected <<<<<<<<<<<<<\n\t# 4. [len(OuterLane_Points)==2)]\n\tif  ( Mid_cnts and (len(OuterLane_Points)==2)):\n\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tPoint_a",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tPoint_b",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tClosest_Index",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_Lanes_ret",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):\n\t\t# Discard\n\t\t#Else \n\t\t# Continue\n\t\t# 4. [len(OuterLane_Points)==2)] _ B: Find Connection between Mid And Detected OuterLane Crosses Mid\n\t\tIsPathCrossing , IsCrossingLeft = IsPathCrossingMid(MidLane,Mid_cnts,Outer_cnts_ret)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_ret",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):\n\t\t# Discard\n\t\t#Else \n\t\t# Continue\n\t\t# 4. [len(OuterLane_Points)==2)] _ B: Find Connection between Mid And Detected OuterLane Crosses Mid\n\t\tIsPathCrossing , IsCrossingLeft = IsPathCrossingMid(MidLane,Mid_cnts,Outer_cnts_ret)\n\t\tif(IsPathCrossing):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOuterLanes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOuterLanes = np.zeros_like(OuterLanes)#Empty outerLane\n\t\telse:\n\t\t\t#If no fllor crossing return results\n\t\t\treturn Outer_Lanes_ret ,Outer_cnts_ret, Mid_cnts,0\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tcv2.imshow(\"[GetYellowInnerEdge] OuterLanesaftr\",OuterLanes)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[GetYellowInnerEdge] OuterLanesaftr\")\n\t# 4. [len(OuterLane_Points)!=2)]\n\telif( Mid_cnts and np.any(OuterLanes>0) ):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOuterLanes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOuterLanes = np.zeros_like(OuterLanes)#Empty outerLane\n\t\telse:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [np.any(OuterLanes>0)] Path are not crossing --> Ret as it is\")\n\t\t\t#If no fllor crossing return results\n\t\t\treturn OuterLanes ,Outer_cnts, Mid_cnts,0\t\t\n\t# 4. >>>>>>>>>>>>>> Condition 2 : if MidLane is present but no Outlane detected >>>>>>>>>>>>>> Or Outlane got zerod because of crossings Midlane\n\t# Action: Create Outlane on Side that represent the larger Lane as seen by camera\n\tif( Mid_cnts and ( not np.any(OuterLanes>0) ) ):\t\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_highP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_low_Col",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tDrawRight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt\n\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tDrawRight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt\n\t\telse:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] IsPathCrossing = \",IsPathCrossing,\" IsCrossingLeft = \",IsCrossingLeft)\n\t\t\tif IsCrossingLeft: # trajectory from reflane to lane path is crossing midlane while moving left --> Draw Right\n\t\t\t\tDrawRight = True\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] DrawRight = \",DrawRight)\n\t\t#Offset Correction wil be set here to correct for the yellow lane not found ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tDrawRight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\t\tDrawRight = True\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] DrawRight = \",DrawRight)\n\t\t#Offset Correction wil be set here to correct for the yellow lane not found \n\t\t# IF we are drawing right then  we need to correct car to move right to find that outerlane\n\t\t# Else Move Left\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ D : Calculate Offset Correction\n\t\tif not DrawRight:\n\t\t\tlow_Col=0\n\t\t\thigh_Col=0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOffset_correction",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOffset_correction = -20\n\t\telse:\n\t\t\tlow_Col=(int(MidLane.shape[1])-1)\n\t\t\thigh_Col=(int(MidLane.shape[1])-1)\n\t\t\tOffset_correction = 20\n\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOffset_correction",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOffset_correction = 20\n\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP[1]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tLanePoint_lower",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuterLanes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "ExtendShortLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "def ExtendShortLane(MidLane,Mid_cnts,Outer_cnts,OuterLane):\n\t# 1. Sorting the Mid and Outer Contours on basis of rows (Ascending)\n\tif(Mid_cnts and Outer_cnts):\t\t\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tImage_bottom",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tLane_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tLane_Cols",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tBottomPoint_Mid",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\tMidLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tRefLane_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tRefLane_Cols",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tBottomPoint_Outer",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in\n\t\t\t#     the direction of that slope\t",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\tRefLast10Points",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in\n\t\t\t#     the direction of that slope\t\n\t\t\tif(len(RefLast10Points)>1):# Atleast 2 points needed to estimate a line\n\t\t\t\tRef_x = RefLast10Points[:,0]#cols\n\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_x",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_x = RefLast10Points[:,0]#cols\n\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_parameters",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_slope",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_yiCntercept",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_col",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_row",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_col",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_row",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_TouchPoint",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_BottomPoint_tup",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tOuterLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_TouchPoint_Ref",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")\n\treturn MidLane,OuterLane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tOuterLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")\n\treturn MidLane,OuterLane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "EstimateNonMidMask",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def EstimateNonMidMask(MidEdgeROi):\n\tMid_Hull_Mask = np.zeros((MidEdgeROi.shape[0], MidEdgeROi.shape[1], 1), dtype=np.uint8)\n\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "LanePoints",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "FetchInfoAndDisplay",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge\n\t\tMid_lane (numpy_1d_array): estimated midlane [mask]\n\t\tOuter_Lane (numpy_1d_array): detected outerlane (closest side) [mask]\n\t\tframe (numpy_3d_array): Prius front-cam view (BGR)\n\t\tOffset_correction (int): offset to apply to computed lane information [incase either\n\t\t                            midlane or outerlane was missing or removed (false-positives)]\n\tReturns:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tMid_Hull_Mask",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tMid_Hull_Mask = np.zeros((MidEdgeROi.shape[0], MidEdgeROi.shape[1], 1), dtype=np.uint8)\n\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tcontours",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\thull_list",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tcontours",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\thull",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Hull_Mask",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_highP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_highP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLanePoint_lower",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge\n\t\tMid_lane (numpy_1d_array): estimated midlane [mask]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tTraj_lowP,Traj_upP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tTraj_lowP,Traj_upP = LanePoints(Mid_lane,Outer_Lane,Offset_correction)\n    # 2. Compute Distance and Curvature from Trajectory Points \n\tPerpDist_LaneCentralStart_CarNose= -1000\n\tif(Traj_lowP!=(0,0)):\n\t\tPerpDist_LaneCentralStart_CarNose = Traj_lowP[0] - int(Mid_lane.shape[1]/2)\n\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tPerpDist_LaneCentralStart_CarNose",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tPerpDist_LaneCentralStart_CarNose = Traj_lowP[0] - int(Mid_lane.shape[1]/2)\n\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane_edge\")\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane \")\n\t\t# 3. Keep only those edge that are part of MIDLANE",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tcurvature",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane_edge\")\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane \")\n\t\t# 3. Keep only those edge that are part of MIDLANE\n\t\tMid_lane_edge = cv2.bitwise_and(Mid_lane_edge,Mid_lane)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lane_edge",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_lane_edge = cv2.bitwise_and(Mid_lane_edge,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Trash Removed (Mid_lane_edge) \",Mid_lane_edge)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Trash Removed (Mid_lane_edge) \")\n\t\t# 4. Combine Mid and OuterLane to get Lanes Combined\n\t\tLanes_combined = cv2.bitwise_or(Outer_Lane,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Lanes_combined\",Lanes_combined)\n\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLanes_combined",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLanes_combined = cv2.bitwise_or(Outer_Lane,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Lanes_combined\",Lanes_combined)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Lanes_combined\")\n\t\t#Creating an empty image\n\t\tProjectedLane = np.zeros(Lanes_combined.shape,Lanes_combined.dtype)\n\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tProjectedLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tProjectedLane = np.zeros(Lanes_combined.shape,Lanes_combined.dtype)\n\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:\n\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tcnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:\n\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")\n\t\t# 6. Extract MidlessMask from MidLaneEdge\n\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")\n\t\t# 6. Extract MidlessMask from MidLaneEdge\n\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_less_Mask \",Mid_less_Mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_less_Mask",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_less_Mask \",Mid_less_Mask)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_less_Mask \")\n\t\t# 7. Remove Midlane_Region from ProjectedLane\n\t\tProjectedLane = cv2.bitwise_and(Mid_less_Mask,ProjectedLane)\n\t\t# copy where we'll assign the new values\n\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tProjectedLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tProjectedLane = cv2.bitwise_and(Mid_less_Mask,ProjectedLane)\n\t\t# copy where we'll assign the new values\n\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane\n\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane\n\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[ProjectedLane==255]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[Outer_Lane==255]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[Mid_lane==255]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature \n\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOut_image",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature \n\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"\n\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcurvature_str=\"Curvature",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"\n\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)\n\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)\n\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\ttextSize_ratio",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "detect_Lane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Lane_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Lane_Detection",
        "peekOfCode": "def detect_Lane(img):\n        \"\"\" Extract required data from the lane lines representing road lane boundaries.\n        Args:\n                img (numpy nd array): Prius front-cam view\n        Returns:\n                distance    (int): car_front <===distance===> ideal position on road \n                curvature (angle): car <===angle===> roads_direction\n                                e.g. car approaching a right turn so road direction is around or less then 45 deg\n                                                                                cars direction is straight so it is around 90 deg\n        \"\"\"          ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Lane_Detection",
        "documentation": {}
    },
    {
        "label": "BwareaOpen",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def BwareaOpen(img,MinArea):\n    thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY)[1]\n    # Filter using contour area and remove small noise\n    cnts = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    cnts_TooSmall = []\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)\n        if area < MinArea:\n            cnts_TooSmall.append(cnt)\n    thresh = cv2.drawContours(thresh, cnts_TooSmall, -1, 0, -1) # [ contour = less then minarea contour, contourIDx, Colour , Thickness ]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "FindExtremas",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def FindExtremas(img):\n    positions = np.nonzero(img) # position[0] 0 = rows 1 = cols\n    if (len(positions)!=0):\n        top = positions[0].min()\n        bottom = positions[0].max()\n        left = positions[1].min()\n        right = positions[1].max()\n        return top,bottom\n    else:\n        return 0,0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "FindLowestRow",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def FindLowestRow(img):\n    positions = np.nonzero(img) # position[0] 0 = rows 1 = cols\n    if (len(positions)!=0):\n        top = positions[0].min()\n        bottom = positions[0].max()\n        left = positions[1].min()\n        right = positions[1].max()\n        return bottom\n    else:\n        return img.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "RetLargestContour",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def RetLargestContour(gray):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "RetLargestContour_OuterLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def RetLargestContour_OuterLane(gray,minArea):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #################################### TESTING SHADOW BREAKER CODE BY DILATING####################\n    # 3. Dilating Segmented ROI's\n    kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(5,5))\n    bin_img_dilated = cv2.morphologyEx(bin_img, cv2.MORPH_DILATE, kernel)    #Find the two Contours for which you want to find the min distance between them.\n    bin_img_ret = cv2.morphologyEx(bin_img_dilated, cv2.MORPH_ERODE, kernel)    #Find the two Contours for which you want to find the min distance between them.\n    bin_img = bin_img_ret",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ROI_extracter",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def ROI_extracter(image,strtPnt,endPnt):\n    #  Selecting Only ROI from Image\n    ROI_mask = np.zeros(image.shape, dtype=np.uint8)\n    cv2.rectangle(ROI_mask,strtPnt,endPnt,255,thickness=-1)\n    #image_ROI = cv2.bitwise_and(image,image,mask=ROI_mask)\n    image_ROI = cv2.bitwise_and(image,ROI_mask)\n    return image_ROI\ndef ExtractPoint(img,specified_row):\n    Point= (0,specified_row)\n    specified_row_data = img[ specified_row-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ExtractPoint",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def ExtractPoint(img,specified_row):\n    Point= (0,specified_row)\n    specified_row_data = img[ specified_row-1,:]\n    #print(\"specified_row_data\",specified_row_data)\n    positions = np.nonzero(specified_row_data) # position[0] 0 = rows 1 = cols\n    #print(\"positions\",positions)    \n    #print(\"len(positions[0])\",len(positions[0]))    \n    if (len(positions[0])!=0):\n        #print(positions[0])\n        min_col = positions[0].min()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Ret_LowestEdgePoints",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def Ret_LowestEdgePoints(gray):\n    Outer_Points_list=[]\n    thresh = np.zeros(gray.shape,dtype=gray.dtype)\n    Lane_OneSide=np.zeros(gray.shape,dtype=gray.dtype)\n    Lane_TwoSide=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n        #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    thresh = cv2.drawContours(thresh, cnts, 0, (255,255,255), 1) # [ contour = less then minarea contour, contourIDx, Colour , Thickness ]\n    # Boundary of the Contour is extracted and Saved in Thresh",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ApproxDistBWCntrs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])\n    cY_cmp = int(M_cmp[\"m01\"] / M_cmp[\"m00\"])\n    minDist=Distance_((cX,cY),(cX_cmp,cY_cmp))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Estimate_MidLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def Estimate_MidLane(BW,MaxDistance):\n    #cv2.namedWindow(\"BW_zero\",cv2.WINDOW_NORMAL)\n    BW_zero= cv2.cvtColor(BW,cv2.COLOR_GRAY2BGR)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts= cv2.findContours(BW, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]#3ms\n    MinArea=1\n    cnts_Legit=[]\n    for index, _ in enumerate(cnts):\n        area = cv2.contourArea(cnts[index])\n        if area > MinArea:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Distance",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def Distance(a,b):\n    a_y = a[0,0]\n    a_x = a[0,1]\n    b_y = b[0,0]\n    b_x = b[0,1]\n    distance = math.sqrt( ((a_x-b_x)**2)+((a_y-b_y)**2) )\n    return distance\ndef Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef findlaneCurvature(x1,y1,x2,y2):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "Distance_",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef findlaneCurvature(x1,y1,x2,y2):\n    offset_Vert=90# angle found by tan-1 (slop) is wrt horizontal --> This will shift to wrt Vetical\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n        anlgeOfinclination = math.atan(slope) * (180 / np.pi)#Conversion to degrees\n    else:\n        slope=1000#infinity",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "findlaneCurvature",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def findlaneCurvature(x1,y1,x2,y2):\n    offset_Vert=90# angle found by tan-1 (slop) is wrt horizontal --> This will shift to wrt Vetical\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n        anlgeOfinclination = math.atan(slope) * (180 / np.pi)#Conversion to degrees\n    else:\n        slope=1000#infinity\n        y_intercept=0#None [Line never crosses the y axis]\n        anlgeOfinclination = 90#vertical line",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "findLineParameter",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def findLineParameter(x1,y1,x2,y2):\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n    else:\n        slope=1000\n        y_intercept=0\n        #print(\"Vertical Line [Undefined slope]\")\n    return (slope,y_intercept)\ndef Cord_Sort(cnts,order):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "Cord_Sort",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def Cord_Sort(cnts,order):\n    if cnts:\n        cnt=cnts[0]\n        cnt=np.reshape(cnt,(cnt.shape[0],cnt.shape[2]))\n        order_list=[]\n        if(order==\"rows\"):\n            order_list.append((0,1))\n        else:\n            order_list.append((1,0))\n        ind = np.lexsort((cnt[:,order_list[0][0]],cnt[:,order_list[0][1]]))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "average_2b_",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def average_2b_(Edge_ROI):\n    #First Threshold data\n    TrajectoryOnEdge = np.copy(Edge_ROI)\n    row = Edge_ROI.shape[0] # Shape = [row, col, channels]\n    col = Edge_ROI.shape[1]\n    Lane_detected = np.zeros(Edge_ROI.shape,dtype = Edge_ROI.dtype)\n    Edge_Binary = Edge_ROI > 0\n    Edge_Binary_nz_pix = np.where(Edge_Binary)\n    x_len = Edge_Binary_nz_pix[0].shape[0]\n    if(Edge_Binary_nz_pix[0].shape[0]):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''\n    global NUM_CATEGORIES\n    images = list()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "train_SignsModel",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def train_SignsModel(data_dir,IMG_HEIGHT = 30,IMG_WIDTH = 30,EPOCHS = 30, save_model = True,saved_model = \"data/saved_model_Ros2_5_Sign.h5\"):\n    train_path = data_dir + '/Train_Ros2'\n    global NUM_CATEGORIES\n    # Number of Classes\n    NUM_CATEGORIES = len(os.listdir(train_path))\n    print(\"NUM_CATEGORIES = \" , NUM_CATEGORIES)\n    # Visualizing all the different Signs\n    img_dir = pathlib.Path(train_path)\n    plt.figure(figsize=(14,14))\n    index = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "EvaluateModelOnImage",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def EvaluateModelOnImage(model_path,image_path,image_label):\n    # load model\n    model = load_model(model_path)\n    # summarize model.\n    model.summary()\n    # load dataset\n    # split into input (X) and output (Y) variables\n    output = []\n    image = load_img(image_path, target_size=(30, 30))\n    output.append(np.array(image))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def main():\n    if Training_CNN:\n        train_SignsModel(\"D:/Ros2SelfDrivingCar/Ros2_SDC/data/dataset_signs\")\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "Training_CNN",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "Training_CNN = True\nNUM_CATEGORIES = 0\ndef load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "NUM_CATEGORIES",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "NUM_CATEGORIES = 0\ndef load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''\n    global NUM_CATEGORIES",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "SignTracking",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "class SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))\n    known_centers = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "image_forKeras",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n    max_rad = 150 # smaller circles dont have enough votes so only maxRadius need to be controlled ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "SignDetection",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n    max_rad = 150 # smaller circles dont have enough votes so only maxRadius need to be controlled \n                    # As signs are right besides road so they will eventually be in view so ignore circles larger than said limit\n    circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1,mindDistanBtwnCircles,param1=CannyHighthresh,param2=NumOfVotesForCircle,minRadius=10,maxRadius=max_rad)\n    if circles is not None:\n        circles = np.uint16(np.around(circles))\n        for i in circles[0,:]:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "detect_Signs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def detect_Signs(frame,frame_draw):\n    global model_loaded\n    if not model_loaded:\n        print(tf.__version__)#2.4.1\n        print(\"************ LOADING MODEL **************\")\n        global model\n        # load model\n        model = load_model(os.path.abspath('data/saved_model.h5'),compile=False)\n        # summarize model.\n        model.summary()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "detected_img",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "detected_img = 0 #Set this to current dataset images size so that new images number starts from there and dont overwrite\nif config.Detect_lane_N_Draw:\n    write_data = False\nelse:\n    write_data = True\ndraw_detected = True\ndisplay_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "draw_detected",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "draw_detected = True\ndisplay_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "display_images",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "display_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "model_loaded",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "model_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "model = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "sign_classes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "sign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "signTrack",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "signTrack = SignTracking()\ndef image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "Vis_CNN",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "peekOfCode": "def Vis_CNN(model):\n    font = ImageFont.truetype(\"arial.ttf\", 24)  # using comic sans is strictly prohibited!\n    model.add(visualkeras.SpacingDummyLayer(spacing=100))\n    visualkeras.layered_view(model, to_file='self_driving_car_pkg/self_driving_car_pkg/data/Vis_CNN.png',legend=True, font=font,scale_z=2).show()  # font is optional!\ndef main():\n    model = load_model(os.path.abspath('self_driving_car_pkg/self_driving_car_pkg/data/saved_model_5_Sign.h5'),compile=False)\n    Vis_CNN(model)\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "peekOfCode": "def main():\n    model = load_model(os.path.abspath('self_driving_car_pkg/self_driving_car_pkg/data/saved_model_5_Sign.h5'),compile=False)\n    Vis_CNN(model)\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "documentation": {}
    },
    {
        "label": "SignTracking",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "class SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))\n    known_centers = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "image_forKeras",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)\n        NumOfVotesForCircle = 32 #parameter 1 MinVotes needed to be classified as circle",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "SignDetection_Nd_Tracking",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)\n        NumOfVotesForCircle = 32 #parameter 1 MinVotes needed to be classified as circle\n        CannyHighthresh = 250 # High threshold value for applying canny\n        mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n        max_rad = 140 # smaller circles dont have enough votes so only maxRadius need to be controlled \n                        # As signs are right besides road so they will eventually be in view so ignore circles larger than said limit\n        # 4. Detection (Localization)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "detect_Signs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def detect_Signs(frame,frame_draw):\n    \"\"\"Extract required data from the traffic signs on the road\n    Args:\n        frame (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected signs\n    Returns:\n        string: Current mode of signtracker class\n        string: detected speed sign (e.g speed sign 70)\n    \"\"\"    \n    global model_loaded",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "detected_img",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "detected_img = 1000 #Set this to current dataset images size so that new images number starts from there and dont overwrite\n#if config.Detect_lane_N_Draw:\n#    write_data = False # not gathering data # No Training\n#else:\n#    write_data = True\nif config.Training_CNN:\n    write_data = True\nelse:\n    write_data = False # not gathering data # No Training\ndraw_detected = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "draw_detected",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "draw_detected = True\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "model_loaded",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "model_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "model = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "sign_classes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "sign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "signTrack",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "signTrack = SignTracking()\ndef image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "plt_bar",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def plt_bar(Categories,Data_Amount):\n    #x_pos = [i for i, _ in enumerate(Categories)]\n    plt.style.use('ggplot')\n    max_value_idx = Data_Amount.index(max(Data_Amount))\n    for i in range(len(Data_Amount)):\n        if i == max_value_idx:\n            color ='green'\n        else:\n            color ='red'\n        plt.bar(Categories[i],Data_Amount[i],0.3,color=color)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "count_files_in_dirs_n_subdirs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def count_files_in_dirs_n_subdirs(path=None, display_bar=True):\n    if path is None:\n        path= os.getcwd()\n        print(\"CWD = {} \".format(path))\n    Categories = []\n    Amount = []\n    mn = 20\n    folders = ([name for name in os.listdir(path)\n                if os.path.isdir(os.path.join(path, name))]) # get all directories \n    for folder in folders:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "generate_negative_description_file",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def generate_negative_description_file(Negative_dir):\n    # open the output file for writing. will overwrite all existing data in there\n    Neg_txt_dir=os.path.join(os.path.dirname(Negative_dir), 'neg.txt').replace(\"\\\\\",\"/\") \n    print(\"Saving Negative Images dirs to => \", Neg_txt_dir)\n    with open(Neg_txt_dir, 'w') as f:\n        # loop over all the filenames\n        for filename in os.listdir(Negative_dir):\n            f.write( Negative_dir+'/' + filename + '\\n')\ndef extract_frames_from_vid(vid_path, dest_path = None, strt_idx = None, skip_frames = 5):\n    if dest_path is None:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "extract_frames_from_vid",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def extract_frames_from_vid(vid_path, dest_path = None, strt_idx = None, skip_frames = 5):\n    if dest_path is None:\n        dest_path = os.path.join(os.path.dirname(vid_path),\"Extracted_frames\")\n        if not os.path.isdir(dest_path):\n            os.mkdir(dest_path)\n            print(\"Creating ExtractedFrame dir!!!\")\n    if strt_idx is None:\n        # Compute Strt_idx\n        strt_idx = len([name for name in os.listdir(dest_path)])\n        print(\"Computed Strt_idx = {} \".format(strt_idx))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "extract_frames_from_batch",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def extract_frames_from_batch(vids_folder=None, dest_path_ = None, skip_frames_ = 10):\n    if vids_folder is None:\n        print(\"\\nError! : No Vid directory specified \\n\\n##### [Function(Arguments)] = extract_frames_from_batch(vids_folder=None, dest_path_ = None, skip_frames_ = 10) #####\\n\")\n        return\n    vids_dir = (os.path.join(vids_folder,vid_file).replace(\"\\\\\",\"/\") for vid_file in os.listdir(vids_folder) if os.path.isfile( os.path.join(vids_folder,vid_file) ) )\n    for vid_dir in vids_dir:\n        extract_frames_from_vid(vid_dir, dest_path = dest_path_, skip_frames = skip_frames_)\ndef test_trained_cascade(test_vid_path=None,cascade_path=None):\n    if (test_vid_path and cascade_path) is None:\n        print(\"\\nError! : No test vid directory or cascade path specified \\n\\n##### [Function(Arguments)] = test_trained_cascade(test_vid_path,cascade_path) #####\\n\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "test_trained_cascade",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def test_trained_cascade(test_vid_path=None,cascade_path=None):\n    if (test_vid_path and cascade_path) is None:\n        print(\"\\nError! : No test vid directory or cascade path specified \\n\\n##### [Function(Arguments)] = test_trained_cascade(test_vid_path,cascade_path) #####\\n\")\n        return\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(cascade_path)\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):\n        print('--(!)Error loading face cascade')",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "Segment_On_Clr",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class Segment_On_Clr:\n    def __init__(self, a_1 = 56,a_2 = 66,a_3 = 41,a_4 = 23, b_1 = 0,b_2 = 8,b_3 = 33,b_4 = 23):\n        self.HLS = 0\n        self.src = 0\n        self.Hue_Low_G  = a_1\n        self.Hue_High_G = a_2\n        self.Lit_Low_G  = a_3\n        self.Sat_Low_G  = a_4\n        self.Hue_Low_R  = b_1\n        self.Hue_High_R = b_2",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_States",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class TL_States:\n    def __init__(self):\n        # Instance Variables\n        self.detected_circle = 0 \n        self.Traffic_State = \"Unknown\"\n        self.prevTraffic_State = 0\n        self.write_data = False\n        self.draw_detected = True\n        self.display_images = True\n        self.HLS = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Cascade_Detector",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class Cascade_Detector:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of Cascade_Detector class\")\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(os.getcwd(), \"self_driving_car_pkg/self_driving_car_pkg/data/TrafficLight_cascade.xml\")\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):\n        print('--(!)Error loading face cascade')",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_Tracker",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class TL_Tracker:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of signTracking class\")\n    # Class Variables\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "detect_TrafficLights",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "def detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light\n    \"\"\"    \n    Curr_TL_State = \"Unknown\"",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_States_",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "TL_States_ = TL_States()\nclass Cascade_Detector:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of Cascade_Detector class\")\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(os.getcwd(), \"self_driving_car_pkg/self_driving_car_pkg/data/TrafficLight_cascade.xml\")\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "cascade_detector",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "cascade_detector = Cascade_Detector()\nTL_Track = TL_Tracker()\nSegment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_Track",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "TL_Track = TL_Tracker()\nSegment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Segment_On_Clr_",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "Segment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light\n    \"\"\"    ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Navigator",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.Navigation",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.Navigation",
        "peekOfCode": "class Navigator():\n    def __init__(self):\n        # Creating objects for each stage of the robot navigation\n        self.bot_localizer = bot_localizer()\n        self.bot_mapper = bot_mapper()\n        self.bot_pathplanner = bot_pathplanner()\n        self.bot_motionplanner = bot_motionplanner()\n        self.debugging = Debugging()\n        # [NEW]: Boolean to determine if we are taking destination from user or not\n        self.accquiring_destination = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.Navigation",
        "documentation": {}
    },
    {
        "label": "bot_localizer",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_localization",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_localization",
        "peekOfCode": "class bot_localizer():\n    def __init__(self):\n        # State Variables\n        self.is_bg_extracted =False\n        # Output Variables [BG_model,Refrence_Maze,Rel_Loc_of_car]\n        self.bg_model = []\n        self.maze_og = []\n        self.loc_car = 0\n        # Transfomation(Crop + Rotated) Variables\n        self.orig_X = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_localization",
        "documentation": {}
    },
    {
        "label": "Graph",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "class Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0\n    # function to add new vertex to graph\n    # if neighbor == None  Just add vertex\n    #      Otherwise add connection",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "bot_mapper",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "class bot_mapper():\n    def __init__(self):\n        # State Variables\n        self.graphified = False\n        # Cropping control for removing maze boundary\n        self.crp_amt = 5\n        # Creating a graph object for storing Maze\n        self.Graph = Graph()\n        # State variables to define the connection status of each vertex\n        self.connected_left = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "draw_intrstpts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "draw_intrstpts = True\ndebug_mapping = False\n# Creating Graph Class to store IP and their connected paths\nclass Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "debug_mapping",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "debug_mapping = False\n# Creating Graph Class to store IP and their connected paths\nclass Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0\n    # function to add new vertex to graph",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "bot_motionplanner",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_motionplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_motionplanning",
        "peekOfCode": "class bot_motionplanner():\n    def __init__(self):\n        # counter to move car forward for a few iterations\n        self.count = 0\n        # State Variable => Initial Point Extracted?\n        self.pt_i_taken = False\n        # [Container] => Store Initial car location\n        self.init_loc = 0\n        # State Variable => Angle relation computed?\n        self.angle_relation_computed = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_motionplanning",
        "documentation": {}
    },
    {
        "label": "bot_pathplanner",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class bot_pathplanner():\n    def __init__(self):\n        self.DFS = DFS()\n        self.dijisktra = dijisktra()\n        self.astar = a_star()\n        self.path_to_goal = []\n        self.img_shortest_path = []\n        self.choosen_route = []\n    @staticmethod\n    def cords_to_pts(cords):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "DFS",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class DFS():\n    # A not so simple problem, \n    #    Lets try a recursive approach\n    @staticmethod\n    def get_paths(graph,start,end,path = []):\n        # Update the path to where ever you have been to\n        path = path + [start]\n        # 2) Define the simplest case\n        if (start == end):\n            return [path]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "Heap",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class Heap():\n    def __init__(self):\n        # Priority queue will be stored in an array (list of list containing vertex and their resp distance)\n        self.array = []\n        # Counter to track nodes left in priority queue\n        self.size = 0\n        # Curr_pos of each vertex is stored\n        self.posOfVertices = []\n    # create a minheap node => List(vertex,distance)\n    def new_minHeap_node(self,v,dist):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "dijisktra",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class dijisktra():\n    def __init__(self):\n        # State variable \n        self.shortestpath_found = False\n        # Once found save the shortest path\n        self.shortest_path = []\n        self.shortest_path_overlayed = []\n        # instance variable assigned obj of heap class for implementing required priority queue\n        self.minHeap = Heap()\n        # Creating dictionaries to manage the world",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "a_star",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class a_star(dijisktra):\n    def __init__(self):\n        super().__init__()\n        # Counter added to track total nodes visited to \n        #               reach goal node\n        self.astar_nodes_visited = 0\n    # Heuristic function ( One of the components required to compute total cost of any node ) \n    @staticmethod\n    def euc_d(a,b):\n        return sqrt( pow( (a[0]-b[0]),2 ) + pow( (a[1]-b[1]),2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "debug",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug = False\ndebug_localization = False\ndebug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_localization",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_localization = False\ndebug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_mapping",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_pathplanning",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_motionplanning",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_live",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_live_amount",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_map_live_amount",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_path_live_amount",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "destination",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "destination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "Debugging",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "class Debugging:\n    def __init__(self): \n       self.time_elasped = 0\n       self.Live_created = False\n    def nothing(self,x):\n        pass\n    cv2.namedWindow('CONFIG')\n    # create switch for ON/OFF functionality\n    debugging_SW = 'Debug'\n    cv2.createTrackbar(debugging_SW, 'CONFIG',False,True,nothing)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_largest_reg",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def ret_largest_reg(mask):\n    cnts = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[1]\n    max_cntr_pix = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        curr_cnt_pix = cnt.shape[0]\n        if curr_cnt_pix > max_cntr_pix:\n            max_cntr_pix = curr_cnt_pix\n            Max_Cntr_idx = index\n    largst_reg_mask = np.zeros_like(mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "disp_on_mydev",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def disp_on_mydev(screen,device=\"tablet\"):\n    resource_dir = \"self_driving_car_pkg/self_driving_car_pkg/GPS_Navigation/resource\"\n    device_path = os.path.join(resource_dir,device) + \".png\"\n    device_view = cv2.imread(device_path)\n    device_hls = cv2.cvtColor(device_view, cv2.COLOR_BGR2HLS)\n    # Case : If the screen is the middle is brighter then everything else\n    mask = cv2.inRange(device_hls, np.array([0,150,0]), np.array([255,255,255]))\n    largst_reg_cnt,largst_reg_mask = ret_largest_reg(mask)\n    [x,y,w,h] = cv2.boundingRect(largst_reg_cnt)\n    dsize = (screen.shape[1]+ (2*x), screen.shape[0]+(2*y))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "closest_node",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def closest_node(node, nodes):\n    nodes = np.asarray(nodes)\n    dist_2 = np.sum((nodes - node)**2, axis=(nodes.ndim-1))\n    return np.argmin(dist_2)\n# [NEW]: Find centroid of a contour\ndef get_centroid(cnt):\n    M = cv2.moments(cnt)\n    if M['m00']==0:\n        (cx,cy) = cv2.minEnclosingCircle(cnt)[0]        \n        return (int(cx),int(cy))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "get_centroid",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def get_centroid(cnt):\n    M = cv2.moments(cnt)\n    if M['m00']==0:\n        (cx,cy) = cv2.minEnclosingCircle(cnt)[0]        \n        return (int(cx),int(cy))\n    else:\n        cx = int(M['m10']/M['m00'])\n        cy = int(M['m01']/M['m00'])\n        return (cx,cy)\n# [NEW]: Update the destination to user selected location",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "click_event",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def click_event(event, x, y, flags, params):\n    # checking for left mouse clicks\n    if event == cv2.EVENT_LBUTTONDOWN:\n        # displaying the coordinates\n        # on the Shell\n        config.destination = (x,y)\n# [NEW]: Transform point to new Frame of Refrence [described by provided rot and translation tranformations]\ndef find_point_in_FOR(bot_cntr,transform_arr,rot_mat,cols,rows):\n        # b) Converting from point --> array to apply transforms\n        bot_cntr_arr =  np.array([bot_cntr[0],bot_cntr[1]])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "find_point_in_FOR",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def find_point_in_FOR(bot_cntr,transform_arr,rot_mat,cols,rows):\n        # b) Converting from point --> array to apply transforms\n        bot_cntr_arr =  np.array([bot_cntr[0],bot_cntr[1]])\n        # c) Shift origin from sat_view -> maze\n        bot_cntr_translated = np.zeros_like(bot_cntr_arr)\n        bot_cntr_translated[0] = bot_cntr_arr[0] - transform_arr[0]\n        bot_cntr_translated[1] = bot_cntr_arr[1] - transform_arr[1]\n        # d) Applying rotation tranformation to bot_centroid to get bot location relative to maze\n        bot_on_maze = (rot_mat @ bot_cntr_translated.T).T\n        center_ = np.array([int(cols/2),int(rows/2)])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "imfill",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def imfill(image):\n  cnts = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]# OpenCV 4.2\n  for idx,_ in enumerate(cnts):\n    cv2.drawContours(image, cnts, idx, 255,-1)\ndef ret_largest_obj(img):\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_largest_obj",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def ret_largest_obj(img):\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)\n        if area > Max_Cntr_area:\n            Max_Cntr_area = area\n            Max_Cntr_idx = index",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_smallest_obj",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def ret_smallest_obj(cnts, noise_thresh = 10):\n  Min_Cntr_area = 1000\n  Min_Cntr_idx= -1\n  for index, cnt in enumerate(cnts):\n      area = cv2.contourArea(cnt)\n      if (area < Min_Cntr_area) and (area > 10):\n          Min_Cntr_area = area\n          Min_Cntr_idx = index\n          SmallestContour_Found = True\n  print(\"min_area\" , Min_Cntr_area)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "overlay",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay(image,overlay_img):\n    gray = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n    mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n    mask_inv = cv2.bitwise_not(mask)\n    roi = image\n    img2 = overlay_img\n    # Now black-out the area of logo in ROI\n    img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n    # Take only region of logo from logo image.\n    img2_fg = cv2.bitwise_and(img2,img2,mask = mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "overlay_cropped",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay_cropped(frame_disp,image_rot,crop_loc_row,crop_loc_col,overlay_cols):\n    image_rot_cols = image_rot.shape[1]\n    gray = cv2.cvtColor(image_rot[:,image_rot_cols-overlay_cols:image_rot_cols], cv2.COLOR_BGR2GRAY)\n    mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY)[1]\n    mask_inv = cv2.bitwise_not(mask)\n    frame_overlay_cols = crop_loc_col + image_rot_cols\n    roi = frame_disp[crop_loc_row:crop_loc_row + image_rot.shape[0],frame_overlay_cols-overlay_cols:frame_overlay_cols]            \n    img2 = image_rot[:,image_rot_cols-overlay_cols:image_rot_cols]\n    # Now black-out the area of logo in ROI\n    img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "overlay_live",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay_live(frame_disp,overlay,overlay_map,overlay_path,transform_arr,crp_amt):\n    overlay_rot = cv2.rotate(overlay, cv2.ROTATE_90_CLOCKWISE)\n    map_rot = cv2.rotate(overlay_map, cv2.ROTATE_90_CLOCKWISE)\n    image_rot = cv2.rotate(overlay_path, cv2.ROTATE_90_CLOCKWISE)\n    crop_loc_col = transform_arr[0]+crp_amt\n    #crop_loc_endCol = transform_arr[0]+transform_arr[2]+crp_amt\n    crop_loc_row = transform_arr[1]+crp_amt\n    new_cols = int(overlay_rot.shape[1]*config.debug_live_amount)\n    new_path_cols = int(overlay_rot.shape[1]*config.debug_path_live_amount)\n    new_map_cols = int(overlay_rot.shape[1]*config.debug_map_live_amount)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "draw_bot_speedo",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def draw_bot_speedo(image,bot_speed,bot_turning):\n    height, width = image.shape[0:2]\n    # Ellipse parameters\n    radius = 50\n    center = (int(width / 2), height - 25)\n    axes = (radius, radius)\n    angle = 0\n    startAngle = 180\n    endAngle = 360\n    thickness = 10",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "disp_SatNav",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def disp_SatNav(frame_disp,sbot_view,bot_curr_speed,bot_curr_turning,maze_interestPts,choosen_route,img_choosen_route,transform_arr,crp_amt):\n    # View bot view on left to frame Display\n    bot_view = cv2.resize(sbot_view,None,fx=0.95,fy=0.95)\n    # Draw & Display [For better Understanding of current robot state]\n    center_frame_disp = int(frame_disp.shape[0]/2)\n    center_bot_view = int(bot_view.shape[0]/4)\n    bot_offset = frame_disp.shape[0] - bot_view.shape[0] - 25\n    center_img_shortest_path = int(img_choosen_route.shape[0]/2)\n    isp_offset = center_frame_disp - center_img_shortest_path\n    bot_view = draw_bot_speedo(bot_view,bot_curr_speed,bot_curr_turning)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "detect",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "detect = 1 # Set to 1 for Lane detection\nTesting = True# Set to True --> if want to see what the car is seeing\nProfiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Testing",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Testing = True# Set to True --> if want to see what the car is seeing\nProfiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Profiling",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Profiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "write",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "write = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "In_write",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "In_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Out_write",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Out_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_Lane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_L_ColorSeg",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_Signs",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_TrafficLights",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_TL_Config",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "enable_SatNav",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "enable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "animate_steering",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "animate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "angle_orig",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "angle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "angle",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "angle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "engines_on",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "engines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "clr_seg_dbg_created",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "clr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Detect_lane_N_Draw",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Detect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Training_CNN",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Training_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "vid_path",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "vid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Resized_width",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Resized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Resized_height",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Resized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920\nRef_imgHeight = 1080",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "in_q",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "in_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920\nRef_imgHeight = 1080\n#Ref_imgWidth = 640",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Ref_imgWidth",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Ref_imgWidth = 1920\nRef_imgHeight = 1080\n#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Ref_imgHeight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Ref_imgHeight = 1080\n#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "#Ref_imgWidth",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "#Ref_imgHeight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Frame_pixels",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Frame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Resize_Framepixels",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Resize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Lane_Extraction_minArea_per",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "Lane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "minArea_resized",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "minArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "BWContourOpen_speed_MaxDist_per",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "BWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "MaxDist_resized",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "MaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "CropHeight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "CropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "CropHeight_resized",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "peekOfCode": "CropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Debugging",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "peekOfCode": "class Debugging:\n    def __init__(self):\n        self.TL_Created = False\n        self.Lan_Created = False\n    def nothing(self,x):\n        pass\n    cv2.namedWindow('CONFIG')\n    enable_SatNav = 'Sat-Nav'\n    cv2.createTrackbar(enable_SatNav, 'CONFIG',False,True,nothing)\n    # creating (Engine) on/off trackbar",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "documentation": {}
    },
    {
        "label": "Control",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "peekOfCode": "class Control:\n    def __init__(self):\n        self.prev_Mode = \"Detection\"\n        self.prev_Mode_LT = \"Detection\"\n        self.car_speed = 80\n        self.angle_of_car = 0\n        self.Left_turn_iterations = 0\n        self.Frozen_Angle = 0\n        self.Detected_LeftTurn = False\n        self.Activat_LeftTurn = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "documentation": {}
    },
    {
        "label": "Car",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "peekOfCode": "class Car:\n    def __init__( self,Inc_TL = True, Inc_LT = True ):\n        self.Control_ = Control()\n        self.Inc_TL = Inc_TL\n        self.Inc_LT = Inc_LT\n        # [NEW]: Containers to Keep track of current state of Signs and Traffic Light detection\n        self.Tracked_class = \"Unknown\"\n        self.Traffic_State = \"Unknown\"\n    def display_state(self,frame_disp,angle_of_car,current_speed,Tracked_class,Traffic_State,Detected_LeftTurn, Activat_LeftTurn):\n        ###################################################  Displaying CONTROL STATE ####################################",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.Drive_Bot",
        "documentation": {}
    },
    {
        "label": "Video_feed_in",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.computer_vision_node",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.computer_vision_node",
        "peekOfCode": "class Video_feed_in(Node):\n    def __init__(self):\n        super().__init__('video_subscriber')\n        self.subscriber = self.create_subscription(Image,'/camera/image_raw',self.process_data,10)\n        self.publisher = self.create_publisher(Twist, '/cmd_vel', 40)\n        timer_period = 0.5;self.timer = self.create_timer(timer_period, self.send_cmd_vel)\n        self.velocity = Twist()\n        self.bridge   = CvBridge() # converting ros images to opencv data\n        self.Debug    = Debugging()\n        self.Car      = Car()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.computer_vision_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.computer_vision_node",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.computer_vision_node",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_feed_in()\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.computer_vision_node",
        "documentation": {}
    },
    {
        "label": "DriveNode",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.drive_node",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.drive_node",
        "peekOfCode": "class DriveNode(Node):\n    def __init__(self):\n        super().__init__('drive_node')\n        self.publisher_ = self.create_publisher(Twist, 'cmd_vel', 10)\n        timer_period = 0.5\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n        self.get_logger().info('Publishing: cmd_vel ')\n        self.cmd_vel_msg = Twist()\n    def timer_callback(self):\n        self.cmd_vel_msg.linear.x = 10.0;",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.drive_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.drive_node",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.drive_node",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    cmd_vel_publisher = DriveNode()\n    rclpy.spin(cmd_vel_publisher)\n    cmd_vel_publisher.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.drive_node",
        "documentation": {}
    },
    {
        "label": "Video_feed_in",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdc_V2",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdc_V2",
        "peekOfCode": "class Video_feed_in(Node):\n    def __init__(self):\n        super().__init__('video_subscriber')\n        self.subscriber = self.create_subscription(Image,'/camera/image_raw',self.process_data,10)\n        self.publisher = self.create_publisher(Twist, '/cmd_vel', 40)\n        self.velocity = Twist()\n        self.bridge   = CvBridge() # converting ros images to opencv data\n        self.Debug    = Debugging()\n        self.Car      = Car()\n        # creating object of navigator class",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdc_V2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdc_V2",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdc_V2",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_feed_in()\n  # [NEW]: Animate Steering to see how rolling average smoothes the lane assist\n  if config.animate_steering:\n    concurrent.futures.ThreadPoolExecutor().submit(image_subscriber.animate)\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdc_V2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdf_spawner",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdf_spawner",
        "peekOfCode": "def main():\n    argv = sys.argv[1:]\n    rclpy.init()\n    node = rclpy.create_node(\"Spawning_Node\")\n    client = node.create_client(SpawnEntity, \"/spawn_entity\")\n    if not client.service_is_ready():\n        client.wait_for_service()\n        node.get_logger().info(\"connected to spawner\")\n    sdf_path = argv[0]\n    request = SpawnEntity.Request()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.sdf_spawner",
        "documentation": {}
    },
    {
        "label": "Video_get",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.upper_camera_video",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.upper_camera_video",
        "peekOfCode": "class Video_get(Node):\n  def __init__(self):\n    super().__init__('video_subscriber')# node name\n    ## Created a subscriber \n    self.subscriber = self.create_subscription(Image,'/upper_camera/image_raw',self.process_data,10)\n    ## setting for writing the frames into a video\n    self.out = cv2.VideoWriter('/home/luqman/output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (1280,720))\n    self.bridge = CvBridge() # converting ros images to opencv data\n  def process_data(self, data): \n    frame = self.bridge.imgmsg_to_cv2(data,'bgr8') # performing conversion",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.upper_camera_video",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.upper_camera_video",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.upper_camera_video",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_get()\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n  main()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.upper_camera_video",
        "documentation": {}
    },
    {
        "label": "VisionSave",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.video_save",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.video_save",
        "peekOfCode": "class VisionSave(Node):\n    def __init__(self):\n        super().__init__('vision_save_node')\n        self.subscriber = self.create_subscription(Image,'/camera/image_raw',self.process_data,10)\n        self.out = cv2.VideoWriter('/home/luqman/in_new.avi',cv2.VideoWriter_fourcc('M','J','P','G'),30,(1280,720))\n        self.get_logger().info('Subscribing Image Feed and video recording')\n        self.bridge = CvBridge()\n    def process_data(self,data):\n        frame=self.bridge.imgmsg_to_cv2(data,'bgr8')\n        self.out.write(frame)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.video_save",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.video_save",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.video_save",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    vision_subcriber = VisionSave()\n    rclpy.spin(vision_subcriber)\n    vision_subcriber.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg.video_save",
        "documentation": {}
    },
    {
        "label": "OnHueLowChange",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):\n    global Sat_Low",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnLitLowChange",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):\n    global Sat_Low\n    Sat_Low = val\n    MaskExtract()\ndef OnHueLowChange_Y(val):\n    global Hue_Low_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnSatLowChange",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnSatLowChange(val):\n    global Sat_Low\n    Sat_Low = val\n    MaskExtract()\ndef OnHueLowChange_Y(val):\n    global Hue_Low_Y\n    Hue_Low_Y = val\n    MaskExtract()\ndef OnHueHighChange_Y(val):\n    global Hue_High_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnHueLowChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueLowChange_Y(val):\n    global Hue_Low_Y\n    Hue_Low_Y = val\n    MaskExtract()\ndef OnHueHighChange_Y(val):\n    global Hue_High_Y\n    Hue_High_Y = val\n    MaskExtract()\t\ndef OnLitLowChange_Y(val):\n    global Lit_Low_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnHueHighChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueHighChange_Y(val):\n    global Hue_High_Y\n    Hue_High_Y = val\n    MaskExtract()\t\ndef OnLitLowChange_Y(val):\n    global Lit_Low_Y\n    Lit_Low_Y = val\n    MaskExtract()\ndef OnSatLowChange_Y(val):\n    global Sat_Low_Y",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnLitLowChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnLitLowChange_Y(val):\n    global Lit_Low_Y\n    Lit_Low_Y = val\n    MaskExtract()\ndef OnSatLowChange_Y(val):\n    global Sat_Low_Y\n    Sat_Low_Y = val\n    MaskExtract()\ndef MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnSatLowChange_Y",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnSatLowChange_Y(val):\n    global Sat_Low_Y\n    Sat_Low_Y = val\n    MaskExtract()\ndef MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))\n    mask_Y = clr_segment(HLS,(Hue_Low_Y,Lit_Low_Y ,Sat_Low_Y),(Hue_High_Y,255,255))#Combine 6ms\n    mask_Y_ = mask_Y != 0\n    dst_Y = src * (mask_Y_[:,:,None].astype(src.dtype))\n    mask_ = mask != 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "MaskExtract",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))\n    mask_Y = clr_segment(HLS,(Hue_Low_Y,Lit_Low_Y ,Sat_Low_Y),(Hue_High_Y,255,255))#Combine 6ms\n    mask_Y_ = mask_Y != 0\n    dst_Y = src * (mask_Y_[:,:,None].astype(src.dtype))\n    mask_ = mask != 0\n    dst = src * (mask_[:,:,None].astype(src.dtype))\n    if (config.debugging_Lane and config.debugging and config.debugging_L_ColorSeg):\n        cv2.imshow('[Segment_Colour_final] mask',dst)\n        cv2.imshow('[Segment_Colour_final] mask_Y',dst_Y)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "clr_segment",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def clr_segment(HSL,lower_range,upper_range):\n    # 2. Performing Color Segmentation on Given Range\n    lower = np.array( [lower_range[0],lower_range[1] ,lower_range[2]] )\n    upper = np.array( [upper_range[0]    ,255     ,255])\n    mask = cv2.inRange(HSL, lower, upper)\n    # 3. Dilating Segmented ROI's\n    kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(3,3))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)\n    return mask\ndef LaneROI(frame,mask,minArea):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "LaneROI",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def LaneROI(frame,mask,minArea):\n    # 4a. Keeping only Midlane ROI of frame\n    frame_Lane = cv2.bitwise_and(frame,frame,mask=mask)#Extracting only RGB from a specific region\n    # 4b. Converting frame to grayscale\n    Lane_gray = cv2.cvtColor(frame_Lane,cv2.COLOR_BGR2GRAY) # Converting to grayscale\n    # 4c. Keep Only larger objects\n    Lane_gray_opened = BwareaOpen(Lane_gray,minArea) # Getting mask of only objects larger then minArea\n    Lane_gray = cv2.bitwise_and(Lane_gray,Lane_gray_opened)# Getting the gray of that mask\n    Lane_gray_Smoothed = cv2.GaussianBlur(Lane_gray,(11,11),1) # Smoothing out the edges for edge extraction later\n    # 4d. Keeping only Edges of Segmented ROI    ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OuterLaneROI",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OuterLaneROI(frame,mask,minArea):\n    Outer_Points_list=[]\n    # 5a. Extracted OuterLanes Mask And Edge\n    frame_Lane = cv2.bitwise_and(frame,frame,mask=mask)#Extracting only RGB from a specific region\n    Lane_gray = cv2.cvtColor(frame_Lane,cv2.COLOR_BGR2GRAY)# Converting to grayscale\n    Lane_gray_opened = BwareaOpen(Lane_gray,minArea) # Getting mask of only objects larger then minArea\n    Lane_gray = cv2.bitwise_and(Lane_gray,Lane_gray_opened)# Getting the gray of that mask\n    Lane_gray_Smoothed = cv2.GaussianBlur(Lane_gray,(11,11),1)# Smoothing out the edges for edge extraction later\n    Lane_edge = cv2.Canny(Lane_gray_Smoothed,50,150, None, 3) # Extracting the Edge of Canny\n    # 5b. Kept Larger OuterLane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Segment_Colour",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def Segment_Colour(frame,minArea):\n    \"\"\" Segment Lane-Lines (both outer and middle) from the road lane\n    Args:\n        frame (numpy nd array): Prius front-cam view\n        minArea (int): minimum area of an object required to be considered as a valid object\n    Returns:\n        numpy 2d array: Edges of white mid-lane\n        numpy 2d array: Mask  of white  mid-lane\n        numpy 2d array: Edges of yellow outer-lane\n        numpy 2d array: Edges of outer-lane (Seperated to get inner side later)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_Low",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_Low = 0\nLit_Low = 225\nSat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Lit_Low",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Lit_Low = 225\nSat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Sat_Low",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Sat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_Low_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_High_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Lit_Low_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Lit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Sat_Low_Y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Sat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Distance_",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "ApproxDistBWCntrs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])\n    cY_cmp = int(M_cmp[\"m01\"] / M_cmp[\"m00\"])\n    minDist=Distance_((cX,cY),(cX_cmp,cY_cmp))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "RetLargestContour",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def RetLargestContour(gray):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "Estimate_MidLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def Estimate_MidLane(BW,MaxDistance):\n    \"\"\"Estimate the mid-lane trajectory based on the detected midlane (patches) mask\n    Args:\n        BW (numpy_1d_array): Midlane (patches) mask extracted from the GetLaneROI()\n        MaxDistance (int): max distance for a patch to be considered part of the midlane \n                                      else it is noise\n    Returns:\n        numpy_1d_array: estimated midlane trajectory (mask)\n    \"\"\"\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "IsPathCrossingMid",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "def IsPathCrossingMid(Midlane,Mid_cnts,Outer_cnts):\n\tis_Ref_to_path_Left = 0\n\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "GetYellowInnerEdge",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "def GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:\n\t\tOuterLanes (numpy_1d_array): detected outerlane\n\t\tMidLane (numpy_1d_array): estimated midlane trajectory\n\t\tOuterLane_Points (list): points one from each side of detected outerlane\n\tReturns:\n\t\tnumpy_1d_array: outerlane (side) closest to midlane\n\t\tlist[List[tuple]]: refined contours of outerlane\n\t\tlist[List[tuple]]: refined contours of midlane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tis_Ref_to_path_Left",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tis_Ref_to_path_Left = 0\n\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tRef_To_Path_Image",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMidlane_copy",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tTraj_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tis_Ref_to_path_Left",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left\n\telse:\n\t\treturn False,is_Ref_to_path_Left\ndef GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t#Distance_And_Midlane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left\n\telse:\n\t\treturn False,is_Ref_to_path_Left\ndef GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:\n\t\tOuterLanes (numpy_1d_array): detected outerlane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOffset_correction",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOffset_correction = 0\n\t#Container for storing/returning closest Outer Lane\n\tOuter_Lanes_ret= np.zeros(OuterLanes.shape,OuterLanes.dtype)\n\t# 1. Extracting Mid and OuterLane Contours\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:\n\t\tNoOuterLane_before=False\n\t# 3. Setting the first contour of Midlane as Refrence\n\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:\n\t\tNoOuterLane_before=False\n\t# 3. Setting the first contour of Midlane as Refrence\n\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):\n\t\tRef = tuple(Mid_cnts[0][0][0])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tRef",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):\n\t\tRef = tuple(Mid_cnts[0][0][0])\n\t# 4. >>>>>>>>>>>>>> Condition 1 : if Both Midlane and Outlane is detected <<<<<<<<<<<<<\n\t# 4. [len(OuterLane_Points)==2)]\n\tif  ( Mid_cnts and (len(OuterLane_Points)==2)):\n\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tRef",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tRef = tuple(Mid_cnts[0][0][0])\n\t# 4. >>>>>>>>>>>>>> Condition 1 : if Both Midlane and Outlane is detected <<<<<<<<<<<<<\n\t# 4. [len(OuterLane_Points)==2)]\n\tif  ( Mid_cnts and (len(OuterLane_Points)==2)):\n\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tPoint_a",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tPoint_b",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tClosest_Index",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_Lanes_ret",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):\n\t\t# Discard\n\t\t#Else \n\t\t# Continue\n\t\t# 4. [len(OuterLane_Points)==2)] _ B: Find Connection between Mid And Detected OuterLane Crosses Mid\n\t\tIsPathCrossing , IsCrossingLeft = IsPathCrossingMid(MidLane,Mid_cnts,Outer_cnts_ret)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_ret",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):\n\t\t# Discard\n\t\t#Else \n\t\t# Continue\n\t\t# 4. [len(OuterLane_Points)==2)] _ B: Find Connection between Mid And Detected OuterLane Crosses Mid\n\t\tIsPathCrossing , IsCrossingLeft = IsPathCrossingMid(MidLane,Mid_cnts,Outer_cnts_ret)\n\t\tif(IsPathCrossing):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOuterLanes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOuterLanes = np.zeros_like(OuterLanes)#Empty outerLane\n\t\telse:\n\t\t\t#If no fllor crossing return results\n\t\t\treturn Outer_Lanes_ret ,Outer_cnts_ret, Mid_cnts,0\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tcv2.imshow(\"[GetYellowInnerEdge] OuterLanesaftr\",OuterLanes)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[GetYellowInnerEdge] OuterLanesaftr\")\n\t# 4. [len(OuterLane_Points)!=2)]\n\telif( Mid_cnts and np.any(OuterLanes>0) ):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOuterLanes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOuterLanes = np.zeros_like(OuterLanes)#Empty outerLane\n\t\telse:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [np.any(OuterLanes>0)] Path are not crossing --> Ret as it is\")\n\t\t\t#If no fllor crossing return results\n\t\t\treturn OuterLanes ,Outer_cnts, Mid_cnts,0\t\t\n\t# 4. >>>>>>>>>>>>>> Condition 2 : if MidLane is present but no Outlane detected >>>>>>>>>>>>>> Or Outlane got zerod because of crossings Midlane\n\t# Action: Create Outlane on Side that represent the larger Lane as seen by camera\n\tif( Mid_cnts and ( not np.any(OuterLanes>0) ) ):\t\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_highP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_low_Col",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tDrawRight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt\n\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tDrawRight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt\n\t\telse:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] IsPathCrossing = \",IsPathCrossing,\" IsCrossingLeft = \",IsCrossingLeft)\n\t\t\tif IsCrossingLeft: # trajectory from reflane to lane path is crossing midlane while moving left --> Draw Right\n\t\t\t\tDrawRight = True\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] DrawRight = \",DrawRight)\n\t\t#Offset Correction wil be set here to correct for the yellow lane not found ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tDrawRight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\t\tDrawRight = True\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] DrawRight = \",DrawRight)\n\t\t#Offset Correction wil be set here to correct for the yellow lane not found \n\t\t# IF we are drawing right then  we need to correct car to move right to find that outerlane\n\t\t# Else Move Left\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ D : Calculate Offset Correction\n\t\tif not DrawRight:\n\t\t\tlow_Col=0\n\t\t\thigh_Col=0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOffset_correction",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOffset_correction = -20\n\t\telse:\n\t\t\tlow_Col=(int(MidLane.shape[1])-1)\n\t\t\thigh_Col=(int(MidLane.shape[1])-1)\n\t\t\tOffset_correction = 20\n\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOffset_correction",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOffset_correction = 20\n\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP[1]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tLanePoint_lower",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuterLanes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "ExtendShortLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "def ExtendShortLane(MidLane,Mid_cnts,Outer_cnts,OuterLane):\n\t# 1. Sorting the Mid and Outer Contours on basis of rows (Ascending)\n\tif(Mid_cnts and Outer_cnts):\t\t\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tImage_bottom",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tLane_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tLane_Cols",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tBottomPoint_Mid",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\tMidLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tRefLane_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tRefLane_Cols",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tBottomPoint_Outer",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in\n\t\t\t#     the direction of that slope\t",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\tRefLast10Points",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in\n\t\t\t#     the direction of that slope\t\n\t\t\tif(len(RefLast10Points)>1):# Atleast 2 points needed to estimate a line\n\t\t\t\tRef_x = RefLast10Points[:,0]#cols\n\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_x",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_x = RefLast10Points[:,0]#cols\n\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_y",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_parameters",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_slope",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_yiCntercept",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_col",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_row",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_col",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_row",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_TouchPoint",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_BottomPoint_tup",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tOuterLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_TouchPoint_Ref",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")\n\treturn MidLane,OuterLane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tOuterLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")\n\treturn MidLane,OuterLane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "EstimateNonMidMask",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def EstimateNonMidMask(MidEdgeROi):\n\tMid_Hull_Mask = np.zeros((MidEdgeROi.shape[0], MidEdgeROi.shape[1], 1), dtype=np.uint8)\n\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "LanePoints",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "FetchInfoAndDisplay",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge\n\t\tMid_lane (numpy_1d_array): estimated midlane [mask]\n\t\tOuter_Lane (numpy_1d_array): detected outerlane (closest side) [mask]\n\t\tframe (numpy_3d_array): Prius front-cam view (BGR)\n\t\tOffset_correction (int): offset to apply to computed lane information [incase either\n\t\t                            midlane or outerlane was missing or removed (false-positives)]\n\tReturns:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tMid_Hull_Mask",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tMid_Hull_Mask = np.zeros((MidEdgeROi.shape[0], MidEdgeROi.shape[1], 1), dtype=np.uint8)\n\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tcontours",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\thull_list",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tcontours",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\thull",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Hull_Mask",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_Rows",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_highP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_lowP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_highP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLanePoint_lower",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge\n\t\tMid_lane (numpy_1d_array): estimated midlane [mask]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tTraj_lowP,Traj_upP",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tTraj_lowP,Traj_upP = LanePoints(Mid_lane,Outer_Lane,Offset_correction)\n    # 2. Compute Distance and Curvature from Trajectory Points \n\tPerpDist_LaneCentralStart_CarNose= -1000\n\tif(Traj_lowP!=(0,0)):\n\t\tPerpDist_LaneCentralStart_CarNose = Traj_lowP[0] - int(Mid_lane.shape[1]/2)\n\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tPerpDist_LaneCentralStart_CarNose",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tPerpDist_LaneCentralStart_CarNose = Traj_lowP[0] - int(Mid_lane.shape[1]/2)\n\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane_edge\")\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane \")\n\t\t# 3. Keep only those edge that are part of MIDLANE",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tcurvature",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane_edge\")\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane \")\n\t\t# 3. Keep only those edge that are part of MIDLANE\n\t\tMid_lane_edge = cv2.bitwise_and(Mid_lane_edge,Mid_lane)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lane_edge",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_lane_edge = cv2.bitwise_and(Mid_lane_edge,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Trash Removed (Mid_lane_edge) \",Mid_lane_edge)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Trash Removed (Mid_lane_edge) \")\n\t\t# 4. Combine Mid and OuterLane to get Lanes Combined\n\t\tLanes_combined = cv2.bitwise_or(Outer_Lane,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Lanes_combined\",Lanes_combined)\n\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLanes_combined",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLanes_combined = cv2.bitwise_or(Outer_Lane,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Lanes_combined\",Lanes_combined)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Lanes_combined\")\n\t\t#Creating an empty image\n\t\tProjectedLane = np.zeros(Lanes_combined.shape,Lanes_combined.dtype)\n\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tProjectedLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tProjectedLane = np.zeros(Lanes_combined.shape,Lanes_combined.dtype)\n\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:\n\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tcnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:\n\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")\n\t\t# 6. Extract MidlessMask from MidLaneEdge\n\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcnts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")\n\t\t# 6. Extract MidlessMask from MidLaneEdge\n\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_less_Mask \",Mid_less_Mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_less_Mask",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_less_Mask \",Mid_less_Mask)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_less_Mask \")\n\t\t# 7. Remove Midlane_Region from ProjectedLane\n\t\tProjectedLane = cv2.bitwise_and(Mid_less_Mask,ProjectedLane)\n\t\t# copy where we'll assign the new values\n\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tProjectedLane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tProjectedLane = cv2.bitwise_and(Mid_less_Mask,ProjectedLane)\n\t\t# copy where we'll assign the new values\n\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane\n\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane\n\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[ProjectedLane==255]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[Outer_Lane==255]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[Mid_lane==255]",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature \n\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOut_image",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature \n\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"\n\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcurvature_str=\"Curvature",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"\n\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)\n\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)\n\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\ttextSize_ratio",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "detect_Lane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Lane_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Lane_Detection",
        "peekOfCode": "def detect_Lane(img):\n        \"\"\" Extract required data from the lane lines representing road lane boundaries.\n        Args:\n                img (numpy nd array): Prius front-cam view\n        Returns:\n                distance    (int): car_front <===distance===> ideal position on road \n                curvature (angle): car <===angle===> roads_direction\n                                e.g. car approaching a right turn so road direction is around or less then 45 deg\n                                                                                cars direction is straight so it is around 90 deg\n        \"\"\"          ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Lane_Detection",
        "documentation": {}
    },
    {
        "label": "BwareaOpen",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def BwareaOpen(img,MinArea):\n    thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY)[1]\n    # Filter using contour area and remove small noise\n    cnts = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    cnts_TooSmall = []\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)\n        if area < MinArea:\n            cnts_TooSmall.append(cnt)\n    thresh = cv2.drawContours(thresh, cnts_TooSmall, -1, 0, -1) # [ contour = less then minarea contour, contourIDx, Colour , Thickness ]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "FindExtremas",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def FindExtremas(img):\n    positions = np.nonzero(img) # position[0] 0 = rows 1 = cols\n    if (len(positions)!=0):\n        top = positions[0].min()\n        bottom = positions[0].max()\n        left = positions[1].min()\n        right = positions[1].max()\n        return top,bottom\n    else:\n        return 0,0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "FindLowestRow",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def FindLowestRow(img):\n    positions = np.nonzero(img) # position[0] 0 = rows 1 = cols\n    if (len(positions)!=0):\n        top = positions[0].min()\n        bottom = positions[0].max()\n        left = positions[1].min()\n        right = positions[1].max()\n        return bottom\n    else:\n        return img.shape[0]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "RetLargestContour",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def RetLargestContour(gray):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "RetLargestContour_OuterLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def RetLargestContour_OuterLane(gray,minArea):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #################################### TESTING SHADOW BREAKER CODE BY DILATING####################\n    # 3. Dilating Segmented ROI's\n    kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(5,5))\n    bin_img_dilated = cv2.morphologyEx(bin_img, cv2.MORPH_DILATE, kernel)    #Find the two Contours for which you want to find the min distance between them.\n    bin_img_ret = cv2.morphologyEx(bin_img_dilated, cv2.MORPH_ERODE, kernel)    #Find the two Contours for which you want to find the min distance between them.\n    bin_img = bin_img_ret",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ROI_extracter",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def ROI_extracter(image,strtPnt,endPnt):\n    #  Selecting Only ROI from Image\n    ROI_mask = np.zeros(image.shape, dtype=np.uint8)\n    cv2.rectangle(ROI_mask,strtPnt,endPnt,255,thickness=-1)\n    #image_ROI = cv2.bitwise_and(image,image,mask=ROI_mask)\n    image_ROI = cv2.bitwise_and(image,ROI_mask)\n    return image_ROI\ndef ExtractPoint(img,specified_row):\n    Point= (0,specified_row)\n    specified_row_data = img[ specified_row-1,:]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ExtractPoint",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def ExtractPoint(img,specified_row):\n    Point= (0,specified_row)\n    specified_row_data = img[ specified_row-1,:]\n    #print(\"specified_row_data\",specified_row_data)\n    positions = np.nonzero(specified_row_data) # position[0] 0 = rows 1 = cols\n    #print(\"positions\",positions)    \n    #print(\"len(positions[0])\",len(positions[0]))    \n    if (len(positions[0])!=0):\n        #print(positions[0])\n        min_col = positions[0].min()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Ret_LowestEdgePoints",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def Ret_LowestEdgePoints(gray):\n    Outer_Points_list=[]\n    thresh = np.zeros(gray.shape,dtype=gray.dtype)\n    Lane_OneSide=np.zeros(gray.shape,dtype=gray.dtype)\n    Lane_TwoSide=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n        #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    thresh = cv2.drawContours(thresh, cnts, 0, (255,255,255), 1) # [ contour = less then minarea contour, contourIDx, Colour , Thickness ]\n    # Boundary of the Contour is extracted and Saved in Thresh",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ApproxDistBWCntrs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])\n    cY_cmp = int(M_cmp[\"m01\"] / M_cmp[\"m00\"])\n    minDist=Distance_((cX,cY),(cX_cmp,cY_cmp))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Estimate_MidLane",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "peekOfCode": "def Estimate_MidLane(BW,MaxDistance):\n    #cv2.namedWindow(\"BW_zero\",cv2.WINDOW_NORMAL)\n    BW_zero= cv2.cvtColor(BW,cv2.COLOR_GRAY2BGR)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts= cv2.findContours(BW, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]#3ms\n    MinArea=1\n    cnts_Legit=[]\n    for index, _ in enumerate(cnts):\n        area = cv2.contourArea(cnts[index])\n        if area > MinArea:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Distance",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "peekOfCode": "def Distance(a,b):\n    a_y = a[0,0]\n    a_x = a[0,1]\n    b_y = b[0,0]\n    b_x = b[0,1]\n    distance = math.sqrt( ((a_x-b_x)**2)+((a_y-b_y)**2) )\n    return distance\ndef Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef findlaneCurvature(x1,y1,x2,y2):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "Distance_",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "peekOfCode": "def Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef findlaneCurvature(x1,y1,x2,y2):\n    offset_Vert=90# angle found by tan-1 (slop) is wrt horizontal --> This will shift to wrt Vetical\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n        anlgeOfinclination = math.atan(slope) * (180 / np.pi)#Conversion to degrees\n    else:\n        slope=1000#infinity",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "findlaneCurvature",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "peekOfCode": "def findlaneCurvature(x1,y1,x2,y2):\n    offset_Vert=90# angle found by tan-1 (slop) is wrt horizontal --> This will shift to wrt Vetical\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n        anlgeOfinclination = math.atan(slope) * (180 / np.pi)#Conversion to degrees\n    else:\n        slope=1000#infinity\n        y_intercept=0#None [Line never crosses the y axis]\n        anlgeOfinclination = 90#vertical line",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "findLineParameter",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "peekOfCode": "def findLineParameter(x1,y1,x2,y2):\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n    else:\n        slope=1000\n        y_intercept=0\n        #print(\"Vertical Line [Undefined slope]\")\n    return (slope,y_intercept)\ndef Cord_Sort(cnts,order):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "Cord_Sort",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "peekOfCode": "def Cord_Sort(cnts,order):\n    if cnts:\n        cnt=cnts[0]\n        cnt=np.reshape(cnt,(cnt.shape[0],cnt.shape[2]))\n        order_list=[]\n        if(order==\"rows\"):\n            order_list.append((0,1))\n        else:\n            order_list.append((1,0))\n        ind = np.lexsort((cnt[:,order_list[0][0]],cnt[:,order_list[0][1]]))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "average_2b_",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "peekOfCode": "def average_2b_(Edge_ROI):\n    #First Threshold data\n    TrajectoryOnEdge = np.copy(Edge_ROI)\n    row = Edge_ROI.shape[0] # Shape = [row, col, channels]\n    col = Edge_ROI.shape[1]\n    Lane_detected = np.zeros(Edge_ROI.shape,dtype = Edge_ROI.dtype)\n    Edge_Binary = Edge_ROI > 0\n    Edge_Binary_nz_pix = np.where(Edge_Binary)\n    x_len = Edge_Binary_nz_pix[0].shape[0]\n    if(Edge_Binary_nz_pix[0].shape[0]):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "peekOfCode": "def load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''\n    global NUM_CATEGORIES\n    images = list()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "train_SignsModel",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "peekOfCode": "def train_SignsModel(data_dir,IMG_HEIGHT = 30,IMG_WIDTH = 30,EPOCHS = 30, save_model = True,saved_model = \"data/saved_model_Ros2_5_Sign.h5\"):\n    train_path = data_dir + '/Train_Ros2'\n    global NUM_CATEGORIES\n    # Number of Classes\n    NUM_CATEGORIES = len(os.listdir(train_path))\n    print(\"NUM_CATEGORIES = \" , NUM_CATEGORIES)\n    # Visualizing all the different Signs\n    img_dir = pathlib.Path(train_path)\n    plt.figure(figsize=(14,14))\n    index = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "EvaluateModelOnImage",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "peekOfCode": "def EvaluateModelOnImage(model_path,image_path,image_label):\n    # load model\n    model = load_model(model_path)\n    # summarize model.\n    model.summary()\n    # load dataset\n    # split into input (X) and output (Y) variables\n    output = []\n    image = load_img(image_path, target_size=(30, 30))\n    output.append(np.array(image))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "peekOfCode": "def main():\n    if Training_CNN:\n        train_SignsModel(\"D:/Ros2SelfDrivingCar/Ros2_SDC/data/dataset_signs\")\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "Training_CNN",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "peekOfCode": "Training_CNN = True\nNUM_CATEGORIES = 0\ndef load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "NUM_CATEGORIES",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "peekOfCode": "NUM_CATEGORIES = 0\ndef load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''\n    global NUM_CATEGORIES",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "SignTracking",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "class SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))\n    known_centers = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "image_forKeras",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n    max_rad = 150 # smaller circles dont have enough votes so only maxRadius need to be controlled ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "SignDetection",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n    max_rad = 150 # smaller circles dont have enough votes so only maxRadius need to be controlled \n                    # As signs are right besides road so they will eventually be in view so ignore circles larger than said limit\n    circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1,mindDistanBtwnCircles,param1=CannyHighthresh,param2=NumOfVotesForCircle,minRadius=10,maxRadius=max_rad)\n    if circles is not None:\n        circles = np.uint16(np.around(circles))\n        for i in circles[0,:]:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "detect_Signs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def detect_Signs(frame,frame_draw):\n    global model_loaded\n    if not model_loaded:\n        print(tf.__version__)#2.4.1\n        print(\"************ LOADING MODEL **************\")\n        global model\n        # load model\n        model = load_model(os.path.abspath('data/saved_model.h5'),compile=False)\n        # summarize model.\n        model.summary()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "detected_img",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "detected_img = 0 #Set this to current dataset images size so that new images number starts from there and dont overwrite\nif config.Detect_lane_N_Draw:\n    write_data = False\nelse:\n    write_data = True\ndraw_detected = True\ndisplay_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "draw_detected",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "draw_detected = True\ndisplay_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "display_images",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "display_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "model_loaded",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "model_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "model = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "sign_classes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "sign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "signTrack",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "signTrack = SignTracking()\ndef image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "Vis_CNN",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Visualize_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Visualize_CNN",
        "peekOfCode": "def Vis_CNN(model):\n    font = ImageFont.truetype(\"arial.ttf\", 24)  # using comic sans is strictly prohibited!\n    model.add(visualkeras.SpacingDummyLayer(spacing=100))\n    visualkeras.layered_view(model, to_file='self_driving_car_pkg/self_driving_car_pkg/data/Vis_CNN.png',legend=True, font=font,scale_z=2).show()  # font is optional!\ndef main():\n    model = load_model(os.path.abspath('self_driving_car_pkg/self_driving_car_pkg/data/saved_model_5_Sign.h5'),compile=False)\n    Vis_CNN(model)\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Visualize_CNN",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Visualize_CNN",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Visualize_CNN",
        "peekOfCode": "def main():\n    model = load_model(os.path.abspath('self_driving_car_pkg/self_driving_car_pkg/data/saved_model_5_Sign.h5'),compile=False)\n    Vis_CNN(model)\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.Classification.Visualize_CNN",
        "documentation": {}
    },
    {
        "label": "SignTracking",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "class SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))\n    known_centers = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "image_forKeras",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)\n        NumOfVotesForCircle = 32 #parameter 1 MinVotes needed to be classified as circle",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "SignDetection_Nd_Tracking",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)\n        NumOfVotesForCircle = 32 #parameter 1 MinVotes needed to be classified as circle\n        CannyHighthresh = 250 # High threshold value for applying canny\n        mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n        max_rad = 140 # smaller circles dont have enough votes so only maxRadius need to be controlled \n                        # As signs are right besides road so they will eventually be in view so ignore circles larger than said limit\n        # 4. Detection (Localization)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "detect_Signs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def detect_Signs(frame,frame_draw):\n    \"\"\"Extract required data from the traffic signs on the road\n    Args:\n        frame (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected signs\n    Returns:\n        string: Current mode of signtracker class\n        string: detected speed sign (e.g speed sign 70)\n    \"\"\"    \n    global model_loaded",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "detected_img",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "detected_img = 1000 #Set this to current dataset images size so that new images number starts from there and dont overwrite\n#if config.Detect_lane_N_Draw:\n#    write_data = False # not gathering data # No Training\n#else:\n#    write_data = True\nif config.Training_CNN:\n    write_data = True\nelse:\n    write_data = False # not gathering data # No Training\ndraw_detected = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "draw_detected",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "draw_detected = True\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "model_loaded",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "model_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "model = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "sign_classes",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "sign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "signTrack",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "peekOfCode": "signTrack = SignTracking()\ndef image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "plt_bar",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def plt_bar(Categories,Data_Amount):\n    #x_pos = [i for i, _ in enumerate(Categories)]\n    plt.style.use('ggplot')\n    max_value_idx = Data_Amount.index(max(Data_Amount))\n    for i in range(len(Data_Amount)):\n        if i == max_value_idx:\n            color ='green'\n        else:\n            color ='red'\n        plt.bar(Categories[i],Data_Amount[i],0.3,color=color)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "count_files_in_dirs_n_subdirs",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def count_files_in_dirs_n_subdirs(path=None, display_bar=True):\n    if path is None:\n        path= os.getcwd()\n        print(\"CWD = {} \".format(path))\n    Categories = []\n    Amount = []\n    mn = 20\n    folders = ([name for name in os.listdir(path)\n                if os.path.isdir(os.path.join(path, name))]) # get all directories \n    for folder in folders:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "generate_negative_description_file",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def generate_negative_description_file(Negative_dir):\n    # open the output file for writing. will overwrite all existing data in there\n    Neg_txt_dir=os.path.join(os.path.dirname(Negative_dir), 'neg.txt').replace(\"\\\\\",\"/\") \n    print(\"Saving Negative Images dirs to => \", Neg_txt_dir)\n    with open(Neg_txt_dir, 'w') as f:\n        # loop over all the filenames\n        for filename in os.listdir(Negative_dir):\n            f.write( Negative_dir+'/' + filename + '\\n')\ndef extract_frames_from_vid(vid_path, dest_path = None, strt_idx = None, skip_frames = 5):\n    if dest_path is None:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "extract_frames_from_vid",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def extract_frames_from_vid(vid_path, dest_path = None, strt_idx = None, skip_frames = 5):\n    if dest_path is None:\n        dest_path = os.path.join(os.path.dirname(vid_path),\"Extracted_frames\")\n        if not os.path.isdir(dest_path):\n            os.mkdir(dest_path)\n            print(\"Creating ExtractedFrame dir!!!\")\n    if strt_idx is None:\n        # Compute Strt_idx\n        strt_idx = len([name for name in os.listdir(dest_path)])\n        print(\"Computed Strt_idx = {} \".format(strt_idx))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "extract_frames_from_batch",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def extract_frames_from_batch(vids_folder=None, dest_path_ = None, skip_frames_ = 10):\n    if vids_folder is None:\n        print(\"\\nError! : No Vid directory specified \\n\\n##### [Function(Arguments)] = extract_frames_from_batch(vids_folder=None, dest_path_ = None, skip_frames_ = 10) #####\\n\")\n        return\n    vids_dir = (os.path.join(vids_folder,vid_file).replace(\"\\\\\",\"/\") for vid_file in os.listdir(vids_folder) if os.path.isfile( os.path.join(vids_folder,vid_file) ) )\n    for vid_dir in vids_dir:\n        extract_frames_from_vid(vid_dir, dest_path = dest_path_, skip_frames = skip_frames_)\ndef test_trained_cascade(test_vid_path=None,cascade_path=None):\n    if (test_vid_path and cascade_path) is None:\n        print(\"\\nError! : No test vid directory or cascade path specified \\n\\n##### [Function(Arguments)] = test_trained_cascade(test_vid_path,cascade_path) #####\\n\")",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "test_trained_cascade",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "peekOfCode": "def test_trained_cascade(test_vid_path=None,cascade_path=None):\n    if (test_vid_path and cascade_path) is None:\n        print(\"\\nError! : No test vid directory or cascade path specified \\n\\n##### [Function(Arguments)] = test_trained_cascade(test_vid_path,cascade_path) #####\\n\")\n        return\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(cascade_path)\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):\n        print('--(!)Error loading face cascade')",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.HaarCascade.Training.utils",
        "documentation": {}
    },
    {
        "label": "Segment_On_Clr",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class Segment_On_Clr:\n    def __init__(self, a_1 = 56,a_2 = 66,a_3 = 41,a_4 = 23, b_1 = 0,b_2 = 8,b_3 = 33,b_4 = 23):\n        self.HLS = 0\n        self.src = 0\n        self.Hue_Low_G  = a_1\n        self.Hue_High_G = a_2\n        self.Lit_Low_G  = a_3\n        self.Sat_Low_G  = a_4\n        self.Hue_Low_R  = b_1\n        self.Hue_High_R = b_2",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_States",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class TL_States:\n    def __init__(self):\n        # Instance Variables\n        self.detected_circle = 0 \n        self.Traffic_State = \"Unknown\"\n        self.prevTraffic_State = 0\n        self.write_data = False\n        self.draw_detected = True\n        self.display_images = True\n        self.HLS = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Cascade_Detector",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class Cascade_Detector:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of Cascade_Detector class\")\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(os.getcwd(), \"self_driving_car_pkg/self_driving_car_pkg/data/TrafficLight_cascade.xml\")\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):\n        print('--(!)Error loading face cascade')",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_Tracker",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class TL_Tracker:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of signTracking class\")\n    # Class Variables\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "detect_TrafficLights",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "def detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light\n    \"\"\"    \n    Curr_TL_State = \"Unknown\"",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_States_",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "TL_States_ = TL_States()\nclass Cascade_Detector:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of Cascade_Detector class\")\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(os.getcwd(), \"self_driving_car_pkg/self_driving_car_pkg/data/TrafficLight_cascade.xml\")\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "cascade_detector",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "cascade_detector = Cascade_Detector()\nTL_Track = TL_Tracker()\nSegment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_Track",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "TL_Track = TL_Tracker()\nSegment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Segment_On_Clr_",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "Segment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light\n    \"\"\"    ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Navigator",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.Navigation",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.Navigation",
        "peekOfCode": "class Navigator():\n    def __init__(self):\n        # Creating objects for each stage of the robot navigation\n        self.bot_localizer = bot_localizer()\n        self.bot_mapper = bot_mapper()\n        self.bot_pathplanner = bot_pathplanner()\n        self.bot_motionplanner = bot_motionplanner()\n        self.debugging = Debugging()\n        # [NEW]: Boolean to determine if we are taking destination from user or not\n        self.accquiring_destination = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.Navigation",
        "documentation": {}
    },
    {
        "label": "bot_localizer",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_localization",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_localization",
        "peekOfCode": "class bot_localizer():\n    def __init__(self):\n        # State Variables\n        self.is_bg_extracted =False\n        # Output Variables [BG_model,Refrence_Maze,Rel_Loc_of_car]\n        self.bg_model = []\n        self.maze_og = []\n        self.loc_car = 0\n        # Transfomation(Crop + Rotated) Variables\n        self.orig_X = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_localization",
        "documentation": {}
    },
    {
        "label": "Graph",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "peekOfCode": "class Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0\n    # function to add new vertex to graph\n    # if neighbor == None  Just add vertex\n    #      Otherwise add connection",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "bot_mapper",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "peekOfCode": "class bot_mapper():\n    def __init__(self):\n        # State Variables\n        self.graphified = False\n        # Cropping control for removing maze boundary\n        self.crp_amt = 5\n        # Creating a graph object for storing Maze\n        self.Graph = Graph()\n        # State variables to define the connection status of each vertex\n        self.connected_left = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "draw_intrstpts",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "peekOfCode": "draw_intrstpts = True\ndebug_mapping = False\n# Creating Graph Class to store IP and their connected paths\nclass Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "debug_mapping",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "peekOfCode": "debug_mapping = False\n# Creating Graph Class to store IP and their connected paths\nclass Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0\n    # function to add new vertex to graph",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "bot_motionplanner",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_motionplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_motionplanning",
        "peekOfCode": "class bot_motionplanner():\n    def __init__(self):\n        # counter to move car forward for a few iterations\n        self.count = 0\n        # State Variable => Initial Point Extracted?\n        self.pt_i_taken = False\n        # [Container] => Store Initial car location\n        self.init_loc = 0\n        # State Variable => Angle relation computed?\n        self.angle_relation_computed = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_motionplanning",
        "documentation": {}
    },
    {
        "label": "bot_pathplanner",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class bot_pathplanner():\n    def __init__(self):\n        self.DFS = DFS()\n        self.dijisktra = dijisktra()\n        self.astar = a_star()\n        self.path_to_goal = []\n        self.img_shortest_path = []\n        self.choosen_route = []\n    @staticmethod\n    def cords_to_pts(cords):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "DFS",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class DFS():\n    # A not so simple problem, \n    #    Lets try a recursive approach\n    @staticmethod\n    def get_paths(graph,start,end,path = []):\n        # Update the path to where ever you have been to\n        path = path + [start]\n        # 2) Define the simplest case\n        if (start == end):\n            return [path]",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "Heap",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class Heap():\n    def __init__(self):\n        # Priority queue will be stored in an array (list of list containing vertex and their resp distance)\n        self.array = []\n        # Counter to track nodes left in priority queue\n        self.size = 0\n        # Curr_pos of each vertex is stored\n        self.posOfVertices = []\n    # create a minheap node => List(vertex,distance)\n    def new_minHeap_node(self,v,dist):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "dijisktra",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class dijisktra():\n    def __init__(self):\n        # State variable \n        self.shortestpath_found = False\n        # Once found save the shortest path\n        self.shortest_path = []\n        self.shortest_path_overlayed = []\n        # instance variable assigned obj of heap class for implementing required priority queue\n        self.minHeap = Heap()\n        # Creating dictionaries to manage the world",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "a_star",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class a_star(dijisktra):\n    def __init__(self):\n        super().__init__()\n        # Counter added to track total nodes visited to \n        #               reach goal node\n        self.astar_nodes_visited = 0\n    # Heuristic function ( One of the components required to compute total cost of any node ) \n    @staticmethod\n    def euc_d(a,b):\n        return sqrt( pow( (a[0]-b[0]),2 ) + pow( (a[1]-b[1]),2 ) )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "debug",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug = False\ndebug_localization = False\ndebug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_localization",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_localization = False\ndebug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_mapping",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_pathplanning",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_motionplanning",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_live",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_live_amount",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_map_live_amount",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_path_live_amount",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "debug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "destination",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "peekOfCode": "destination = []",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "Debugging",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "class Debugging:\n    def __init__(self): \n       self.time_elasped = 0\n       self.Live_created = False\n    def nothing(self,x):\n        pass\n    cv2.namedWindow('CONFIG')\n    # create switch for ON/OFF functionality\n    debugging_SW = 'Debug'\n    cv2.createTrackbar(debugging_SW, 'CONFIG',False,True,nothing)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_largest_reg",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def ret_largest_reg(mask):\n    cnts = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[1]\n    max_cntr_pix = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        curr_cnt_pix = cnt.shape[0]\n        if curr_cnt_pix > max_cntr_pix:\n            max_cntr_pix = curr_cnt_pix\n            Max_Cntr_idx = index\n    largst_reg_mask = np.zeros_like(mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "disp_on_mydev",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def disp_on_mydev(screen,device=\"tablet\"):\n    resource_dir = \"self_driving_car_pkg/self_driving_car_pkg/GPS_Navigation/resource\"\n    device_path = os.path.join(resource_dir,device) + \".png\"\n    device_view = cv2.imread(device_path)\n    device_hls = cv2.cvtColor(device_view, cv2.COLOR_BGR2HLS)\n    # Case : If the screen is the middle is brighter then everything else\n    mask = cv2.inRange(device_hls, np.array([0,150,0]), np.array([255,255,255]))\n    largst_reg_cnt,largst_reg_mask = ret_largest_reg(mask)\n    [x,y,w,h] = cv2.boundingRect(largst_reg_cnt)\n    dsize = (screen.shape[1]+ (2*x), screen.shape[0]+(2*y))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "closest_node",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def closest_node(node, nodes):\n    nodes = np.asarray(nodes)\n    dist_2 = np.sum((nodes - node)**2, axis=(nodes.ndim-1))\n    return np.argmin(dist_2)\n# [NEW]: Find centroid of a contour\ndef get_centroid(cnt):\n    M = cv2.moments(cnt)\n    if M['m00']==0:\n        (cx,cy) = cv2.minEnclosingCircle(cnt)[0]        \n        return (int(cx),int(cy))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "get_centroid",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def get_centroid(cnt):\n    M = cv2.moments(cnt)\n    if M['m00']==0:\n        (cx,cy) = cv2.minEnclosingCircle(cnt)[0]        \n        return (int(cx),int(cy))\n    else:\n        cx = int(M['m10']/M['m00'])\n        cy = int(M['m01']/M['m00'])\n        return (cx,cy)\n# [NEW]: Update the destination to user selected location",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "click_event",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def click_event(event, x, y, flags, params):\n    # checking for left mouse clicks\n    if event == cv2.EVENT_LBUTTONDOWN:\n        # displaying the coordinates\n        # on the Shell\n        config.destination = (x,y)\n# [NEW]: Transform point to new Frame of Refrence [described by provided rot and translation tranformations]\ndef find_point_in_FOR(bot_cntr,transform_arr,rot_mat,cols,rows):\n        # b) Converting from point --> array to apply transforms\n        bot_cntr_arr =  np.array([bot_cntr[0],bot_cntr[1]])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "find_point_in_FOR",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def find_point_in_FOR(bot_cntr,transform_arr,rot_mat,cols,rows):\n        # b) Converting from point --> array to apply transforms\n        bot_cntr_arr =  np.array([bot_cntr[0],bot_cntr[1]])\n        # c) Shift origin from sat_view -> maze\n        bot_cntr_translated = np.zeros_like(bot_cntr_arr)\n        bot_cntr_translated[0] = bot_cntr_arr[0] - transform_arr[0]\n        bot_cntr_translated[1] = bot_cntr_arr[1] - transform_arr[1]\n        # d) Applying rotation tranformation to bot_centroid to get bot location relative to maze\n        bot_on_maze = (rot_mat @ bot_cntr_translated.T).T\n        center_ = np.array([int(cols/2),int(rows/2)])",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "imfill",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def imfill(image):\n  cnts = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]# OpenCV 4.2\n  for idx,_ in enumerate(cnts):\n    cv2.drawContours(image, cnts, idx, 255,-1)\ndef ret_largest_obj(img):\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_largest_obj",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def ret_largest_obj(img):\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)\n        if area > Max_Cntr_area:\n            Max_Cntr_area = area\n            Max_Cntr_idx = index",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_smallest_obj",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "peekOfCode": "def ret_smallest_obj(cnts, noise_thresh = 10):\n  Min_Cntr_area = 1000\n  Min_Cntr_idx= -1\n  for index, cnt in enumerate(cnts):\n      area = cv2.contourArea(cnt)\n      if (area < Min_Cntr_area) and (area > 10):\n          Min_Cntr_area = area\n          Min_Cntr_idx = index\n          SmallestContour_Found = True\n  print(\"min_area\" , Min_Cntr_area)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "overlay",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay(image,overlay_img):\n    gray = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n    mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n    mask_inv = cv2.bitwise_not(mask)\n    roi = image\n    img2 = overlay_img\n    # Now black-out the area of logo in ROI\n    img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n    # Take only region of logo from logo image.\n    img2_fg = cv2.bitwise_and(img2,img2,mask = mask)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "overlay_cropped",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay_cropped(frame_disp,image_rot,crop_loc_row,crop_loc_col,overlay_cols):\n    image_rot_cols = image_rot.shape[1]\n    gray = cv2.cvtColor(image_rot[:,image_rot_cols-overlay_cols:image_rot_cols], cv2.COLOR_BGR2GRAY)\n    mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY)[1]\n    mask_inv = cv2.bitwise_not(mask)\n    frame_overlay_cols = crop_loc_col + image_rot_cols\n    roi = frame_disp[crop_loc_row:crop_loc_row + image_rot.shape[0],frame_overlay_cols-overlay_cols:frame_overlay_cols]            \n    img2 = image_rot[:,image_rot_cols-overlay_cols:image_rot_cols]\n    # Now black-out the area of logo in ROI\n    img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "overlay_live",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay_live(frame_disp,overlay,overlay_map,overlay_path,transform_arr,crp_amt):\n    overlay_rot = cv2.rotate(overlay, cv2.ROTATE_90_CLOCKWISE)\n    map_rot = cv2.rotate(overlay_map, cv2.ROTATE_90_CLOCKWISE)\n    image_rot = cv2.rotate(overlay_path, cv2.ROTATE_90_CLOCKWISE)\n    crop_loc_col = transform_arr[0]+crp_amt\n    #crop_loc_endCol = transform_arr[0]+transform_arr[2]+crp_amt\n    crop_loc_row = transform_arr[1]+crp_amt\n    new_cols = int(overlay_rot.shape[1]*config.debug_live_amount)\n    new_path_cols = int(overlay_rot.shape[1]*config.debug_path_live_amount)\n    new_map_cols = int(overlay_rot.shape[1]*config.debug_map_live_amount)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "draw_bot_speedo",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "peekOfCode": "def draw_bot_speedo(image,bot_speed,bot_turning):\n    height, width = image.shape[0:2]\n    # Ellipse parameters\n    radius = 50\n    center = (int(width / 2), height - 25)\n    axes = (radius, radius)\n    angle = 0\n    startAngle = 180\n    endAngle = 360\n    thickness = 10",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "disp_SatNav",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "peekOfCode": "def disp_SatNav(frame_disp,sbot_view,bot_curr_speed,bot_curr_turning,maze_interestPts,choosen_route,img_choosen_route,transform_arr,crp_amt):\n    # View bot view on left to frame Display\n    bot_view = cv2.resize(sbot_view,None,fx=0.95,fy=0.95)\n    # Draw & Display [For better Understanding of current robot state]\n    center_frame_disp = int(frame_disp.shape[0]/2)\n    center_bot_view = int(bot_view.shape[0]/4)\n    bot_offset = frame_disp.shape[0] - bot_view.shape[0] - 25\n    center_img_shortest_path = int(img_choosen_route.shape[0]/2)\n    isp_offset = center_frame_disp - center_img_shortest_path\n    bot_view = draw_bot_speedo(bot_view,bot_curr_speed,bot_curr_turning)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "detect",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "detect = 1 # Set to 1 for Lane detection\nTesting = True# Set to True --> if want to see what the car is seeing\nProfiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Testing",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Testing = True# Set to True --> if want to see what the car is seeing\nProfiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Profiling",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Profiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "write",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "write = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "In_write",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "In_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Out_write",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Out_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "debugging",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "debugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_Lane",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "debugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_L_ColorSeg",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "debugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_Signs",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "debugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_TrafficLights",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "debugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_TL_Config",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "debugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "enable_SatNav",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "enable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "animate_steering",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "animate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False ",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "angle_orig",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "angle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "angle",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "angle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "engines_on",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "engines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "clr_seg_dbg_created",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "clr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Detect_lane_N_Draw",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Detect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Training_CNN",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Training_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "vid_path",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "vid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Resized_width",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Resized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Resized_height",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Resized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920\nRef_imgHeight = 1080",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "in_q",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "in_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920\nRef_imgHeight = 1080\n#Ref_imgWidth = 640",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Ref_imgWidth",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Ref_imgWidth = 1920\nRef_imgHeight = 1080\n#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Ref_imgHeight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Ref_imgHeight = 1080\n#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "#Ref_imgWidth",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "#Ref_imgHeight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Frame_pixels",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Frame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Resize_Framepixels",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Resize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Lane_Extraction_minArea_per",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "Lane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "minArea_resized",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "minArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "BWContourOpen_speed_MaxDist_per",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "BWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "MaxDist_resized",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "MaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "CropHeight",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "CropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "CropHeight_resized",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "peekOfCode": "CropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.config.config",
        "documentation": {}
    },
    {
        "label": "Video_feed_in",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.sdc_V2",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.sdc_V2",
        "peekOfCode": "class Video_feed_in(Node):\n    def __init__(self):\n        super().__init__('video_subscriber')\n        self.subscriber = self.create_subscription(Image,'/camera/image_raw',self.process_data,10)\n        self.publisher = self.create_publisher(Twist, '/cmd_vel', 40)\n        self.velocity = Twist()\n        self.bridge   = CvBridge() # converting ros images to opencv data\n        self.Debug    = Debugging()\n        self.Car      = Car()\n        # creating object of navigator class",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.sdc_V2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.sdc_V2",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.sdc_V2",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_feed_in()\n  # [NEW]: Animate Steering to see how rolling average smoothes the lane assist\n  if config.animate_steering:\n    concurrent.futures.ThreadPoolExecutor().submit(image_subscriber.animate)\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n\tmain()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.sdc_V2",
        "documentation": {}
    },
    {
        "label": "Video_get",
        "kind": 6,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.upper_camera_video",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.upper_camera_video",
        "peekOfCode": "class Video_get(Node):\n  def __init__(self):\n    super().__init__('video_subscriber')# node name\n    ## Created a subscriber \n    self.subscriber = self.create_subscription(Image,'/upper_camera/image_raw',self.process_data,10)\n    ## setting for writing the frames into a video\n    self.out = cv2.VideoWriter('/home/luqman/output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (1280,720))\n    self.bridge = CvBridge() # converting ros images to opencv data\n  def process_data(self, data): \n    frame = self.bridge.imgmsg_to_cv2(data,'bgr8') # performing conversion",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.upper_camera_video",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.upper_camera_video",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.upper_camera_video",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_get()\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n  main()",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.self_driving_car_pkg copy.upper_camera_video",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_copyright",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_flake8",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_pep257",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "peekOfCode": "package_name = 'self_driving_car_pkg'\nconfig_module = \"self_driving_car_pkg/config\"\ndata_module =\"self_driving_car_pkg/data\"\ndetection_module =\"self_driving_car_pkg/Detection\"\ngps_navigation = \"self_driving_car_pkg/GPS_Navigation\"\ndet_l_module =\"self_driving_car_pkg/Detection/Lanes\"\ndetec_l_a_module=\"self_driving_car_pkg/Detection/Lanes/a_Segmentation\"\ndetec_l_b_module=\"self_driving_car_pkg/Detection/Lanes/b_Estimation\"\ndetec_l_c_module=\"self_driving_car_pkg/Detection/Lanes/c_Cleaning\"\ndetec_l_d_module=\"self_driving_car_pkg/Detection/Lanes/d_LaneInfo_Extraction\"",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "documentation": {}
    },
    {
        "label": "config_module",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "peekOfCode": "config_module = \"self_driving_car_pkg/config\"\ndata_module =\"self_driving_car_pkg/data\"\ndetection_module =\"self_driving_car_pkg/Detection\"\ngps_navigation = \"self_driving_car_pkg/GPS_Navigation\"\ndet_l_module =\"self_driving_car_pkg/Detection/Lanes\"\ndetec_l_a_module=\"self_driving_car_pkg/Detection/Lanes/a_Segmentation\"\ndetec_l_b_module=\"self_driving_car_pkg/Detection/Lanes/b_Estimation\"\ndetec_l_c_module=\"self_driving_car_pkg/Detection/Lanes/c_Cleaning\"\ndetec_l_d_module=\"self_driving_car_pkg/Detection/Lanes/d_LaneInfo_Extraction\"\ndet_s_module =\"self_driving_car_pkg/Detection/Signs\"",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "documentation": {}
    },
    {
        "label": "gps_navigation",
        "kind": 5,
        "importPath": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "description": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "peekOfCode": "gps_navigation = \"self_driving_car_pkg/GPS_Navigation\"\ndet_l_module =\"self_driving_car_pkg/Detection/Lanes\"\ndetec_l_a_module=\"self_driving_car_pkg/Detection/Lanes/a_Segmentation\"\ndetec_l_b_module=\"self_driving_car_pkg/Detection/Lanes/b_Estimation\"\ndetec_l_c_module=\"self_driving_car_pkg/Detection/Lanes/c_Cleaning\"\ndetec_l_d_module=\"self_driving_car_pkg/Detection/Lanes/d_LaneInfo_Extraction\"\ndet_s_module =\"self_driving_car_pkg/Detection/Signs\"\ndetec_s_a_module=\"self_driving_car_pkg/Detection/Signs/Classification\"\ndetec_TL_module=\"self_driving_car_pkg/Detection/TrafficLights\"\nsetup(",
        "detail": "ROS2-Self-Driving-Car-AI-using-OpenCV.self_driving_car_pkg.setup",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_executable",
        "description": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_executable",
        "peekOfCode": "def main(args=None):\n    writer = rosbag2_py.SequentialWriter()\n    storage_options = rosbag2_py._storage.StorageOptions(\n        uri='big_synthetic_bag',\n        storage_id='mcap')\n    converter_options = rosbag2_py._storage.ConverterOptions('', '')\n    writer.open(storage_options, converter_options)\n    topic_info = rosbag2_py._storage.TopicMetadata(\n        id=0,\n        name='synthetic',",
        "detail": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_executable",
        "documentation": {}
    },
    {
        "label": "DataGeneratorNode",
        "kind": 6,
        "importPath": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_node",
        "description": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_node",
        "peekOfCode": "class DataGeneratorNode(Node):\n    def __init__(self):\n        super().__init__('data_generator_node')\n        self.data = Int32()\n        self.data.data = 0\n        self.writer = rosbag2_py.SequentialWriter()\n        storage_options = rosbag2_py._storage.StorageOptions(\n            uri='timed_synthetic_bag',\n            storage_id='mcap')\n        converter_options = rosbag2_py._storage.ConverterOptions('', '')",
        "detail": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_node",
        "description": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_node",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    dgn = DataGeneratorNode()\n    rclpy.spin(dgn)\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.data_generator_node",
        "documentation": {}
    },
    {
        "label": "SimpleBagRecorder",
        "kind": 6,
        "importPath": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.simple_bag_recorder",
        "description": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.simple_bag_recorder",
        "peekOfCode": "class SimpleBagRecorder(Node):\n    def __init__(self):\n        super().__init__('simple_bag_recorder')\n        self.writer = rosbag2_py.SequentialWriter()\n        storage_options = rosbag2_py._storage.StorageOptions(\n            uri='/home/ubuntu/my_bag',\n            storage_id='mcap')\n        converter_options = rosbag2_py._storage.ConverterOptions('', '')\n        self.writer.open(storage_options, converter_options)\n        topic_info = rosbag2_py._storage.TopicMetadata(",
        "detail": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.simple_bag_recorder",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.simple_bag_recorder",
        "description": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.simple_bag_recorder",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    sbr = SimpleBagRecorder()\n    rclpy.spin(sbr)\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.bag_recorder_nodes_py.build.lib.bag_recorder_nodes_py.simple_bag_recorder",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "kind": 6,
        "importPath": "build.custom_msg.build.lib.custom_msg.my_custom_msg._sample_class",
        "description": "build.custom_msg.build.lib.custom_msg.my_custom_msg._sample_class",
        "peekOfCode": "class SampleClass:\n    \"\"\"A sample class to check how they can be imported by other ROS2 packages.\"\"\"\n    def __init__(self, name: str):\n        self._name = name\n    def get_name(self) -> str:\n        \"\"\"\n        Gets the name of this instance.\n        :return: This name.\n        \"\"\"\n        return self._name",
        "detail": "build.custom_msg.build.lib.custom_msg.my_custom_msg._sample_class",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "kind": 2,
        "importPath": "build.custom_msg.build.lib.custom_msg.my_custom_msg._sample_function",
        "description": "build.custom_msg.build.lib.custom_msg.my_custom_msg._sample_function",
        "peekOfCode": "def sample_function_for_square_of_sum(a: float, b: float) -> float:\n    \"\"\"Returns the square of a sum (a + b)^2 = a^2 + 2ab + b^2\"\"\"\n    return a**2 + 2*a*b + b**2",
        "detail": "build.custom_msg.build.lib.custom_msg.my_custom_msg._sample_function",
        "documentation": {}
    },
    {
        "label": "Metaclass_AmazingQuote",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "peekOfCode": "class Metaclass_AmazingQuote(type):\n    \"\"\"Metaclass of message 'AmazingQuote'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "peekOfCode": "class AmazingQuote(metaclass=Metaclass_AmazingQuote):\n    \"\"\"Message class 'AmazingQuote'.\"\"\"\n    __slots__ = [\n        '_id',\n        '_quote',\n        '_philosopher_name',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'id': 'int32',",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "documentation": {}
    },
    {
        "label": "ros_python_check_fields",
        "kind": 5,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "peekOfCode": "ros_python_check_fields = getenv('ROS_PYTHON_CHECK_FIELDS', default='')\n# Import statements for member types\nimport builtins  # noqa: E402, I100\nimport rosidl_parser.definition  # noqa: E402, I100\nclass Metaclass_AmazingQuote(type):\n    \"\"\"Metaclass of message 'AmazingQuote'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.msg._amazing_quote",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint_Request",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint_Request(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Request'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint_Request",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint_Request(metaclass=Metaclass_WhatIsThePoint_Request):\n    \"\"\"Message class 'WhatIsThePoint_Request'.\"\"\"\n    __slots__ = [\n        '_quote',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'quote': 'custom_msg_cpp/AmazingQuote',\n    }\n    # This attribute is used to store an rosidl_parser.definition variable",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint_Response",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint_Response(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Response'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint_Response",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint_Response(metaclass=Metaclass_WhatIsThePoint_Response):\n    \"\"\"Message class 'WhatIsThePoint_Response'.\"\"\"\n    __slots__ = [\n        '_point',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'point': 'geometry_msgs/Point',\n    }\n    # This attribute is used to store an rosidl_parser.definition variable",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint_Event",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint_Event(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Event'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint_Event",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint_Event(metaclass=Metaclass_WhatIsThePoint_Event):\n    \"\"\"Message class 'WhatIsThePoint_Event'.\"\"\"\n    __slots__ = [\n        '_info',\n        '_request',\n        '_response',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'info': 'service_msgs/ServiceEventInfo',",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint(type):\n    \"\"\"Metaclass of service 'WhatIsThePoint'.\"\"\"\n    _TYPE_SUPPORT = None\n    @classmethod\n    def __import_type_support__(cls):\n        try:\n            from rosidl_generator_py import import_type_support\n            module = import_type_support('custom_msg_cpp')\n        except ImportError:\n            import logging",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint(metaclass=Metaclass_WhatIsThePoint):\n    from custom_msg_cpp.srv._what_is_the_point import WhatIsThePoint_Request as Request\n    from custom_msg_cpp.srv._what_is_the_point import WhatIsThePoint_Response as Response\n    from custom_msg_cpp.srv._what_is_the_point import WhatIsThePoint_Event as Event\n    def __init__(self):\n        raise NotImplementedError('Service classes can not be instantiated')",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "ros_python_check_fields",
        "kind": 5,
        "importPath": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "ros_python_check_fields = getenv('ROS_PYTHON_CHECK_FIELDS', default='')\n# Import statements for member types\nimport builtins  # noqa: E402, I100\nimport rosidl_parser.definition  # noqa: E402, I100\nclass Metaclass_WhatIsThePoint_Request(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Request'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None",
        "detail": "build.custom_msg_cpp.ament_cmake_python.custom_msg_cpp.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "Metaclass_AmazingQuote",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "peekOfCode": "class Metaclass_AmazingQuote(type):\n    \"\"\"Metaclass of message 'AmazingQuote'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "documentation": {}
    },
    {
        "label": "AmazingQuote",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "peekOfCode": "class AmazingQuote(metaclass=Metaclass_AmazingQuote):\n    \"\"\"Message class 'AmazingQuote'.\"\"\"\n    __slots__ = [\n        '_id',\n        '_quote',\n        '_philosopher_name',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'id': 'int32',",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "documentation": {}
    },
    {
        "label": "ros_python_check_fields",
        "kind": 5,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "peekOfCode": "ros_python_check_fields = getenv('ROS_PYTHON_CHECK_FIELDS', default='')\n# Import statements for member types\nimport builtins  # noqa: E402, I100\nimport rosidl_parser.definition  # noqa: E402, I100\nclass Metaclass_AmazingQuote(type):\n    \"\"\"Metaclass of message 'AmazingQuote'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.msg._amazing_quote",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint_Request",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint_Request(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Request'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint_Request",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint_Request(metaclass=Metaclass_WhatIsThePoint_Request):\n    \"\"\"Message class 'WhatIsThePoint_Request'.\"\"\"\n    __slots__ = [\n        '_quote',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'quote': 'custom_msg_cpp/AmazingQuote',\n    }\n    # This attribute is used to store an rosidl_parser.definition variable",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint_Response",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint_Response(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Response'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint_Response",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint_Response(metaclass=Metaclass_WhatIsThePoint_Response):\n    \"\"\"Message class 'WhatIsThePoint_Response'.\"\"\"\n    __slots__ = [\n        '_point',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'point': 'geometry_msgs/Point',\n    }\n    # This attribute is used to store an rosidl_parser.definition variable",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint_Event",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint_Event(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Event'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None\n    _TYPE_SUPPORT = None\n    __constants = {\n    }\n    @classmethod",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint_Event",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint_Event(metaclass=Metaclass_WhatIsThePoint_Event):\n    \"\"\"Message class 'WhatIsThePoint_Event'.\"\"\"\n    __slots__ = [\n        '_info',\n        '_request',\n        '_response',\n        '_check_fields',\n    ]\n    _fields_and_field_types = {\n        'info': 'service_msgs/ServiceEventInfo',",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "Metaclass_WhatIsThePoint",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class Metaclass_WhatIsThePoint(type):\n    \"\"\"Metaclass of service 'WhatIsThePoint'.\"\"\"\n    _TYPE_SUPPORT = None\n    @classmethod\n    def __import_type_support__(cls):\n        try:\n            from rosidl_generator_py import import_type_support\n            module = import_type_support('custom_msg_cpp')\n        except ImportError:\n            import logging",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "WhatIsThePoint",
        "kind": 6,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "class WhatIsThePoint(metaclass=Metaclass_WhatIsThePoint):\n    from custom_msg_cpp.srv._what_is_the_point import WhatIsThePoint_Request as Request\n    from custom_msg_cpp.srv._what_is_the_point import WhatIsThePoint_Response as Response\n    from custom_msg_cpp.srv._what_is_the_point import WhatIsThePoint_Event as Event\n    def __init__(self):\n        raise NotImplementedError('Service classes can not be instantiated')",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "ros_python_check_fields",
        "kind": 5,
        "importPath": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "description": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "peekOfCode": "ros_python_check_fields = getenv('ROS_PYTHON_CHECK_FIELDS', default='')\n# Import statements for member types\nimport builtins  # noqa: E402, I100\nimport rosidl_parser.definition  # noqa: E402, I100\nclass Metaclass_WhatIsThePoint_Request(type):\n    \"\"\"Metaclass of message 'WhatIsThePoint_Request'.\"\"\"\n    _CREATE_ROS_MESSAGE = None\n    _CONVERT_FROM_PY = None\n    _CONVERT_TO_PY = None\n    _DESTROY_ROS_MESSAGE = None",
        "detail": "build.custom_msg_cpp.rosidl_generator_py.custom_msg_cpp.srv._what_is_the_point",
        "documentation": {}
    },
    {
        "label": "TurtleNode",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.TurtleNode",
        "description": "build.entity_controller.build.lib.entity_controller.TurtleNode",
        "peekOfCode": "class TurtleNode(Node):\n    def __init__(self):\n        super().__init__('TurtleNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # msg = Person()\n        # msg.name = \"ROS User\"\n        # msg.age = 4  \n        # print(\">>>>>>>>>>>>>\",msg)      \n        # 声明参数\n        self.declare_parameter('node_name', 'TurtleNode')\n        self.declare_parameter('linear_speed', 0.5)",
        "detail": "build.entity_controller.build.lib.entity_controller.TurtleNode",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.TurtleNode",
        "description": "build.entity_controller.build.lib.entity_controller.TurtleNode",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    turtlenode = TurtleNode()\n    rclpy.spin(turtlenode)\n    turtlenode.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.entity_controller.build.lib.entity_controller.TurtleNode",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.WarShip",
        "description": "build.entity_controller.build.lib.entity_controller.WarShip",
        "peekOfCode": "def main():\n    print('Hi from entity_controller.')\nif __name__ == '__main__':\n    main()",
        "detail": "build.entity_controller.build.lib.entity_controller.WarShip",
        "documentation": {}
    },
    {
        "label": "WarShipPublisher",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.WarShipPublisher",
        "description": "build.entity_controller.build.lib.entity_controller.WarShipPublisher",
        "peekOfCode": "class WarShipPublisher(Node):\n    def __init__(self):\n        super().__init__('entity_controller_WarShip')\n        # 10: 这是发布者的质量服务（Quality of Service，QoS）设置。QoS设置定义了消息传递的可靠性和历史保持策略。在这里，10是QoS配置的整数表示，对应于rmw_qos_profile_sensor_data，这是一个适用于传感器数据的QoS配置，它提供了一定的可靠性保证和历史保持策略。\n        self.publisher_ = self.create_publisher(String, 'entity_controller/WarShip', 10)\n        timer_period = 0.5  # seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n    def timer_callback(self):\n        msg = String()\n        msg.data = 'Hello ROS2!'",
        "detail": "build.entity_controller.build.lib.entity_controller.WarShipPublisher",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.WarShipPublisher",
        "description": "build.entity_controller.build.lib.entity_controller.WarShipPublisher",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    publisher = WarShipPublisher()\n    rclpy.spin(publisher)\n    publisher.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.entity_controller.build.lib.entity_controller.WarShipPublisher",
        "documentation": {}
    },
    {
        "label": "WarShipSubscriber",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.WarShipSubscriber",
        "description": "build.entity_controller.build.lib.entity_controller.WarShipSubscriber",
        "peekOfCode": "class WarShipSubscriber(Node):\n    def __init__(self):\n        super().__init__('entity_controller_WarShip')\n        self.subscription = self.create_subscription(\n            String,\n            'entity_controller/WarShip', \n            self.listener_callback,\n            10)\n        self.subscription  # prevent unused variable warning\n    def listener_callback(self, msg):",
        "detail": "build.entity_controller.build.lib.entity_controller.WarShipSubscriber",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.WarShipSubscriber",
        "description": "build.entity_controller.build.lib.entity_controller.WarShipSubscriber",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    subscriber = WarShipSubscriber()\n    rclpy.spin(subscriber)\n    subscriber.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.entity_controller.build.lib.entity_controller.WarShipSubscriber",
        "documentation": {}
    },
    {
        "label": "AmazingQuoteConfigurablePublisherNode",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.amazing_quote_configurable_publisher_node",
        "description": "build.entity_controller.build.lib.entity_controller.amazing_quote_configurable_publisher_node",
        "peekOfCode": "class AmazingQuoteConfigurablePublisherNode(Node):\n    \"\"\"A configurable ROS2 Node that publishes a configurable amazing quote.\"\"\"\n    def __init__(self):\n        super().__init__('amazing_quote_configurable_publisher_node')\n        # Periodically-obtained parameters(周期性参数)\n        self.declare_parameter('quote', 'Use the force, Pikachu!')\n        self.declare_parameter('philosopher_name', 'Uncle Ben')\n        # One-off parameters(一次性参数)\n        self.declare_parameter('topic_name', 'amazing_quote')\n        topic_name: str = self.get_parameter('topic_name').get_parameter_value().string_value",
        "detail": "build.entity_controller.build.lib.entity_controller.amazing_quote_configurable_publisher_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.amazing_quote_configurable_publisher_node",
        "description": "build.entity_controller.build.lib.entity_controller.amazing_quote_configurable_publisher_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        amazing_quote_configurable_publisher_node = AmazingQuoteConfigurablePublisherNode()\n        rclpy.spin(amazing_quote_configurable_publisher_node)",
        "detail": "build.entity_controller.build.lib.entity_controller.amazing_quote_configurable_publisher_node",
        "documentation": {}
    },
    {
        "label": "AmazingQuotePublisherNode",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.amazing_quote_publisher_node",
        "description": "build.entity_controller.build.lib.entity_controller.amazing_quote_publisher_node",
        "peekOfCode": "class AmazingQuotePublisherNode(Node):\n    \"\"\"A ROS2 Node that publishes an amazing quote.\"\"\"\n    def __init__(self):\n        super().__init__('amazing_quote_publisher_node')\n        self.amazing_quote_publisher = self.create_publisher(\n            msg_type=AmazingQuote,\n            topic='/amazing_quote',\n            qos_profile=1)\n        timer_period: float = 0.5\n        self.timer = self.create_timer(timer_period, self.timer_callback)",
        "detail": "build.entity_controller.build.lib.entity_controller.amazing_quote_publisher_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.amazing_quote_publisher_node",
        "description": "build.entity_controller.build.lib.entity_controller.amazing_quote_publisher_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        amazing_quote_publisher_node = AmazingQuotePublisherNode()\n        rclpy.spin(amazing_quote_publisher_node)",
        "detail": "build.entity_controller.build.lib.entity_controller.amazing_quote_publisher_node",
        "documentation": {}
    },
    {
        "label": "AmazingQuoteSubscriberNode",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.amazing_quote_subscriber_node",
        "description": "build.entity_controller.build.lib.entity_controller.amazing_quote_subscriber_node",
        "peekOfCode": "class AmazingQuoteSubscriberNode(Node):\n    \"\"\"A ROS2 Node that receives and AmazingQuote and prints out its info.\"\"\"\n    def __init__(self):\n        super().__init__('amazing_quote_subscriber_node')\n        self.amazing_quote_subscriber = self.create_subscription(\n            msg_type=AmazingQuote,\n            topic='/amazing_quote',\n            callback=self.amazing_quote_subscriber_callback,\n            qos_profile=1)\n    def amazing_quote_subscriber_callback(self, msg: AmazingQuote):",
        "detail": "build.entity_controller.build.lib.entity_controller.amazing_quote_subscriber_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.amazing_quote_subscriber_node",
        "description": "build.entity_controller.build.lib.entity_controller.amazing_quote_subscriber_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        amazing_quote_subscriber_node = AmazingQuoteSubscriberNode()\n        rclpy.spin(amazing_quote_subscriber_node)",
        "detail": "build.entity_controller.build.lib.entity_controller.amazing_quote_subscriber_node",
        "documentation": {}
    },
    {
        "label": "WhatIsThePointServiceClientNode",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_client_node",
        "description": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_client_node",
        "peekOfCode": "class WhatIsThePointServiceClientNode(Node):\n    \"\"\"A ROS2 Node with a Service Client for WhatIsThePoint.\"\"\"\n    def __init__(self):\n        super().__init__('what_is_the_point_service_client')\n        self.service_client = self.create_client(\n            srv_type=WhatIsThePoint,\n            srv_name='/what_is_the_point')\n        while not self.service_client.wait_for_service(timeout_sec=1.0):\n            self.get_logger().info(f'service {self.service_client.srv_name} not available, waiting...')\n        self.future: Future = None",
        "detail": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_client_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_client_node",
        "description": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_client_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        what_is_the_point_service_client_node = WhatIsThePointServiceClientNode()\n        rclpy.spin(what_is_the_point_service_client_node)",
        "detail": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_client_node",
        "documentation": {}
    },
    {
        "label": "WhatIsThePointServiceServerNode",
        "kind": 6,
        "importPath": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_server_node",
        "description": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_server_node",
        "peekOfCode": "class WhatIsThePointServiceServerNode(Node):\n    \"\"\"A ROS2 Node with a Service Server for WhatIsThePoint.\"\"\"\n    def __init__(self):\n        super().__init__('what_is_the_point_service_server')\n        self.service_server = self.create_service(\n            srv_type=WhatIsThePoint,\n            srv_name='/what_is_the_point',\n            callback=self.what_is_the_point_service_callback)\n        self.service_server_call_count: int = 0\n    def what_is_the_point_service_callback(self,",
        "detail": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_server_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_server_node",
        "description": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_server_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        what_is_the_point_service_server_node = WhatIsThePointServiceServerNode()\n        rclpy.spin(what_is_the_point_service_server_node)",
        "detail": "build.entity_controller.build.lib.entity_controller.what_is_the_point_service_server_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.environment_simulator.build.lib.environment_simulator.Weather",
        "description": "build.environment_simulator.build.lib.environment_simulator.Weather",
        "peekOfCode": "def main():\n    print('Hi from environment_simulator.')\nif __name__ == '__main__':\n    main()",
        "detail": "build.environment_simulator.build.lib.environment_simulator.Weather",
        "documentation": {}
    },
    {
        "label": "OnHueLowChange",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):\n    global Sat_Low",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnLitLowChange",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):\n    global Sat_Low\n    Sat_Low = val\n    MaskExtract()\ndef OnHueLowChange_Y(val):\n    global Hue_Low_Y",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnSatLowChange",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnSatLowChange(val):\n    global Sat_Low\n    Sat_Low = val\n    MaskExtract()\ndef OnHueLowChange_Y(val):\n    global Hue_Low_Y\n    Hue_Low_Y = val\n    MaskExtract()\ndef OnHueHighChange_Y(val):\n    global Hue_High_Y",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnHueLowChange_Y",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueLowChange_Y(val):\n    global Hue_Low_Y\n    Hue_Low_Y = val\n    MaskExtract()\ndef OnHueHighChange_Y(val):\n    global Hue_High_Y\n    Hue_High_Y = val\n    MaskExtract()\t\ndef OnLitLowChange_Y(val):\n    global Lit_Low_Y",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnHueHighChange_Y",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnHueHighChange_Y(val):\n    global Hue_High_Y\n    Hue_High_Y = val\n    MaskExtract()\t\ndef OnLitLowChange_Y(val):\n    global Lit_Low_Y\n    Lit_Low_Y = val\n    MaskExtract()\ndef OnSatLowChange_Y(val):\n    global Sat_Low_Y",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnLitLowChange_Y",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnLitLowChange_Y(val):\n    global Lit_Low_Y\n    Lit_Low_Y = val\n    MaskExtract()\ndef OnSatLowChange_Y(val):\n    global Sat_Low_Y\n    Sat_Low_Y = val\n    MaskExtract()\ndef MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OnSatLowChange_Y",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OnSatLowChange_Y(val):\n    global Sat_Low_Y\n    Sat_Low_Y = val\n    MaskExtract()\ndef MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))\n    mask_Y = clr_segment(HLS,(Hue_Low_Y,Lit_Low_Y ,Sat_Low_Y),(Hue_High_Y,255,255))#Combine 6ms\n    mask_Y_ = mask_Y != 0\n    dst_Y = src * (mask_Y_[:,:,None].astype(src.dtype))\n    mask_ = mask != 0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "MaskExtract",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def MaskExtract():\n    mask   = clr_segment(HLS,(Hue_Low  ,Lit_Low   ,Sat_Low  ),(255       ,255,255))\n    mask_Y = clr_segment(HLS,(Hue_Low_Y,Lit_Low_Y ,Sat_Low_Y),(Hue_High_Y,255,255))#Combine 6ms\n    mask_Y_ = mask_Y != 0\n    dst_Y = src * (mask_Y_[:,:,None].astype(src.dtype))\n    mask_ = mask != 0\n    dst = src * (mask_[:,:,None].astype(src.dtype))\n    if (config.debugging_Lane and config.debugging and config.debugging_L_ColorSeg):\n        cv2.imshow('[Segment_Colour_final] mask',dst)\n        cv2.imshow('[Segment_Colour_final] mask_Y',dst_Y)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "clr_segment",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def clr_segment(HSL,lower_range,upper_range):\n    # 2. Performing Color Segmentation on Given Range\n    lower = np.array( [lower_range[0],lower_range[1] ,lower_range[2]] )\n    upper = np.array( [upper_range[0]    ,255     ,255])\n    mask = cv2.inRange(HSL, lower, upper)\n    # 3. Dilating Segmented ROI's\n    kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(3,3))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_DILATE, kernel)\n    return mask\ndef LaneROI(frame,mask,minArea):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "LaneROI",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def LaneROI(frame,mask,minArea):\n    # 4a. Keeping only Midlane ROI of frame\n    frame_Lane = cv2.bitwise_and(frame,frame,mask=mask)#Extracting only RGB from a specific region\n    # 4b. Converting frame to grayscale\n    Lane_gray = cv2.cvtColor(frame_Lane,cv2.COLOR_BGR2GRAY) # Converting to grayscale\n    # 4c. Keep Only larger objects\n    Lane_gray_opened = BwareaOpen(Lane_gray,minArea) # Getting mask of only objects larger then minArea\n    Lane_gray = cv2.bitwise_and(Lane_gray,Lane_gray_opened)# Getting the gray of that mask\n    Lane_gray_Smoothed = cv2.GaussianBlur(Lane_gray,(11,11),1) # Smoothing out the edges for edge extraction later\n    # 4d. Keeping only Edges of Segmented ROI    ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "OuterLaneROI",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def OuterLaneROI(frame,mask,minArea):\n    Outer_Points_list=[]\n    # 5a. Extracted OuterLanes Mask And Edge\n    frame_Lane = cv2.bitwise_and(frame,frame,mask=mask)#Extracting only RGB from a specific region\n    Lane_gray = cv2.cvtColor(frame_Lane,cv2.COLOR_BGR2GRAY)# Converting to grayscale\n    Lane_gray_opened = BwareaOpen(Lane_gray,minArea) # Getting mask of only objects larger then minArea\n    Lane_gray = cv2.bitwise_and(Lane_gray,Lane_gray_opened)# Getting the gray of that mask\n    Lane_gray_Smoothed = cv2.GaussianBlur(Lane_gray,(11,11),1)# Smoothing out the edges for edge extraction later\n    Lane_edge = cv2.Canny(Lane_gray_Smoothed,50,150, None, 3) # Extracting the Edge of Canny\n    # 5b. Kept Larger OuterLane",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Segment_Colour",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "def Segment_Colour(frame,minArea):\n    \"\"\" Segment Lane-Lines (both outer and middle) from the road lane\n    Args:\n        frame (numpy nd array): Prius front-cam view\n        minArea (int): minimum area of an object required to be considered as a valid object\n    Returns:\n        numpy 2d array: Edges of white mid-lane\n        numpy 2d array: Mask  of white  mid-lane\n        numpy 2d array: Edges of yellow outer-lane\n        numpy 2d array: Edges of outer-lane (Seperated to get inner side later)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_Low",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_Low = 0\nLit_Low = 225\nSat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Lit_Low",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Lit_Low = 225\nSat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Sat_Low",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Sat_Low = 0#61\nHue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_Low_Y",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_Low_Y = 30#30\nHue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Hue_High_Y",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Hue_High_Y = 33#40\nLit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Lit_Low_Y",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Lit_Low_Y = 120#63\nSat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Sat_Low_Y",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "peekOfCode": "Sat_Low_Y = 0#81\ndef OnHueLowChange(val):\n    global Hue_Low\n    Hue_Low = val\n    MaskExtract()\ndef OnLitLowChange(val):\n    global Lit_Low\n    Lit_Low = val\n    MaskExtract()\ndef OnSatLowChange(val):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.a_Segmentation.colour_segmentation_final",
        "documentation": {}
    },
    {
        "label": "Distance_",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "ApproxDistBWCntrs",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])\n    cY_cmp = int(M_cmp[\"m01\"] / M_cmp[\"m00\"])\n    minDist=Distance_((cX,cY),(cX_cmp,cY_cmp))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "RetLargestContour",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def RetLargestContour(gray):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "Estimate_MidLane",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "peekOfCode": "def Estimate_MidLane(BW,MaxDistance):\n    \"\"\"Estimate the mid-lane trajectory based on the detected midlane (patches) mask\n    Args:\n        BW (numpy_1d_array): Midlane (patches) mask extracted from the GetLaneROI()\n        MaxDistance (int): max distance for a patch to be considered part of the midlane \n                                      else it is noise\n    Returns:\n        numpy_1d_array: estimated midlane trajectory (mask)\n    \"\"\"\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,2))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.b_Estimation.Our_EstimationAlgo",
        "documentation": {}
    },
    {
        "label": "IsPathCrossingMid",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "def IsPathCrossingMid(Midlane,Mid_cnts,Outer_cnts):\n\tis_Ref_to_path_Left = 0\n\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "GetYellowInnerEdge",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "def GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:\n\t\tOuterLanes (numpy_1d_array): detected outerlane\n\t\tMidLane (numpy_1d_array): estimated midlane trajectory\n\t\tOuterLane_Points (list): points one from each side of detected outerlane\n\tReturns:\n\t\tnumpy_1d_array: outerlane (side) closest to midlane\n\t\tlist[List[tuple]]: refined contours of outerlane\n\t\tlist[List[tuple]]: refined contours of midlane",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tis_Ref_to_path_Left",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tis_Ref_to_path_Left = 0\n\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tRef_To_Path_Image",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tRef_To_Path_Image = np.zeros_like(Midlane)\n\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMidlane_copy",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMidlane_copy = Midlane.copy()\n\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\tif not Mid_cnts:\n\t\t\tprint(\"[Warning!!!] NO Midlane detected\")\n\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_Rows",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_Rows",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_lowP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_lowP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tTraj_lowP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tTraj_lowP = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) , int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t#cv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t#cv2.line(Ref_To_Path_Image,(Traj_lowP[0],Ref_To_Path_Image.shape[0]),(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Ref_To_Path_Image,Traj_lowP,(int(Ref_To_Path_Image.shape[1]/2),Ref_To_Path_Image.shape[0]),(255,255,0),2)# distance of car center with lane path\n\tcv2.line(Midlane_copy,tuple(Mid_lowP),(Mid_lowP[0],Midlane_copy.shape[0]-1),(255,255,0),2)# distance of car center with lane path\n\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tis_Ref_to_path_Left",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tis_Ref_to_path_Left = ( (int(Ref_To_Path_Image.shape[1]/2) - Traj_lowP[0]) > 0 )\n\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left\n\telse:\n\t\treturn False,is_Ref_to_path_Left\ndef GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t#Distance_And_Midlane",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t#Distance_And_Midlane = cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy)\n\tif( np.any( (cv2.bitwise_and(Ref_To_Path_Image,Midlane_copy) > 0) ) ):\n\t\t# Midlane and CarPath Intersets (MidCrossing)\n\t\treturn True,is_Ref_to_path_Left\n\telse:\n\t\treturn False,is_Ref_to_path_Left\ndef GetYellowInnerEdge(OuterLanes,MidLane,OuterLane_Points):\n\t\"\"\"Fetching closest outer lane (side) to mid lane \n\tArgs:\n\t\tOuterLanes (numpy_1d_array): detected outerlane",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOffset_correction",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOffset_correction = 0\n\t#Container for storing/returning closest Outer Lane\n\tOuter_Lanes_ret= np.zeros(OuterLanes.shape,OuterLanes.dtype)\n\t# 1. Extracting Mid and OuterLane Contours\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:\n\t\tNoOuterLane_before=False\n\t# 3. Setting the first contour of Midlane as Refrence\n\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t# 2. Checking if OuterLane was Present initially or not\n\tif not Outer_cnts:\n\t\tNoOuterLane_before=True\n\telse:\n\t\tNoOuterLane_before=False\n\t# 3. Setting the first contour of Midlane as Refrence\n\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):\n\t\tRef = tuple(Mid_cnts[0][0][0])",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\tRef",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\tRef = (0,0) #If MidContours are present use the first ContourPoint as Ref To Find Nearest YellowLaneContour\n\tif(Mid_cnts):\n\t\tRef = tuple(Mid_cnts[0][0][0])\n\t# 4. >>>>>>>>>>>>>> Condition 1 : if Both Midlane and Outlane is detected <<<<<<<<<<<<<\n\t# 4. [len(OuterLane_Points)==2)]\n\tif  ( Mid_cnts and (len(OuterLane_Points)==2)):\n\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tRef",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tRef = tuple(Mid_cnts[0][0][0])\n\t# 4. >>>>>>>>>>>>>> Condition 1 : if Both Midlane and Outlane is detected <<<<<<<<<<<<<\n\t# 4. [len(OuterLane_Points)==2)]\n\tif  ( Mid_cnts and (len(OuterLane_Points)==2)):\n\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tPoint_a",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tPoint_a = OuterLane_Points[0]\n\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tPoint_b",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tPoint_b = OuterLane_Points[1]\n\t\t# 4. [len(OuterLane_Points)==2)] _ A: Find closest outlane to the midlane\n\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tClosest_Index",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tClosest_Index = 0\n\t\tif(Distance_(Point_a,Ref) <= Distance_(Point_b,Ref)):\n\t\t\tClosest_Index=0\n\t\telif(len(Outer_cnts)>1):\n\t\t\tClosest_Index=1\n\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_Lanes_ret",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_Lanes_ret = cv2.drawContours(Outer_Lanes_ret, Outer_cnts, Closest_Index, 255, 1)\n\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):\n\t\t# Discard\n\t\t#Else \n\t\t# Continue\n\t\t# 4. [len(OuterLane_Points)==2)] _ B: Find Connection between Mid And Detected OuterLane Crosses Mid\n\t\tIsPathCrossing , IsCrossingLeft = IsPathCrossingMid(MidLane,Mid_cnts,Outer_cnts_ret)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_ret",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_cnts_ret = [Outer_cnts[Closest_Index]]\n\t\t# ================================ Checking IF Correct Side outlane is detected =====================================\n\t\t# The idea is to find lane points here and determine if trajectory is crossing midlane\n\t\t#If (Yes):\n\t\t# Discard\n\t\t#Else \n\t\t# Continue\n\t\t# 4. [len(OuterLane_Points)==2)] _ B: Find Connection between Mid And Detected OuterLane Crosses Mid\n\t\tIsPathCrossing , IsCrossingLeft = IsPathCrossingMid(MidLane,Mid_cnts,Outer_cnts_ret)\n\t\tif(IsPathCrossing):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOuterLanes",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOuterLanes = np.zeros_like(OuterLanes)#Empty outerLane\n\t\telse:\n\t\t\t#If no fllor crossing return results\n\t\t\treturn Outer_Lanes_ret ,Outer_cnts_ret, Mid_cnts,0\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tcv2.imshow(\"[GetYellowInnerEdge] OuterLanesaftr\",OuterLanes)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[GetYellowInnerEdge] OuterLanesaftr\")\n\t# 4. [len(OuterLane_Points)!=2)]\n\telif( Mid_cnts and np.any(OuterLanes>0) ):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOuterLanes",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOuterLanes = np.zeros_like(OuterLanes)#Empty outerLane\n\t\telse:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [np.any(OuterLanes>0)] Path are not crossing --> Ret as it is\")\n\t\t\t#If no fllor crossing return results\n\t\t\treturn OuterLanes ,Outer_cnts, Mid_cnts,0\t\t\n\t# 4. >>>>>>>>>>>>>> Condition 2 : if MidLane is present but no Outlane detected >>>>>>>>>>>>>> Or Outlane got zerod because of crossings Midlane\n\t# Action: Create Outlane on Side that represent the larger Lane as seen by camera\n\tif( Mid_cnts and ( not np.any(OuterLanes>0) ) ):\t\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Rows",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_highP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_low_Col",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_low_Col = Mid_lowP[0]\n\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tDrawRight",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tDrawRight = False\n\t\t# 4. [Midlane But , No OuterLanes!!!]\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ A : Check if Present before or Not \n\t\tif NoOuterLane_before:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] No OuterLanes were detected at all so can only rely on Midlane Info!!\")\n\t\t\tif(Mid_low_Col < int(MidLane.shape[1]/2)): # MidLane on left side of Col/2 of image --> Bigger side is right side draw there\n\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt\n\t\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tDrawRight",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\t\tDrawRight = True\n\t\t# If Outerlane was present before and got EKIA: >>> DrawRight because it was Crossing LEFt\n\t\telse:\n\t\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\t\tprint(\"[FindClosestLane] IsPathCrossing = \",IsPathCrossing,\" IsCrossingLeft = \",IsCrossingLeft)\n\t\t\tif IsCrossingLeft: # trajectory from reflane to lane path is crossing midlane while moving left --> Draw Right\n\t\t\t\tDrawRight = True\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] DrawRight = \",DrawRight)\n\t\t#Offset Correction wil be set here to correct for the yellow lane not found ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tDrawRight",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\t\tDrawRight = True\n\t\tif (config.debugging_Lane and config.debugging and config.debugging_L_Cleaning):\n\t\t\tprint(\"[FindClosestLane] [OuterLanes is Empty] DrawRight = \",DrawRight)\n\t\t#Offset Correction wil be set here to correct for the yellow lane not found \n\t\t# IF we are drawing right then  we need to correct car to move right to find that outerlane\n\t\t# Else Move Left\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ D : Calculate Offset Correction\n\t\tif not DrawRight:\n\t\t\tlow_Col=0\n\t\t\thigh_Col=0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOffset_correction",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOffset_correction = -20\n\t\telse:\n\t\t\tlow_Col=(int(MidLane.shape[1])-1)\n\t\t\thigh_Col=(int(MidLane.shape[1])-1)\n\t\t\tOffset_correction = 20\n\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\t\tOffset_correction",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\t\tOffset_correction = 20\n\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP[1]",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tMid_lowP[1] = MidLane.shape[0]# setting mid_trajectory_lowestPoint_Row to MaxRows of Image\n\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tLanePoint_lower",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tLanePoint_lower =  (low_Col , int( Mid_lowP[1] ) )\n\t\tLanePoint_top   =  (high_Col, int( Mid_highP[1]) )\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ B : Draw OuterLAnes according to midlane information\n\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuterLanes",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuterLanes = cv2.line(OuterLanes,LanePoint_lower,LanePoint_top,255,1)\t\n\t\t# 4. [Midlane But , No OuterLanes!!!] _ C : Find OuterLane Contours\t\n\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "peekOfCode": "\t\tOuter_cnts = cv2.findContours(OuterLanes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction\n\t# 5. Condition 3 [No MidLane]\n\telse:\n\t\treturn OuterLanes, Outer_cnts, Mid_cnts, Offset_correction",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.CheckifYellowLaneCorrect_RetInnerBoundary",
        "documentation": {}
    },
    {
        "label": "ExtendShortLane",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "def ExtendShortLane(MidLane,Mid_cnts,Outer_cnts,OuterLane):\n\t# 1. Sorting the Mid and Outer Contours on basis of rows (Ascending)\n\tif(Mid_cnts and Outer_cnts):\t\t\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tImage_bottom",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tImage_bottom = MidLane.shape[0]\n\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tLane_Rows",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tLane_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tLane_Cols",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tLane_Cols = Mid_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tBottomPoint_Mid",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tBottomPoint_Mid = Mid_cnts_Rowsorted[Lane_Rows-1,:]\t\n\t\t# 2. Connect Midlane to imagebottom by drawing a Vertical line\n\t\tif (BottomPoint_Mid[1] < Image_bottom):\n\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\tMidLane",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\tMidLane = cv2.line(MidLane,tuple(BottomPoint_Mid),(BottomPoint_Mid[0],Image_bottom),255)\n\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tRefLane_Rows",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tRefLane_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tRefLane_Cols",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tRefLane_Cols = Outer_cnts_Rowsorted.shape[1]\n\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\tBottomPoint_Outer",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\tBottomPoint_Outer = Outer_cnts_Rowsorted[RefLane_Rows-1,:]\n\t\t# 3. Connect Outerlane to imagebottom by performing 2 steps if neccasary\n\t\tif (BottomPoint_Outer[1] < Image_bottom):\n\t\t\tif(RefLane_Rows>20):\n\t\t\t\tshift=20\n\t\t\telse:\n\t\t\t\tshift=2\n\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in\n\t\t\t#     the direction of that slope\t",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\tRefLast10Points",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\tRefLast10Points = Outer_cnts_Rowsorted[RefLane_Rows-shift:RefLane_Rows-1:2,:]\n\t\t\t# 3a. Connect Outerlane to imagebottom by Estimating its sloping and extending in\n\t\t\t#     the direction of that slope\t\n\t\t\tif(len(RefLast10Points)>1):# Atleast 2 points needed to estimate a line\n\t\t\t\tRef_x = RefLast10Points[:,0]#cols\n\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_x",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_x = RefLast10Points[:,0]#cols\n\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_y",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_y = RefLast10Points[:,1]#rows\n\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_parameters",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_parameters = np.polyfit(Ref_x, Ref_y, 1)\n\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_slope",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_slope = Ref_parameters[0]\n\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_yiCntercept",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_yiCntercept = Ref_parameters[1]\n\t\t\t\t#Decreasing slope means Current lane is left lane and by going towards 0 x we touchdown\n\t\t\t\tif(Ref_slope < 0):\n\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_col",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_col = 0\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_row",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_row = Ref_yiCntercept\n\t\t\t\telse:\n\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_col",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_col = OuterLane.shape[1]-1 # Cols have lenth of ColLength But traversal is from 0 to ColLength-1\n\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_LineTouchPoint_row",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_LineTouchPoint_row = Ref_slope * Ref_LineTouchPoint_col + Ref_yiCntercept\n\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_TouchPoint",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_TouchPoint = (Ref_LineTouchPoint_col,int(Ref_LineTouchPoint_row))#(col ,row)\n\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tRef_BottomPoint_tup",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tRef_BottomPoint_tup = tuple(BottomPoint_Outer)\n\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\tOuterLane",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_BottomPoint_tup,255)\n\t\t\t\t# 3b. Incase extended outerlane is still less then image bottom extend by\n\t\t\t\t#     drawing a vertical line\n\t\t\t\tif(Ref_LineTouchPoint_row < Image_bottom):\n\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tRef_TouchPoint_Ref",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tRef_TouchPoint_Ref = (Ref_LineTouchPoint_col,Image_bottom)\n\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")\n\treturn MidLane,OuterLane",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "\t\t\t\t\tOuterLane",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "peekOfCode": "\t\t\t\t\tOuterLane = cv2.line(OuterLane,Ref_TouchPoint,Ref_TouchPoint_Ref,255)\n\tif (config.debugging and config.debugging_Lane and config.debugging_L_Cleaning):\n\t\tcv2.imshow(\"[ExtendShortLane] OuterLanes\",OuterLane)\n\telse:\n\t\tcv2.destroyWindow(\"[ExtendShortLane] OuterLanes\")\n\treturn MidLane,OuterLane",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.c_Cleaning.ExtendLanesAndRefineMidLaneEdge",
        "documentation": {}
    },
    {
        "label": "EstimateNonMidMask",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def EstimateNonMidMask(MidEdgeROi):\n\tMid_Hull_Mask = np.zeros((MidEdgeROi.shape[0], MidEdgeROi.shape[1], 1), dtype=np.uint8)\n\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "LanePoints",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "FetchInfoAndDisplay",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "def FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge\n\t\tMid_lane (numpy_1d_array): estimated midlane [mask]\n\t\tOuter_Lane (numpy_1d_array): detected outerlane (closest side) [mask]\n\t\tframe (numpy_3d_array): Prius front-cam view (BGR)\n\t\tOffset_correction (int): offset to apply to computed lane information [incase either\n\t\t                            midlane or outerlane was missing or removed (false-positives)]\n\tReturns:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tMid_Hull_Mask",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tMid_Hull_Mask = np.zeros((MidEdgeROi.shape[0], MidEdgeROi.shape[1], 1), dtype=np.uint8)\n\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tcontours",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tcontours = cv2.findContours(MidEdgeROi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif contours:\n\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\thull_list",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\thull_list = []\n\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tcontours",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tcontours = np.concatenate(contours)\n\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\thull",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\thull = cv2.convexHull(contours)\n\t\thull_list.append(hull)\n\t\t# Draw contours + hull results\n\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Hull_Mask",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_Hull_Mask = cv2.drawContours(Mid_Hull_Mask, hull_list, 0, 255,-1)\n\t\t#cv2.namedWindow(\"Mid_Hull_Mask\",cv2.WINDOW_NORMAL)\n\t\t#cv2.imshow(\"Mid_Hull_Mask\",Mid_Hull_Mask)\n\tNon_Mid_Mask=cv2.bitwise_not(Mid_Hull_Mask)\n\treturn Non_Mid_Mask\ndef LanePoints(MidLane,OuterLane,Offset_correction):\n\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tMid_cnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tMid_cnts = cv2.findContours(MidLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tOuter_cnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tOuter_cnts = cv2.findContours(OuterLane, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n\tif(Mid_cnts and Outer_cnts):\n\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_cnts_Rowsorted",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_cnts_Rowsorted = Cord_Sort(Mid_cnts,\"rows\")\n\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_cnts_Rowsorted",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_cnts_Rowsorted = Cord_Sort(Outer_cnts,\"rows\")\n\t\t#print(Mid_cnts_Rowsorted)\n\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_Rows",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_Rows = Mid_cnts_Rowsorted.shape[0]\n\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_Rows",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_Rows = Outer_cnts_Rowsorted.shape[0]\n\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lowP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_lowP = Mid_cnts_Rowsorted[Mid_Rows-1,:]\n\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_highP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_highP = Mid_cnts_Rowsorted[0,:]\n\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_lowP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_lowP = Outer_cnts_Rowsorted[Outer_Rows-1,:]\n\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOuter_highP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOuter_highP = Outer_cnts_Rowsorted[0,:]\n\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLanePoint_lower",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLanePoint_lower = ( int( (Mid_lowP[0] + Outer_lowP[0]  ) / 2 ) + Offset_correction, int( (Mid_lowP[1]  + Outer_lowP[1] ) / 2 ) )\n\t\tLanePoint_top   = ( int( (Mid_highP[0] + Outer_highP[0]) / 2 ) + Offset_correction, int( (Mid_highP[1] + Outer_highP[1]) / 2 ) )\n\t\treturn LanePoint_lower,LanePoint_top\n\telse:\n\t\treturn (0,0),(0,0)\ndef FetchInfoAndDisplay(Mid_lane_edge,Mid_lane,Outer_Lane,frame,Offset_correction):\n\t\"\"\"Extracts the required data from the detected lane lines (outer and middle)\n\tArgs:\n\t\tMidEdgeROi (numpy_1d_array): detected midlane edge\n\t\tMid_lane (numpy_1d_array): estimated midlane [mask]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tTraj_lowP,Traj_upP",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tTraj_lowP,Traj_upP = LanePoints(Mid_lane,Outer_Lane,Offset_correction)\n    # 2. Compute Distance and Curvature from Trajectory Points \n\tPerpDist_LaneCentralStart_CarNose= -1000\n\tif(Traj_lowP!=(0,0)):\n\t\tPerpDist_LaneCentralStart_CarNose = Traj_lowP[0] - int(Mid_lane.shape[1]/2)\n\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tPerpDist_LaneCentralStart_CarNose",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tPerpDist_LaneCentralStart_CarNose = Traj_lowP[0] - int(Mid_lane.shape[1]/2)\n\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane_edge\")\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane \")\n\t\t# 3. Keep only those edge that are part of MIDLANE",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\tcurvature",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\tcurvature = findlaneCurvature(Traj_lowP[0],Traj_lowP[1],Traj_upP[0],Traj_upP[1])\n\tif config.Testing:\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane_edge\",Mid_lane_edge)\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_lane \",Mid_lane)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane_edge\")\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_lane \")\n\t\t# 3. Keep only those edge that are part of MIDLANE\n\t\tMid_lane_edge = cv2.bitwise_and(Mid_lane_edge,Mid_lane)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_lane_edge",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_lane_edge = cv2.bitwise_and(Mid_lane_edge,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Trash Removed (Mid_lane_edge) \",Mid_lane_edge)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Trash Removed (Mid_lane_edge) \")\n\t\t# 4. Combine Mid and OuterLane to get Lanes Combined\n\t\tLanes_combined = cv2.bitwise_or(Outer_Lane,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Lanes_combined\",Lanes_combined)\n\t\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLanes_combined",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLanes_combined = cv2.bitwise_or(Outer_Lane,Mid_lane)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Lanes_combined\",Lanes_combined)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Lanes_combined\")\n\t\t#Creating an empty image\n\t\tProjectedLane = np.zeros(Lanes_combined.shape,Lanes_combined.dtype)\n\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tProjectedLane",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tProjectedLane = np.zeros(Lanes_combined.shape,Lanes_combined.dtype)\n\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:\n\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tcnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tcnts = cv2.findContours(Lanes_combined,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[1]\n\t\t# 5. Fill ProjectedLane with fillConvexPoly\n\t\tif cnts:\n\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcnts = np.concatenate(cnts)\n\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")\n\t\t# 6. Extract MidlessMask from MidLaneEdge\n\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcnts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcnts = np.array(cnts)\n\t\t\tcv2.fillConvexPoly(ProjectedLane, cnts, 255)\n\t\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] ProjectedLane\",ProjectedLane)\n\t\t\telse:\n\t\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] ProjectedLane\")\n\t\t# 6. Extract MidlessMask from MidLaneEdge\n\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_less_Mask \",Mid_less_Mask)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tMid_less_Mask",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tMid_less_Mask = EstimateNonMidMask(Mid_lane_edge)\n\t\tif (config.debugging and config.debugging_Lane and config.debugging_L_LaneInfoExtraction):\n\t\t\tcv2.imshow(\"[FetchInfoAndDisplay] Mid_less_Mask \",Mid_less_Mask)\n\t\telse:\n\t\t\tcv2.destroyWindow(\"[FetchInfoAndDisplay] Mid_less_Mask \")\n\t\t# 7. Remove Midlane_Region from ProjectedLane\n\t\tProjectedLane = cv2.bitwise_and(Mid_less_Mask,ProjectedLane)\n\t\t# copy where we'll assign the new values\n\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tProjectedLane",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tProjectedLane = cv2.bitwise_and(Mid_less_Mask,ProjectedLane)\n\t\t# copy where we'll assign the new values\n\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane\n\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame = frame\n\t\t# 8. Draw projected lane\n\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[ProjectedLane==255]",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[ProjectedLane==255] = Lane_drawn_frame[ProjectedLane==255] + (0,100,0)\n\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[Outer_Lane==255]",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[Outer_Lane==255] = Lane_drawn_frame[Outer_Lane==255] + (0,0,100)# Outer Lane Coloured Red\n\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tLane_drawn_frame[Mid_lane==255]",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tLane_drawn_frame[Mid_lane==255] = Lane_drawn_frame[Mid_lane==255] + (100,0,0)# Mid Lane Coloured Blue\n\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature \n\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\tOut_image",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\tOut_image = Lane_drawn_frame\n\t\t# 9. Draw Cars direction and Lanes direction\n\t\tcv2.line(Out_image,(int(Out_image.shape[1]/2),Out_image.shape[0]),(int(Out_image.shape[1]/2),Out_image.shape[0]-int (Out_image.shape[0]/5)),(0,0,255),2)\n\t\tcv2.line(Out_image,Traj_lowP,Traj_upP,(255,0,0),2)\n\t\tif(Traj_lowP!=(0,0)):\n\t\t\tcv2.line(Out_image,Traj_lowP,(int(Out_image.shape[1]/2),Traj_lowP[1]),(255,255,0),2)# distance of car center with lane path\n\t\tif (config.debugging and config.debugging_Lane):\n\t\t\t# 10. Draw extracted distance and curvature \n\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"\n\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tcurvature_str=\"Curvature",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tcurvature_str=\"Curvature = \" + f\"{curvature:.2f}\"\n\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)\n\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\tPerpDist_ImgCen_CarNose_str=\"Distance = \" + str(PerpDist_LaneCentralStart_CarNose)\n\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "\t\t\ttextSize_ratio",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "peekOfCode": "\t\t\ttextSize_ratio = 0.5\n\t\t\tcv2.putText(Out_image,curvature_str,(10,30),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\t\t\tcv2.putText(Out_image,PerpDist_ImgCen_CarNose_str,(10,50),cv2.FONT_HERSHEY_DUPLEX,textSize_ratio,(0,255,255),1)\n\treturn PerpDist_LaneCentralStart_CarNose,curvature",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.d_LaneInfo_Extraction.GetStateInfoandDisplayLane",
        "documentation": {}
    },
    {
        "label": "detect_Lane",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Lane_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Lane_Detection",
        "peekOfCode": "def detect_Lane(img):\n        \"\"\" Extract required data from the lane lines representing road lane boundaries.\n        Args:\n                img (numpy nd array): Prius front-cam view\n        Returns:\n                distance    (int): car_front <===distance===> ideal position on road \n                curvature (angle): car <===angle===> roads_direction\n                                e.g. car approaching a right turn so road direction is around or less then 45 deg\n                                                                                cars direction is straight so it is around 90 deg\n        \"\"\"          ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Lane_Detection",
        "documentation": {}
    },
    {
        "label": "BwareaOpen",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def BwareaOpen(img,MinArea):\n    thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY)[1]\n    # Filter using contour area and remove small noise\n    cnts = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    cnts_TooSmall = []\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)\n        if area < MinArea:\n            cnts_TooSmall.append(cnt)\n    thresh = cv2.drawContours(thresh, cnts_TooSmall, -1, 0, -1) # [ contour = less then minarea contour, contourIDx, Colour , Thickness ]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "FindExtremas",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def FindExtremas(img):\n    positions = np.nonzero(img) # position[0] 0 = rows 1 = cols\n    if (len(positions)!=0):\n        top = positions[0].min()\n        bottom = positions[0].max()\n        left = positions[1].min()\n        right = positions[1].max()\n        return top,bottom\n    else:\n        return 0,0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "FindLowestRow",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def FindLowestRow(img):\n    positions = np.nonzero(img) # position[0] 0 = rows 1 = cols\n    if (len(positions)!=0):\n        top = positions[0].min()\n        bottom = positions[0].max()\n        left = positions[1].min()\n        right = positions[1].max()\n        return bottom\n    else:\n        return img.shape[0]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "RetLargestContour",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def RetLargestContour(gray):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "RetLargestContour_OuterLane",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def RetLargestContour_OuterLane(gray,minArea):\n    LargestContour_Found = False\n    thresh=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n    #################################### TESTING SHADOW BREAKER CODE BY DILATING####################\n    # 3. Dilating Segmented ROI's\n    kernel = cv2.getStructuringElement(shape=cv2.MORPH_ELLIPSE, ksize=(5,5))\n    bin_img_dilated = cv2.morphologyEx(bin_img, cv2.MORPH_DILATE, kernel)    #Find the two Contours for which you want to find the min distance between them.\n    bin_img_ret = cv2.morphologyEx(bin_img_dilated, cv2.MORPH_ERODE, kernel)    #Find the two Contours for which you want to find the min distance between them.\n    bin_img = bin_img_ret",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ROI_extracter",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def ROI_extracter(image,strtPnt,endPnt):\n    #  Selecting Only ROI from Image\n    ROI_mask = np.zeros(image.shape, dtype=np.uint8)\n    cv2.rectangle(ROI_mask,strtPnt,endPnt,255,thickness=-1)\n    #image_ROI = cv2.bitwise_and(image,image,mask=ROI_mask)\n    image_ROI = cv2.bitwise_and(image,ROI_mask)\n    return image_ROI\ndef ExtractPoint(img,specified_row):\n    Point= (0,specified_row)\n    specified_row_data = img[ specified_row-1,:]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ExtractPoint",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def ExtractPoint(img,specified_row):\n    Point= (0,specified_row)\n    specified_row_data = img[ specified_row-1,:]\n    #print(\"specified_row_data\",specified_row_data)\n    positions = np.nonzero(specified_row_data) # position[0] 0 = rows 1 = cols\n    #print(\"positions\",positions)    \n    #print(\"len(positions[0])\",len(positions[0]))    \n    if (len(positions[0])!=0):\n        #print(positions[0])\n        min_col = positions[0].min()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Ret_LowestEdgePoints",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def Ret_LowestEdgePoints(gray):\n    Outer_Points_list=[]\n    thresh = np.zeros(gray.shape,dtype=gray.dtype)\n    Lane_OneSide=np.zeros(gray.shape,dtype=gray.dtype)\n    Lane_TwoSide=np.zeros(gray.shape,dtype=gray.dtype)\n    _,bin_img = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)\n        #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    thresh = cv2.drawContours(thresh, cnts, 0, (255,255,255), 1) # [ contour = less then minarea contour, contourIDx, Colour , Thickness ]\n    # Boundary of the Contour is extracted and Saved in Thresh",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "ApproxDistBWCntrs",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def ApproxDistBWCntrs(cnt,cnt_cmp):\n    # compute the center of the contour\n    M = cv2.moments(cnt)\n    cX = int(M[\"m10\"] / M[\"m00\"])\n    cY = int(M[\"m01\"] / M[\"m00\"])\n    # compute the center of the contour\n    M_cmp = cv2.moments(cnt_cmp)\n    cX_cmp = int(M_cmp[\"m10\"] / M_cmp[\"m00\"])\n    cY_cmp = int(M_cmp[\"m01\"] / M_cmp[\"m00\"])\n    minDist=Distance_((cX,cY),(cX_cmp,cY_cmp))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Estimate_MidLane",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "peekOfCode": "def Estimate_MidLane(BW,MaxDistance):\n    #cv2.namedWindow(\"BW_zero\",cv2.WINDOW_NORMAL)\n    BW_zero= cv2.cvtColor(BW,cv2.COLOR_GRAY2BGR)\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts= cv2.findContours(BW, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[1]#3ms\n    MinArea=1\n    cnts_Legit=[]\n    for index, _ in enumerate(cnts):\n        area = cv2.contourArea(cnts[index])\n        if area > MinArea:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.Morph_op",
        "documentation": {}
    },
    {
        "label": "Distance",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def Distance(a,b):\n    a_y = a[0,0]\n    a_x = a[0,1]\n    b_y = b[0,0]\n    b_x = b[0,1]\n    distance = math.sqrt( ((a_x-b_x)**2)+((a_y-b_y)**2) )\n    return distance\ndef Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef findlaneCurvature(x1,y1,x2,y2):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "Distance_",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def Distance_(a,b):\n    return math.sqrt( ( (a[1]-b[1])**2 ) + ( (a[0]-b[0])**2 ) )\ndef findlaneCurvature(x1,y1,x2,y2):\n    offset_Vert=90# angle found by tan-1 (slop) is wrt horizontal --> This will shift to wrt Vetical\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n        anlgeOfinclination = math.atan(slope) * (180 / np.pi)#Conversion to degrees\n    else:\n        slope=1000#infinity",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "findlaneCurvature",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def findlaneCurvature(x1,y1,x2,y2):\n    offset_Vert=90# angle found by tan-1 (slop) is wrt horizontal --> This will shift to wrt Vetical\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n        anlgeOfinclination = math.atan(slope) * (180 / np.pi)#Conversion to degrees\n    else:\n        slope=1000#infinity\n        y_intercept=0#None [Line never crosses the y axis]\n        anlgeOfinclination = 90#vertical line",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "findLineParameter",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def findLineParameter(x1,y1,x2,y2):\n    if((x2-x1)!=0):\n        slope = (y2-y1)/(x2-x1)\n        y_intercept = y2 - (slope*x2) #y= mx+c\n    else:\n        slope=1000\n        y_intercept=0\n        #print(\"Vertical Line [Undefined slope]\")\n    return (slope,y_intercept)\ndef Cord_Sort(cnts,order):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "Cord_Sort",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def Cord_Sort(cnts,order):\n    if cnts:\n        cnt=cnts[0]\n        cnt=np.reshape(cnt,(cnt.shape[0],cnt.shape[2]))\n        order_list=[]\n        if(order==\"rows\"):\n            order_list.append((0,1))\n        else:\n            order_list.append((1,0))\n        ind = np.lexsort((cnt[:,order_list[0][0]],cnt[:,order_list[0][1]]))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "average_2b_",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "peekOfCode": "def average_2b_(Edge_ROI):\n    #First Threshold data\n    TrajectoryOnEdge = np.copy(Edge_ROI)\n    row = Edge_ROI.shape[0] # Shape = [row, col, channels]\n    col = Edge_ROI.shape[1]\n    Lane_detected = np.zeros(Edge_ROI.shape,dtype = Edge_ROI.dtype)\n    Edge_Binary = Edge_ROI > 0\n    Edge_Binary_nz_pix = np.where(Edge_Binary)\n    x_len = Edge_Binary_nz_pix[0].shape[0]\n    if(Edge_Binary_nz_pix[0].shape[0]):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Lanes.utilities",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''\n    global NUM_CATEGORIES\n    images = list()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "train_SignsModel",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def train_SignsModel(data_dir,IMG_HEIGHT = 30,IMG_WIDTH = 30,EPOCHS = 30, save_model = True,saved_model = \"data/saved_model_Ros2_5_Sign.h5\"):\n    train_path = data_dir + '/Train_Ros2'\n    global NUM_CATEGORIES\n    # Number of Classes\n    NUM_CATEGORIES = len(os.listdir(train_path))\n    print(\"NUM_CATEGORIES = \" , NUM_CATEGORIES)\n    # Visualizing all the different Signs\n    img_dir = pathlib.Path(train_path)\n    plt.figure(figsize=(14,14))\n    index = 0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "EvaluateModelOnImage",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def EvaluateModelOnImage(model_path,image_path,image_label):\n    # load model\n    model = load_model(model_path)\n    # summarize model.\n    model.summary()\n    # load dataset\n    # split into input (X) and output (Y) variables\n    output = []\n    image = load_img(image_path, target_size=(30, 30))\n    output.append(np.array(image))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "def main():\n    if Training_CNN:\n        train_SignsModel(\"D:/Ros2SelfDrivingCar/Ros2_SDC/data/dataset_signs\")\nif __name__ == '__main__':\n\tmain()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "Training_CNN",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "Training_CNN = True\nNUM_CATEGORIES = 0\ndef load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "NUM_CATEGORIES",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "peekOfCode": "NUM_CATEGORIES = 0\ndef load_data(data_dir):\n    '''\n    Loading data from Train folder.\n    Returns a tuple `(images, labels)` , where `images` is a list of all the images in the train directory,\n    where each image is formatted as a numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. \n    `labels` is a list of integer labels, representing the categories for each of the\n    corresponding `images`.\n    '''\n    global NUM_CATEGORIES",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.CNN",
        "documentation": {}
    },
    {
        "label": "SignTracking",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "class SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))\n    known_centers = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "image_forKeras",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n    max_rad = 150 # smaller circles dont have enough votes so only maxRadius need to be controlled ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "SignDetection",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n    max_rad = 150 # smaller circles dont have enough votes so only maxRadius need to be controlled \n                    # As signs are right besides road so they will eventually be in view so ignore circles larger than said limit\n    circles = cv2.HoughCircles(gray,cv2.HOUGH_GRADIENT,1,mindDistanBtwnCircles,param1=CannyHighthresh,param2=NumOfVotesForCircle,minRadius=10,maxRadius=max_rad)\n    if circles is not None:\n        circles = np.uint16(np.around(circles))\n        for i in circles[0,:]:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "detect_Signs",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "def detect_Signs(frame,frame_draw):\n    global model_loaded\n    if not model_loaded:\n        print(tf.__version__)#2.4.1\n        print(\"************ LOADING MODEL **************\")\n        global model\n        # load model\n        model = load_model(os.path.abspath('data/saved_model.h5'),compile=False)\n        # summarize model.\n        model.summary()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "detected_img",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "detected_img = 0 #Set this to current dataset images size so that new images number starts from there and dont overwrite\nif config.Detect_lane_N_Draw:\n    write_data = False\nelse:\n    write_data = True\ndraw_detected = True\ndisplay_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "draw_detected",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "draw_detected = True\ndisplay_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "display_images",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "display_images = False\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "model_loaded",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "model_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "model = 0\nsign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "sign_classes",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "sign_classes = [\"speed_sign_70\",\"speed_sign_80\",\"stop\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "signTrack",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "peekOfCode": "signTrack = SignTracking()\ndef image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection(gray,cimg,frame_draw,model):\n    NumOfVotesForCircle = 40 #parameter 1 MinVotes needed to be classified as circle\n    CannyHighthresh = 200 # High threshold value for applying canny\n    mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Classification_CNN",
        "documentation": {}
    },
    {
        "label": "Vis_CNN",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "peekOfCode": "def Vis_CNN(model):\n    font = ImageFont.truetype(\"arial.ttf\", 24)  # using comic sans is strictly prohibited!\n    model.add(visualkeras.SpacingDummyLayer(spacing=100))\n    visualkeras.layered_view(model, to_file='self_driving_car_pkg/self_driving_car_pkg/data/Vis_CNN.png',legend=True, font=font,scale_z=2).show()  # font is optional!\ndef main():\n    model = load_model(os.path.abspath('self_driving_car_pkg/self_driving_car_pkg/data/saved_model_5_Sign.h5'),compile=False)\n    Vis_CNN(model)\nif __name__ == '__main__':\n\tmain()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "peekOfCode": "def main():\n    model = load_model(os.path.abspath('self_driving_car_pkg/self_driving_car_pkg/data/saved_model_5_Sign.h5'),compile=False)\n    Vis_CNN(model)\nif __name__ == '__main__':\n\tmain()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.Classification.Visualize_CNN",
        "documentation": {}
    },
    {
        "label": "SignTracking",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "class SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))\n    known_centers = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "image_forKeras",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)\n        NumOfVotesForCircle = 32 #parameter 1 MinVotes needed to be classified as circle",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "SignDetection_Nd_Tracking",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)\n        NumOfVotesForCircle = 32 #parameter 1 MinVotes needed to be classified as circle\n        CannyHighthresh = 250 # High threshold value for applying canny\n        mindDistanBtwnCircles = 100 # kept as sign will likely not be overlapping\n        max_rad = 140 # smaller circles dont have enough votes so only maxRadius need to be controlled \n                        # As signs are right besides road so they will eventually be in view so ignore circles larger than said limit\n        # 4. Detection (Localization)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "detect_Signs",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "def detect_Signs(frame,frame_draw):\n    \"\"\"Extract required data from the traffic signs on the road\n    Args:\n        frame (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected signs\n    Returns:\n        string: Current mode of signtracker class\n        string: detected speed sign (e.g speed sign 70)\n    \"\"\"    \n    global model_loaded",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "detected_img",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "detected_img = 1000 #Set this to current dataset images size so that new images number starts from there and dont overwrite\n#if config.Detect_lane_N_Draw:\n#    write_data = False # not gathering data # No Training\n#else:\n#    write_data = True\nif config.Training_CNN:\n    write_data = True\nelse:\n    write_data = False # not gathering data # No Training\ndraw_detected = True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "draw_detected",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "draw_detected = True\nmodel_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "model_loaded",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "model_loaded = False\nmodel = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "model = 0\nsign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "sign_classes",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "sign_classes = [\"speed_sign_30\",\"speed_sign_60\",\"speed_sign_90\",\"stop\",\"left_turn\",\"No_Sign\"] # Trained CNN Classes\nclass SignTracking:\n    def __init__(self):\n        print(\"Initialized Object of signTracking class\")\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors\n    color = np.random.randint(0, 255, (100, 3))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "signTrack",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "peekOfCode": "signTrack = SignTracking()\ndef image_forKeras(image):\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)# Image everywher is in rgb but Opencv does it in BGR convert Back\n    image = cv2.resize(image,(30,30)) #Resize to model size requirement\n    image = np.expand_dims(image, axis=0) # Dimension of model is [Batch_size, input_row,inp_col , inp_chan]\n    return image\ndef SignDetection_Nd_Tracking(gray,cimg,frame_draw,model):\n    # 3. IF Mode of SignTrack is Detection , Proceed\n    if (signTrack.mode == \"Detection\"):\n        # cv2.putText(frame_draw,\"Sign Detected ==> \"+str(signTrack.Tracked_class),(20,85),cv2.FONT_HERSHEY_COMPLEX,0.75,(255,255,0),2)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.Signs.SignDetectionApi",
        "documentation": {}
    },
    {
        "label": "Segment_On_Clr",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class Segment_On_Clr:\n    def __init__(self, a_1 = 56,a_2 = 66,a_3 = 41,a_4 = 23, b_1 = 0,b_2 = 8,b_3 = 33,b_4 = 23):\n        self.HLS = 0\n        self.src = 0\n        self.Hue_Low_G  = a_1\n        self.Hue_High_G = a_2\n        self.Lit_Low_G  = a_3\n        self.Sat_Low_G  = a_4\n        self.Hue_Low_R  = b_1\n        self.Hue_High_R = b_2",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_States",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class TL_States:\n    def __init__(self):\n        # Instance Variables\n        self.detected_circle = 0 \n        self.Traffic_State = \"Unknown\"\n        self.prevTraffic_State = 0\n        self.write_data = False\n        self.draw_detected = True\n        self.display_images = True\n        self.HLS = 0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Cascade_Detector",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class Cascade_Detector:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of Cascade_Detector class\")\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(os.getcwd(), \"self_driving_car_pkg/self_driving_car_pkg/data/TrafficLight_cascade.xml\")\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):\n        print('--(!)Error loading face cascade')",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_Tracker",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "class TL_Tracker:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of signTracking class\")\n    # Class Variables\n    mode = \"Detection\"\n    max_allowed_dist = 100\n    feature_params = dict(maxCorners=100,qualityLevel=0.3,minDistance=7,blockSize=7)\n    lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10, 0.03))  \n    # Create some random colors",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "detect_TrafficLights",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "def detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light\n    \"\"\"    \n    Curr_TL_State = \"Unknown\"",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_States_",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "TL_States_ = TL_States()\nclass Cascade_Detector:\n    def __init__(self):\n        # Instance Variables\n        print(\"Initialized Object of Cascade_Detector class\")\n    # Class Variables\n    TrafficLight_cascade_str = os.path.join(os.getcwd(), \"self_driving_car_pkg/self_driving_car_pkg/data/TrafficLight_cascade.xml\")\n    TrafficLight_cascade = cv2.CascadeClassifier()\n    #-- 1. Load the cascades\n    if not TrafficLight_cascade.load(cv2.samples.findFile(TrafficLight_cascade_str)):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "cascade_detector",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "cascade_detector = Cascade_Detector()\nTL_Track = TL_Tracker()\nSegment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "TL_Track",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "TL_Track = TL_Tracker()\nSegment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Segment_On_Clr_",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "peekOfCode": "Segment_On_Clr_ = Segment_On_Clr()\ndef detect_TrafficLights(img,frame_draw):\n    \"\"\" Detect Traffic light (If-Present) and retrieve its state\n    Args:\n        img (numpy nd array): Prius front-cam view\n        frame_draw (numpy nd array): for displaying detected traffic light\n    Returns:\n        (String): State of the Traffic Light (Red | Green | Unknown) [Unknown: No Traffic Light found!]\n        (bool): SDC <== Close enough? ==> Traffic Light\n    \"\"\"    ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Detection.TrafficLights.TrafficLights_Detection",
        "documentation": {}
    },
    {
        "label": "Navigator",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.Navigation",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.Navigation",
        "peekOfCode": "class Navigator():\n    def __init__(self):\n        # Creating objects for each stage of the robot navigation\n        self.bot_localizer = bot_localizer()\n        self.bot_mapper = bot_mapper()\n        self.bot_pathplanner = bot_pathplanner()\n        self.bot_motionplanner = bot_motionplanner()\n        self.debugging = Debugging()\n        # [NEW]: Boolean to determine if we are taking destination from user or not\n        self.accquiring_destination = True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.Navigation",
        "documentation": {}
    },
    {
        "label": "bot_localizer",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_localization",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_localization",
        "peekOfCode": "class bot_localizer():\n    def __init__(self):\n        # State Variables\n        self.is_bg_extracted =False\n        # Output Variables [BG_model,Refrence_Maze,Rel_Loc_of_car]\n        self.bg_model = []\n        self.maze_og = []\n        self.loc_car = 0\n        # Transfomation(Crop + Rotated) Variables\n        self.orig_X = 0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_localization",
        "documentation": {}
    },
    {
        "label": "Graph",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "class Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0\n    # function to add new vertex to graph\n    # if neighbor == None  Just add vertex\n    #      Otherwise add connection",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "bot_mapper",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "class bot_mapper():\n    def __init__(self):\n        # State Variables\n        self.graphified = False\n        # Cropping control for removing maze boundary\n        self.crp_amt = 5\n        # Creating a graph object for storing Maze\n        self.Graph = Graph()\n        # State variables to define the connection status of each vertex\n        self.connected_left = False",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "draw_intrstpts",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "draw_intrstpts = True\ndebug_mapping = False\n# Creating Graph Class to store IP and their connected paths\nclass Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "debug_mapping",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "peekOfCode": "debug_mapping = False\n# Creating Graph Class to store IP and their connected paths\nclass Graph():\n    def __init__(self):\n        # Dictionary to store graph\n        self.graph = {}\n        # Placeholder for start and end of graph\n        self.start = 0\n        self.end = 0\n    # function to add new vertex to graph",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_mapping",
        "documentation": {}
    },
    {
        "label": "bot_motionplanner",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_motionplanning",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_motionplanning",
        "peekOfCode": "class bot_motionplanner():\n    def __init__(self):\n        # counter to move car forward for a few iterations\n        self.count = 0\n        # State Variable => Initial Point Extracted?\n        self.pt_i_taken = False\n        # [Container] => Store Initial car location\n        self.init_loc = 0\n        # State Variable => Angle relation computed?\n        self.angle_relation_computed = False",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_motionplanning",
        "documentation": {}
    },
    {
        "label": "bot_pathplanner",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class bot_pathplanner():\n    def __init__(self):\n        self.DFS = DFS()\n        self.dijisktra = dijisktra()\n        self.astar = a_star()\n        self.path_to_goal = []\n        self.img_shortest_path = []\n        self.choosen_route = []\n    @staticmethod\n    def cords_to_pts(cords):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "DFS",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class DFS():\n    # A not so simple problem, \n    #    Lets try a recursive approach\n    @staticmethod\n    def get_paths(graph,start,end,path = []):\n        # Update the path to where ever you have been to\n        path = path + [start]\n        # 2) Define the simplest case\n        if (start == end):\n            return [path]",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "Heap",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class Heap():\n    def __init__(self):\n        # Priority queue will be stored in an array (list of list containing vertex and their resp distance)\n        self.array = []\n        # Counter to track nodes left in priority queue\n        self.size = 0\n        # Curr_pos of each vertex is stored\n        self.posOfVertices = []\n    # create a minheap node => List(vertex,distance)\n    def new_minHeap_node(self,v,dist):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "dijisktra",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class dijisktra():\n    def __init__(self):\n        # State variable \n        self.shortestpath_found = False\n        # Once found save the shortest path\n        self.shortest_path = []\n        self.shortest_path_overlayed = []\n        # instance variable assigned obj of heap class for implementing required priority queue\n        self.minHeap = Heap()\n        # Creating dictionaries to manage the world",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "a_star",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "peekOfCode": "class a_star(dijisktra):\n    def __init__(self):\n        super().__init__()\n        # Counter added to track total nodes visited to \n        #               reach goal node\n        self.astar_nodes_visited = 0\n    # Heuristic function ( One of the components required to compute total cost of any node ) \n    @staticmethod\n    def euc_d(a,b):\n        return sqrt( pow( (a[0]-b[0]),2 ) + pow( (a[1]-b[1]),2 ) )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.bot_pathplanning",
        "documentation": {}
    },
    {
        "label": "debug",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug = False\ndebug_localization = False\ndebug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_localization",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_localization = False\ndebug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_mapping",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_mapping = False\ndebug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_pathplanning",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_pathplanning = False\ndebug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_motionplanning",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_motionplanning = False\ndebug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_live",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_live = False\ndebug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_live_amount",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_live_amount = 0\ndebug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_map_live_amount",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_map_live_amount = 0\ndebug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "debug_path_live_amount",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "debug_path_live_amount = 0\n# [NEW]: Container to store destination_pt selected by User\ndestination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "destination",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "peekOfCode": "destination = []",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.config",
        "documentation": {}
    },
    {
        "label": "Debugging",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "class Debugging:\n    def __init__(self): \n       self.time_elasped = 0\n       self.Live_created = False\n    def nothing(self,x):\n        pass\n    cv2.namedWindow('CONFIG')\n    # create switch for ON/OFF functionality\n    debugging_SW = 'Debug'\n    cv2.createTrackbar(debugging_SW, 'CONFIG',False,True,nothing)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_largest_reg",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def ret_largest_reg(mask):\n    cnts = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[1]\n    max_cntr_pix = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        curr_cnt_pix = cnt.shape[0]\n        if curr_cnt_pix > max_cntr_pix:\n            max_cntr_pix = curr_cnt_pix\n            Max_Cntr_idx = index\n    largst_reg_mask = np.zeros_like(mask)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "disp_on_mydev",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def disp_on_mydev(screen,device=\"tablet\"):\n    resource_dir = \"self_driving_car_pkg/self_driving_car_pkg/GPS_Navigation/resource\"\n    device_path = os.path.join(resource_dir,device) + \".png\"\n    device_view = cv2.imread(device_path)\n    device_hls = cv2.cvtColor(device_view, cv2.COLOR_BGR2HLS)\n    # Case : If the screen is the middle is brighter then everything else\n    mask = cv2.inRange(device_hls, np.array([0,150,0]), np.array([255,255,255]))\n    largst_reg_cnt,largst_reg_mask = ret_largest_reg(mask)\n    [x,y,w,h] = cv2.boundingRect(largst_reg_cnt)\n    dsize = (screen.shape[1]+ (2*x), screen.shape[0]+(2*y))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "closest_node",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def closest_node(node, nodes):\n    nodes = np.asarray(nodes)\n    dist_2 = np.sum((nodes - node)**2, axis=(nodes.ndim-1))\n    return np.argmin(dist_2)\n# [NEW]: Find centroid of a contour\ndef get_centroid(cnt):\n    M = cv2.moments(cnt)\n    if M['m00']==0:\n        (cx,cy) = cv2.minEnclosingCircle(cnt)[0]        \n        return (int(cx),int(cy))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "get_centroid",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def get_centroid(cnt):\n    M = cv2.moments(cnt)\n    if M['m00']==0:\n        (cx,cy) = cv2.minEnclosingCircle(cnt)[0]        \n        return (int(cx),int(cy))\n    else:\n        cx = int(M['m10']/M['m00'])\n        cy = int(M['m01']/M['m00'])\n        return (cx,cy)\n# [NEW]: Update the destination to user selected location",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "click_event",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def click_event(event, x, y, flags, params):\n    # checking for left mouse clicks\n    if event == cv2.EVENT_LBUTTONDOWN:\n        # displaying the coordinates\n        # on the Shell\n        config.destination = (x,y)\n# [NEW]: Transform point to new Frame of Refrence [described by provided rot and translation tranformations]\ndef find_point_in_FOR(bot_cntr,transform_arr,rot_mat,cols,rows):\n        # b) Converting from point --> array to apply transforms\n        bot_cntr_arr =  np.array([bot_cntr[0],bot_cntr[1]])",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "find_point_in_FOR",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def find_point_in_FOR(bot_cntr,transform_arr,rot_mat,cols,rows):\n        # b) Converting from point --> array to apply transforms\n        bot_cntr_arr =  np.array([bot_cntr[0],bot_cntr[1]])\n        # c) Shift origin from sat_view -> maze\n        bot_cntr_translated = np.zeros_like(bot_cntr_arr)\n        bot_cntr_translated[0] = bot_cntr_arr[0] - transform_arr[0]\n        bot_cntr_translated[1] = bot_cntr_arr[1] - transform_arr[1]\n        # d) Applying rotation tranformation to bot_centroid to get bot location relative to maze\n        bot_on_maze = (rot_mat @ bot_cntr_translated.T).T\n        center_ = np.array([int(cols/2),int(rows/2)])",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "imfill",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def imfill(image):\n  cnts = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]# OpenCV 4.2\n  for idx,_ in enumerate(cnts):\n    cv2.drawContours(image, cnts, idx, 255,-1)\ndef ret_largest_obj(img):\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_largest_obj",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def ret_largest_obj(img):\n    #Find the two Contours for which you want to find the min distance between them.\n    cnts = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[1]\n    Max_Cntr_area = 0\n    Max_Cntr_idx= -1\n    for index, cnt in enumerate(cnts):\n        area = cv2.contourArea(cnt)\n        if area > Max_Cntr_area:\n            Max_Cntr_area = area\n            Max_Cntr_idx = index",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "ret_smallest_obj",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "peekOfCode": "def ret_smallest_obj(cnts, noise_thresh = 10):\n  Min_Cntr_area = 1000\n  Min_Cntr_idx= -1\n  for index, cnt in enumerate(cnts):\n      area = cv2.contourArea(cnt)\n      if (area < Min_Cntr_area) and (area > 10):\n          Min_Cntr_area = area\n          Min_Cntr_idx = index\n          SmallestContour_Found = True\n  print(\"min_area\" , Min_Cntr_area)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities",
        "documentation": {}
    },
    {
        "label": "overlay",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay(image,overlay_img):\n    gray = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n    mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)[1]\n    mask_inv = cv2.bitwise_not(mask)\n    roi = image\n    img2 = overlay_img\n    # Now black-out the area of logo in ROI\n    img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n    # Take only region of logo from logo image.\n    img2_fg = cv2.bitwise_and(img2,img2,mask = mask)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "overlay_cropped",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay_cropped(frame_disp,image_rot,crop_loc_row,crop_loc_col,overlay_cols):\n    image_rot_cols = image_rot.shape[1]\n    gray = cv2.cvtColor(image_rot[:,image_rot_cols-overlay_cols:image_rot_cols], cv2.COLOR_BGR2GRAY)\n    mask = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY)[1]\n    mask_inv = cv2.bitwise_not(mask)\n    frame_overlay_cols = crop_loc_col + image_rot_cols\n    roi = frame_disp[crop_loc_row:crop_loc_row + image_rot.shape[0],frame_overlay_cols-overlay_cols:frame_overlay_cols]            \n    img2 = image_rot[:,image_rot_cols-overlay_cols:image_rot_cols]\n    # Now black-out the area of logo in ROI\n    img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "overlay_live",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def overlay_live(frame_disp,overlay,overlay_map,overlay_path,transform_arr,crp_amt):\n    overlay_rot = cv2.rotate(overlay, cv2.ROTATE_90_CLOCKWISE)\n    map_rot = cv2.rotate(overlay_map, cv2.ROTATE_90_CLOCKWISE)\n    image_rot = cv2.rotate(overlay_path, cv2.ROTATE_90_CLOCKWISE)\n    crop_loc_col = transform_arr[0]+crp_amt\n    #crop_loc_endCol = transform_arr[0]+transform_arr[2]+crp_amt\n    crop_loc_row = transform_arr[1]+crp_amt\n    new_cols = int(overlay_rot.shape[1]*config.debug_live_amount)\n    new_path_cols = int(overlay_rot.shape[1]*config.debug_path_live_amount)\n    new_map_cols = int(overlay_rot.shape[1]*config.debug_map_live_amount)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "draw_bot_speedo",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def draw_bot_speedo(image,bot_speed,bot_turning):\n    height, width = image.shape[0:2]\n    # Ellipse parameters\n    radius = 50\n    center = (int(width / 2), height - 25)\n    axes = (radius, radius)\n    angle = 0\n    startAngle = 180\n    endAngle = 360\n    thickness = 10",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "disp_SatNav",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "peekOfCode": "def disp_SatNav(frame_disp,sbot_view,bot_curr_speed,bot_curr_turning,maze_interestPts,choosen_route,img_choosen_route,transform_arr,crp_amt):\n    # View bot view on left to frame Display\n    bot_view = cv2.resize(sbot_view,None,fx=0.95,fy=0.95)\n    # Draw & Display [For better Understanding of current robot state]\n    center_frame_disp = int(frame_disp.shape[0]/2)\n    center_bot_view = int(bot_view.shape[0]/4)\n    bot_offset = frame_disp.shape[0] - bot_view.shape[0] - 25\n    center_img_shortest_path = int(img_choosen_route.shape[0]/2)\n    isp_offset = center_frame_disp - center_img_shortest_path\n    bot_view = draw_bot_speedo(bot_view,bot_curr_speed,bot_curr_turning)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.GPS_Navigation.utilities_disp",
        "documentation": {}
    },
    {
        "label": "detect",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "detect = 1 # Set to 1 for Lane detection\nTesting = True# Set to True --> if want to see what the car is seeing\nProfiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Testing",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Testing = True# Set to True --> if want to see what the car is seeing\nProfiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Profiling",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Profiling = False # Set to True --> If you want to profile code\nwrite = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "write",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "write = False # Set to True --> If you want to Write input / output videos\nIn_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "In_write",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "In_write = False\nOut_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Out_write",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Out_write = False\ndebugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging = True # Set to True --> If you want to debug code\ndebugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_Lane",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_Lane = True\ndebugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_L_ColorSeg",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_L_ColorSeg = True\ndebugging_L_Est= True\ndebugging_L_Cleaning= True\ndebugging_L_LaneInfoExtraction= True\ndebugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_Signs",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_Signs = True\ndebugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_TrafficLights",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_TrafficLights = True\ndebugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "debugging_TL_Config",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "debugging_TL_Config = True\n# Adding functionality to toggle Sat_Nav on/off\nenable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "enable_SatNav",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "enable_SatNav = False\n# [NEW]: Control switch to turn steering animation on/off\nanimate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "animate_steering",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "animate_steering = False\n# [NEW]: Containers to store the orignal vs Smoothed steering angle for visualizing the effect\nangle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False ",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "angle_orig",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "angle_orig = 0\nangle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "angle",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "angle = 0\n# adding engines on/off control \nengines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "engines_on",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "engines_on = False\n# adding clr_seg_dbg control to create trackbars only once \nclr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "clr_seg_dbg_created",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "clr_seg_dbg_created = False\nDetect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Detect_lane_N_Draw",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Detect_lane_N_Draw = True\nTraining_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Training_CNN",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Training_CNN = False \nvid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "vid_path",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "vid_path = os.path.abspath(\"data/vids/Ros2/lane.avi\")\nloopCount=0\nResized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Resized_width",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Resized_width = 320#320#240#640#320 # Control Parameter\nResized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Resized_height",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Resized_height = 240#240#180#480#240\nin_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920\nRef_imgHeight = 1080",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "in_q",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "in_q = cv2.VideoWriter( os.path.abspath(\"data/Output/in_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nout  = cv2.VideoWriter( os.path.abspath(\"data/Output/out_new.avi\") , cv2.VideoWriter_fourcc('M','J','P','G'), 30, (Resized_width,Resized_height))\nif debugging:\n    waitTime = 1\nelse:\n    waitTime = 1\n#============================================ Paramters for Lane Detection =======================================\nRef_imgWidth = 1920\nRef_imgHeight = 1080\n#Ref_imgWidth = 640",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Ref_imgWidth",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Ref_imgWidth = 1920\nRef_imgHeight = 1080\n#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Ref_imgHeight",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Ref_imgHeight = 1080\n#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "#Ref_imgWidth",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "#Ref_imgWidth = 640\n#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "#Ref_imgHeight",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "#Ref_imgHeight = 480\nFrame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Frame_pixels",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Frame_pixels = Ref_imgWidth * Ref_imgHeight\nResize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Resize_Framepixels",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Resize_Framepixels = Resized_width * Resized_height\nLane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Lane_Extraction_minArea_per",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "Lane_Extraction_minArea_per = 1000 / Frame_pixels\nminArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "minArea_resized",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "minArea_resized = int(Resize_Framepixels * Lane_Extraction_minArea_per)\nBWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "BWContourOpen_speed_MaxDist_per",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "BWContourOpen_speed_MaxDist_per = 500 / Ref_imgHeight\nMaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "MaxDist_resized",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "MaxDist_resized = int(Resized_height * BWContourOpen_speed_MaxDist_per)\nCropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "CropHeight",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "CropHeight = 650 # Required in Camera mounted on top of car 640p\nCropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "CropHeight_resized",
        "kind": 5,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "peekOfCode": "CropHeight_resized = int( (CropHeight / Ref_imgHeight ) * Resized_height )",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.config.config",
        "documentation": {}
    },
    {
        "label": "Debugging",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "peekOfCode": "class Debugging:\n    def __init__(self):\n        self.TL_Created = False\n        self.Lan_Created = False\n    def nothing(self,x):\n        pass\n    cv2.namedWindow('CONFIG')\n    enable_SatNav = 'Sat-Nav'\n    cv2.createTrackbar(enable_SatNav, 'CONFIG',False,True,nothing)\n    # creating (Engine) on/off trackbar",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "documentation": {}
    },
    {
        "label": "Control",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "peekOfCode": "class Control:\n    def __init__(self):\n        self.prev_Mode = \"Detection\"\n        self.prev_Mode_LT = \"Detection\"\n        self.car_speed = 80\n        self.angle_of_car = 0\n        self.Left_turn_iterations = 0\n        self.Frozen_Angle = 0\n        self.Detected_LeftTurn = False\n        self.Activat_LeftTurn = False",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "documentation": {}
    },
    {
        "label": "Car",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "peekOfCode": "class Car:\n    def __init__( self,Inc_TL = True, Inc_LT = True ):\n        self.Control_ = Control()\n        self.Inc_TL = Inc_TL\n        self.Inc_LT = Inc_LT\n        # [NEW]: Containers to Keep track of current state of Signs and Traffic Light detection\n        self.Tracked_class = \"Unknown\"\n        self.Traffic_State = \"Unknown\"\n    def display_state(self,frame_disp,angle_of_car,current_speed,Tracked_class,Traffic_State,Detected_LeftTurn, Activat_LeftTurn):\n        ###################################################  Displaying CONTROL STATE ####################################",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.Drive_Bot",
        "documentation": {}
    },
    {
        "label": "Video_feed_in",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.computer_vision_node",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.computer_vision_node",
        "peekOfCode": "class Video_feed_in(Node):\n    def __init__(self):\n        super().__init__('video_subscriber')\n        self.subscriber = self.create_subscription(Image,'/camera/image_raw',self.process_data,10)\n        self.publisher = self.create_publisher(Twist, '/cmd_vel', 40)\n        timer_period = 0.5;self.timer = self.create_timer(timer_period, self.send_cmd_vel)\n        self.velocity = Twist()\n        self.bridge   = CvBridge() # converting ros images to opencv data\n        self.Debug    = Debugging()\n        self.Car      = Car()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.computer_vision_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.computer_vision_node",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.computer_vision_node",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_feed_in()\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n\tmain()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.computer_vision_node",
        "documentation": {}
    },
    {
        "label": "DriveNode",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.drive_node",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.drive_node",
        "peekOfCode": "class DriveNode(Node):\n    def __init__(self):\n        super().__init__('drive_node')\n        self.publisher_ = self.create_publisher(Twist, 'cmd_vel', 10)\n        timer_period = 0.5\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n        self.get_logger().info('Publishing: cmd_vel ')\n        self.cmd_vel_msg = Twist()\n    def timer_callback(self):\n        self.cmd_vel_msg.linear.x = 10.0;",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.drive_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.drive_node",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.drive_node",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    cmd_vel_publisher = DriveNode()\n    rclpy.spin(cmd_vel_publisher)\n    cmd_vel_publisher.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.drive_node",
        "documentation": {}
    },
    {
        "label": "Video_feed_in",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdc_V2",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdc_V2",
        "peekOfCode": "class Video_feed_in(Node):\n    def __init__(self):\n        super().__init__('video_subscriber')\n        self.subscriber = self.create_subscription(Image,'/camera/image_raw',self.process_data,10)\n        self.publisher = self.create_publisher(Twist, '/cmd_vel', 40)\n        self.velocity = Twist()\n        self.bridge   = CvBridge() # converting ros images to opencv data\n        self.Debug    = Debugging()\n        self.Car      = Car()\n        # creating object of navigator class",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdc_V2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdc_V2",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdc_V2",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_feed_in()\n  # [NEW]: Animate Steering to see how rolling average smoothes the lane assist\n  if config.animate_steering:\n    concurrent.futures.ThreadPoolExecutor().submit(image_subscriber.animate)\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n\tmain()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdc_V2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdf_spawner",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdf_spawner",
        "peekOfCode": "def main():\n    argv = sys.argv[1:]\n    rclpy.init()\n    node = rclpy.create_node(\"Spawning_Node\")\n    client = node.create_client(SpawnEntity, \"/spawn_entity\")\n    if not client.service_is_ready():\n        client.wait_for_service()\n        node.get_logger().info(\"connected to spawner\")\n    sdf_path = argv[0]\n    request = SpawnEntity.Request()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.sdf_spawner",
        "documentation": {}
    },
    {
        "label": "Video_get",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.upper_camera_video",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.upper_camera_video",
        "peekOfCode": "class Video_get(Node):\n  def __init__(self):\n    super().__init__('video_subscriber')# node name\n    ## Created a subscriber \n    self.subscriber = self.create_subscription(Image,'/upper_camera/image_raw',self.process_data,10)\n    ## setting for writing the frames into a video\n    self.out = cv2.VideoWriter('/home/luqman/output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (1280,720))\n    self.bridge = CvBridge() # converting ros images to opencv data\n  def process_data(self, data): \n    frame = self.bridge.imgmsg_to_cv2(data,'bgr8') # performing conversion",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.upper_camera_video",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.upper_camera_video",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.upper_camera_video",
        "peekOfCode": "def main(args=None):\n  rclpy.init(args=args)\n  image_subscriber = Video_get()\n  rclpy.spin(image_subscriber)\n  rclpy.shutdown()\nif __name__ == '__main__':\n  main()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.upper_camera_video",
        "documentation": {}
    },
    {
        "label": "VisionSave",
        "kind": 6,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.video_save",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.video_save",
        "peekOfCode": "class VisionSave(Node):\n    def __init__(self):\n        super().__init__('vision_save_node')\n        self.subscriber = self.create_subscription(Image,'/camera/image_raw',self.process_data,10)\n        self.out = cv2.VideoWriter('/home/luqman/in_new.avi',cv2.VideoWriter_fourcc('M','J','P','G'),30,(1280,720))\n        self.get_logger().info('Subscribing Image Feed and video recording')\n        self.bridge = CvBridge()\n    def process_data(self,data):\n        frame=self.bridge.imgmsg_to_cv2(data,'bgr8')\n        self.out.write(frame)",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.video_save",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.video_save",
        "description": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.video_save",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    vision_subcriber = VisionSave()\n    rclpy.spin(vision_subcriber)\n    vision_subcriber.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.self_driving_car_pkg.build.lib.self_driving_car_pkg.video_save",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.sensor_simulator.build.lib.sensor_simulator.Radar",
        "description": "build.sensor_simulator.build.lib.sensor_simulator.Radar",
        "peekOfCode": "def main():\n    print('Hi from sensor_simulator.')\nif __name__ == '__main__':\n    main()",
        "detail": "build.sensor_simulator.build.lib.sensor_simulator.Radar",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.tactical_decision.build.lib.tactical_decision.FireDecision",
        "description": "build.tactical_decision.build.lib.tactical_decision.FireDecision",
        "peekOfCode": "def main():\n    print('Hi from tactical_decision.')\nif __name__ == '__main__':\n    main()",
        "detail": "build.tactical_decision.build.lib.tactical_decision.FireDecision",
        "documentation": {}
    },
    {
        "label": "TeslaMarkersNode",
        "kind": 6,
        "importPath": "build.tesla_frames.build.lib.tesla_frames.tesla_markers_node",
        "description": "build.tesla_frames.build.lib.tesla_frames.tesla_markers_node",
        "peekOfCode": "class TeslaMarkersNode(Node):\n    def __init__(self):\n        super().__init__(\"tesla_markers_node\")\n        self.publisher_ = self.create_publisher(Marker, \"visualization_marker\", 10)\n        timer_period = 10  # in seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n    def timer_callback(self):\n        marker = Marker()\n        marker.header.frame_id = \"base_footprint\"\n        marker.header.stamp = self.get_clock().now().to_msg()",
        "detail": "build.tesla_frames.build.lib.tesla_frames.tesla_markers_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.tesla_frames.build.lib.tesla_frames.tesla_markers_node",
        "description": "build.tesla_frames.build.lib.tesla_frames.tesla_markers_node",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    mesh_marker_publisher = TeslaMarkersNode()\n    rclpy.spin(mesh_marker_publisher)\n    mesh_marker_publisher.destroy_node()\n    rclpy.shutdown()\nif __name__ == \"__main__\":\n    main()",
        "detail": "build.tesla_frames.build.lib.tesla_frames.tesla_markers_node",
        "documentation": {}
    },
    {
        "label": "TeslaTf2Publisher",
        "kind": 6,
        "importPath": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "description": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "peekOfCode": "class TeslaTf2Publisher(Node):\n    def __init__(self):\n        super().__init__(\"tesla_tf2_publisher\")\n        self.broadcaster = StaticTransformBroadcaster(self)\n        self.publish_transforms()\n    def publish_transforms(self):\n        # Base Link to Base Footprint\n        base_link_to_footprint = TransformStamped()\n        base_link_to_footprint.header.stamp = self.get_clock().now().to_msg()\n        base_link_to_footprint.header.frame_id = \"base_footprint\"",
        "detail": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "documentation": {}
    },
    {
        "label": "quaternion_from_euler",
        "kind": 2,
        "importPath": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "description": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "peekOfCode": "def quaternion_from_euler(roll, pitch, yaw):\n    \"\"\"\n    Converts euler roll, pitch, yaw to quaternion\n    \"\"\"\n    cy = math.cos(yaw * 0.5)\n    sy = math.sin(yaw * 0.5)\n    cp = math.cos(pitch * 0.5)\n    sp = math.sin(pitch * 0.5)\n    cr = math.cos(roll * 0.5)\n    sr = math.sin(roll * 0.5)",
        "detail": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "description": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    node = TeslaTf2Publisher()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        rclpy.shutdown()\nif __name__ == \"__main__\":",
        "detail": "build.tesla_frames.build.lib.tesla_frames.tesla_tf2_publisher",
        "documentation": {}
    },
    {
        "label": "AkshareDataCollector",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.collector.akshare_data_collector",
        "description": "build.trader.build.lib.trader.collector.akshare_data_collector",
        "peekOfCode": "class AkshareDataCollector(DataCollector):\n    def __init__(self):\n        # 初始化时获取热门行业的股票代码列表，并使用lru_cache装饰器缓存结果\n        self._hot_industry_stocks = self.get_hot_industry_stocks()\n    market_spot: pd.DataFrame = None\n    def slope_to_degrees(self, slope):\n        return math.degrees(math.atan(slope))\n    def __fetch_data__(self, symbol: str, start_date: str = None, end_date: str = None, adjust: str = \"\"):\n        start_date = (datetime.now() - timedelta(days=250)\n                      ).strftime('%Y%m%d') if not start_date else start_date",
        "detail": "build.trader.build.lib.trader.collector.akshare_data_collector",
        "documentation": {}
    },
    {
        "label": "DataCollector",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.collector.base",
        "description": "build.trader.build.lib.trader.collector.base",
        "peekOfCode": "class DataCollector(ABC):\n    @abstractmethod\n    def get_data(self, symbol, start_date, end_date):\n        \"\"\"\n        Fetch data from the source.\n        :param symbol: The symbol of the stock.\n        :param start_date: The start date for fetching data.\n        :param end_date: The end date for fetching data.\n        :return: Data fetched from the source.\n        \"\"\"",
        "detail": "build.trader.build.lib.trader.collector.base",
        "documentation": {}
    },
    {
        "label": "Constants",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.core.constants",
        "description": "build.trader.build.lib.trader.core.constants",
        "peekOfCode": "class Constants:\n    BAR_DAY_COLUMNS = [\"date\",\"open\", \"close\", \"high\",\n                       \"low\", \"volume\", \"amount\", \"amp\", \"pct\", \"turnover\"]\n    BAR_MINUTE_COLUMNS = [\"date\", \"open\", \"close\", \"high\",\n                          \"low\", \"volume\", \"amount\", \"amplitude\", \"pct\", \"turnover\"]\n    TA_INDIECT_NAMES = [\"cmf\", \"roc\", \"sma\", \"ema\", \"obv\", \"slope\"]\n    TA_INDIECT_LENTHES = [3, 5, 10]\n    SPOT_EM_COLUMNS = [\n        \"code\",\n        \"name\",",
        "detail": "build.trader.build.lib.trader.core.constants",
        "documentation": {}
    },
    {
        "label": "FavorSignalTopic",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.core.topic",
        "description": "build.trader.build.lib.trader.core.topic",
        "peekOfCode": "class FavorSignalTopic(Enum):\n    UPDATE_FAVOR = 'update.favor.signal'\n    def __str__(self):\n        # 只返回枚举成员的名称，不包括类名\n        return self.value \nclass TradeSignalTopic(Enum):\n    BATCH_BUY = 'batch.buy.signal'\n    BUY = 'buy.signal'\n    SELL = 'sell.signal'\n    SELL_ALL = 'sell.all.signal'",
        "detail": "build.trader.build.lib.trader.core.topic",
        "documentation": {}
    },
    {
        "label": "TradeSignalTopic",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.core.topic",
        "description": "build.trader.build.lib.trader.core.topic",
        "peekOfCode": "class TradeSignalTopic(Enum):\n    BATCH_BUY = 'batch.buy.signal'\n    BUY = 'buy.signal'\n    SELL = 'sell.signal'\n    SELL_ALL = 'sell.all.signal'\n    SELL_HALF = 'sell.half.signal'\n    SELL_QUARTER = 'sell.quarter.signal'\n    CANCEL_ORDER = 'cancel.order.signal'\n    def __str__(self):\n        # 只返回枚举成员的名称，不包括类名",
        "detail": "build.trader.build.lib.trader.core.topic",
        "documentation": {}
    },
    {
        "label": "StockPool",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.pool.base",
        "description": "build.trader.build.lib.trader.pool.base",
        "peekOfCode": "class StockPool(ABC):\n    @abstractmethod\n    def get_symbols(self) -> List[str]:\n        pass\n    def get_data(self, symbols: List[str])->pd.DataFrame:\n        \"\"\"\n        从ADC数据源获取最新的数据。\n        Args:\n            symbols：股票代码列表\n        Returns:",
        "detail": "build.trader.build.lib.trader.pool.base",
        "documentation": {}
    },
    {
        "label": "AmountStockPool",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.pool.pool",
        "description": "build.trader.build.lib.trader.pool.pool",
        "peekOfCode": "class AmountStockPool(StockPool):\n  def __init__(self):\n    self.adc = AkshareDataCollector()\n  def get_symbols(self,cloumn_name:str=\"amount\",k:int=100) -> List[str]:\n    \"\"\"\n    获取股票符号列表，默认为按成交额排序的前100只股票\n    Args:\n        cloumn_name (str, optional): 用于排序的列名，默认为'amount'。\n        k (int, optional): 返回的股票数量，默认为100。\n    Returns:",
        "detail": "build.trader.build.lib.trader.pool.pool",
        "documentation": {}
    },
    {
        "label": "TurtleNode",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.CCIndex",
        "description": "build.trader.build.lib.trader.CCIndex",
        "peekOfCode": "class TurtleNode(Node):\n    def __init__(self):\n        super().__init__('TurtleNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # msg = Person()\n        # msg.name = \"ROS User\"\n        # msg.age = 4  \n        # print(\">>>>>>>>>>>>>\",msg)      \n        # 声明参数\n        self.declare_parameter('node_name', 'trader')\n        self.declare_parameter('linear_speed', 0.5)",
        "detail": "build.trader.build.lib.trader.CCIndex",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.trader.build.lib.trader.CCIndex",
        "description": "build.trader.build.lib.trader.CCIndex",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    turtlenode = TurtleNode()\n    rclpy.spin(turtlenode)\n    turtlenode.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.trader.build.lib.trader.CCIndex",
        "documentation": {}
    },
    {
        "label": "CCIndexNode",
        "kind": 6,
        "importPath": "build.trader.build.lib.trader.CCIndex_marker",
        "description": "build.trader.build.lib.trader.CCIndex_marker",
        "peekOfCode": "class CCIndexNode(Node):\n    def __init__(self):\n        super().__init__('CCIndexNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # 声明参数\n        self.declare_parameter('node_name', 'CCIndexNode')\n        self.declare_parameter('linear_speed', 0.5)\n        self.declare_parameter('angular_speed', 0.2)\n        # 获取参数\n        self.node_name = self.get_parameter('node_name').get_parameter_value().string_value\n        self.linear_speed = self.get_parameter('linear_speed').get_parameter_value().double_value",
        "detail": "build.trader.build.lib.trader.CCIndex_marker",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.trader.build.lib.trader.CCIndex_marker",
        "description": "build.trader.build.lib.trader.CCIndex_marker",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    node = CCIndexNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "build.trader.build.lib.trader.CCIndex_marker",
        "documentation": {}
    },
    {
        "label": "data_points",
        "kind": 5,
        "importPath": "build.trader.build.lib.trader.CCIndex_marker",
        "description": "build.trader.build.lib.trader.CCIndex_marker",
        "peekOfCode": "data_points = []\nclass CCIndexNode(Node):\n    def __init__(self):\n        super().__init__('CCIndexNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # 声明参数\n        self.declare_parameter('node_name', 'CCIndexNode')\n        self.declare_parameter('linear_speed', 0.5)\n        self.declare_parameter('angular_speed', 0.2)\n        # 获取参数\n        self.node_name = self.get_parameter('node_name').get_parameter_value().string_value",
        "detail": "build.trader.build.lib.trader.CCIndex_marker",
        "documentation": {}
    },
    {
        "label": "MyRobotDriver",
        "kind": 6,
        "importPath": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "description": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "peekOfCode": "class MyRobotDriver:\n    def init(self, webots_node, properties):\n        self.__robot = webots_node.robot\n        self.__left_motor = self.__robot.getDevice('left wheel motor')\n        self.__right_motor = self.__robot.getDevice('right wheel motor')\n        self.__left_motor.setPosition(float('inf'))\n        self.__left_motor.setVelocity(0)\n        self.__right_motor.setPosition(float('inf'))\n        self.__right_motor.setVelocity(0)\n        self.__target_twist = Twist()",
        "detail": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "documentation": {}
    },
    {
        "label": "HALF_DISTANCE_BETWEEN_WHEELS",
        "kind": 5,
        "importPath": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "description": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "peekOfCode": "HALF_DISTANCE_BETWEEN_WHEELS = 0.045\nWHEEL_RADIUS = 0.025\nclass MyRobotDriver:\n    def init(self, webots_node, properties):\n        self.__robot = webots_node.robot\n        self.__left_motor = self.__robot.getDevice('left wheel motor')\n        self.__right_motor = self.__robot.getDevice('right wheel motor')\n        self.__left_motor.setPosition(float('inf'))\n        self.__left_motor.setVelocity(0)\n        self.__right_motor.setPosition(float('inf'))",
        "detail": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "documentation": {}
    },
    {
        "label": "WHEEL_RADIUS",
        "kind": 5,
        "importPath": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "description": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "peekOfCode": "WHEEL_RADIUS = 0.025\nclass MyRobotDriver:\n    def init(self, webots_node, properties):\n        self.__robot = webots_node.robot\n        self.__left_motor = self.__robot.getDevice('left wheel motor')\n        self.__right_motor = self.__robot.getDevice('right wheel motor')\n        self.__left_motor.setPosition(float('inf'))\n        self.__left_motor.setVelocity(0)\n        self.__right_motor.setPosition(float('inf'))\n        self.__right_motor.setVelocity(0)",
        "detail": "build.webots_demo.build.lib.webots_demo.my_robot_driver",
        "documentation": {}
    },
    {
        "label": "ObstacleAvoider",
        "kind": 6,
        "importPath": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "description": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "peekOfCode": "class ObstacleAvoider(Node):\n    def __init__(self):\n        super().__init__('obstacle_avoider')\n        self.__publisher = self.create_publisher(Twist, 'cmd_vel', 1)\n        self.create_subscription(Range, 'left_sensor', self.__left_sensor_callback, 1)\n        self.create_subscription(Range, 'right_sensor', self.__right_sensor_callback, 1)\n    def __left_sensor_callback(self, message):\n        self.__left_sensor_value = message.range\n    def __right_sensor_callback(self, message):\n        self.__right_sensor_value = message.range",
        "detail": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "description": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    avoider = ObstacleAvoider()\n    rclpy.spin(avoider)\n    # Destroy the node explicitly\n    # (optional - otherwise it will be done automatically\n    # when the garbage collector destroys the node object)\n    avoider.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':",
        "detail": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "documentation": {}
    },
    {
        "label": "MAX_RANGE",
        "kind": 5,
        "importPath": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "description": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "peekOfCode": "MAX_RANGE = 0.15\nclass ObstacleAvoider(Node):\n    def __init__(self):\n        super().__init__('obstacle_avoider')\n        self.__publisher = self.create_publisher(Twist, 'cmd_vel', 1)\n        self.create_subscription(Range, 'left_sensor', self.__left_sensor_callback, 1)\n        self.create_subscription(Range, 'right_sensor', self.__right_sensor_callback, 1)\n    def __left_sensor_callback(self, message):\n        self.__left_sensor_value = message.range\n    def __right_sensor_callback(self, message):",
        "detail": "build.webots_demo.build.lib.webots_demo.obstacle_avoider",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.entity_controller.share.entity_controller.launch.peanut_butter_falcon_quote_publisher_launch",
        "description": "install.entity_controller.share.entity_controller.launch.peanut_butter_falcon_quote_publisher_launch",
        "peekOfCode": "def generate_launch_description():\n    return LaunchDescription([\n        Node(\n            output='screen',\n            emulate_tty=True,\n            package='entity_controller',\n            executable='amazing_quote_configurable_publisher_node',\n            name='peanut_butter_falcon_quote_publisher_node',\n            parameters=[{\n                \"topic_name\": \"truly_inspirational_quote\",",
        "detail": "install.entity_controller.share.entity_controller.launch.peanut_butter_falcon_quote_publisher_launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.entity_controller.share.entity_controller.launch.turtlesim.launch",
        "description": "install.entity_controller.share.entity_controller.launch.turtlesim.launch",
        "peekOfCode": "def generate_launch_description():\n    # 声明启动参数\n    declare_node_name_prefix_arg = DeclareLaunchArgument(\n        'node_name_prefix', default_value='turtlenode')\n    declare_nums_for_node_arg = DeclareLaunchArgument(\n        'nums_for_node', default_value='2')\n    declare_linear_speed_arg = DeclareLaunchArgument(\n        'linear_speed', default_value='0.5')\n    declare_angular_speed_arg = DeclareLaunchArgument(\n        'angular_speed', default_value='0.2')",
        "detail": "install.entity_controller.share.entity_controller.launch.turtlesim.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.maze_solving_world.launch",
        "description": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.maze_solving_world.launch",
        "peekOfCode": "def generate_launch_description():\n  package_dir=get_package_share_directory('self_driving_car_pkg')\n  world_file = os.path.join(package_dir,'worlds','maze_solving.world')\n  return LaunchDescription([\n        ExecuteProcess(\n            cmd=['gazebo', '--verbose',world_file, '-s', 'libgazebo_ros_factory.so'],\n            output='screen'),\n        Node(\n                package='self_driving_car_pkg',\n                executable='lights_spawner_maze.bash',",
        "detail": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.maze_solving_world.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.record_and_drive.launch",
        "description": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.record_and_drive.launch",
        "peekOfCode": "def generate_launch_description():\n  return LaunchDescription([\n        Node(\n                package='self_driving_car_pkg',\n                executable='video_recording_node',\n                name='video_recorder',\n                output='screen'),\n        Node(\n                package='teleop_twist_keyboard',\n                executable='teleop_twist_keyboard',",
        "detail": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.record_and_drive.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.test_laneFollow.launch",
        "description": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.test_laneFollow.launch",
        "peekOfCode": "def generate_launch_description():\n    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n    pkg_share_dir = get_package_share_directory('self_driving_car_pkg')\n    model_pkg_share_dir = get_package_share_directory('self_driving_car_pkg_models')\n    models_share_dir = os.pathsep + os.path.join(model_pkg_share_dir, 'models')\n    if 'GAZEBO_MODEL_PATH' in os.environ:\n        os.environ['GAZEBO_MODEL_PATH'] += models_share_dir\n    else:\n        os.environ['GAZEBO_MODEL_PATH'] =  models_share_dir\n    print(os.environ['GAZEBO_MODEL_PATH'])",
        "detail": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.test_laneFollow.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.world_gazebo.launch",
        "description": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.world_gazebo.launch",
        "peekOfCode": "def generate_launch_description():\n    # pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n    pkg_gazebo_ros = get_package_share_directory('ros_gz_sim')\n    pkg_share_dir = get_package_share_directory('self_driving_car_pkg')\n    model_pkg_share_dir = get_package_share_directory('self_driving_car_pkg_models')\n    models_share_dir = os.pathsep + os.path.join(model_pkg_share_dir, 'models')\n    if 'GAZEBO_MODEL_PATH' in os.environ:\n        os.environ['GAZEBO_MODEL_PATH'] += models_share_dir\n    else:\n        os.environ['GAZEBO_MODEL_PATH'] =  models_share_dir",
        "detail": "install.self_driving_car_pkg.share.self_driving_car_pkg.launch.world_gazebo.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.tesla_frames.share.tesla_frames.launch.dual_ekf_navsat.launch",
        "description": "install.tesla_frames.share.tesla_frames.launch.dual_ekf_navsat.launch",
        "peekOfCode": "def generate_launch_description():\n    tesla_frames_dir = get_package_share_directory(\"tesla_frames\")\n    parameters_file_dir = os.path.join(tesla_frames_dir, \"config\")\n    parameters_file_path = os.path.join(parameters_file_dir, \"dual_ekf_navsat.yaml\")\n    os.environ[\"FILE_PATH\"] = str(parameters_file_dir)\n    return LaunchDescription(\n        [\n            # launch.actions.DeclareLaunchArgument(\"output_final_position\", default_value=\"false\"),\n            # launch.actions.DeclareLaunchArgument(\n            #     \"output_location\", default_value=\"~/dual_ekf_navsat_debug.txt\"",
        "detail": "install.tesla_frames.share.tesla_frames.launch.dual_ekf_navsat.launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "install.webots_demo.share.webots_demo.launch.robot_launch",
        "description": "install.webots_demo.share.webots_demo.launch.robot_launch",
        "peekOfCode": "def generate_launch_description():\n    package_dir = get_package_share_directory('webots_demo')\n    robot_description_path = os.path.join(package_dir, 'resource', 'my_robot.urdf')\n    webots = WebotsLauncher(\n        world=os.path.join(package_dir, 'worlds', 'my_world.wbt'),\n        ros2_supervisor=True\n    )\n    my_robot_driver = WebotsController(\n        robot_name='my_robot',\n        parameters=[",
        "detail": "install.webots_demo.share.webots_demo.launch.robot_launch",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(\n        'additional_extension', nargs='?',\n        help='The additional file extension to be considered')",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "get_packages",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def get_packages(prefix_path, merged_install):\n    \"\"\"\n    Find packages based on colcon-specific files created during installation.\n    :param Path prefix_path: The install prefix path of all packages\n    :param bool merged_install: The flag if the packages are all installed\n      directly in the prefix or if each package is installed in a subdirectory\n      named after the package\n    :returns: A mapping from the package name to the set of runtime\n      dependencies\n    :rtype: dict",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "add_package_runtime_dependencies",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def add_package_runtime_dependencies(path, packages):\n    \"\"\"\n    Check the path and if it exists extract the packages runtime dependencies.\n    :param Path path: The resource file containing the runtime dependencies\n    :param dict packages: A mapping from package names to the sets of runtime\n      dependencies to add to\n    \"\"\"\n    content = path.read_text()\n    dependencies = set(content.split(os.pathsep) if content else [])\n    packages[path.name] = dependencies",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "order_packages",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def order_packages(packages):\n    \"\"\"\n    Order packages topologically.\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies\n    :returns: The package names\n    :rtype: list\n    \"\"\"\n    # select packages with no dependencies in alphabetical order\n    to_be_ordered = list(packages.keys())",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "reduce_cycle_set",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def reduce_cycle_set(packages):\n    \"\"\"\n    Reduce the set of packages to the ones part of the circular dependency.\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies which is modified in place\n    \"\"\"\n    last_depended = None\n    while len(packages) > 0:\n        # get all remaining dependencies\n        depended = set()",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "get_commands",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def get_commands(pkg_name, prefix, primary_extension, additional_extension):\n    commands = []\n    package_dsv_path = os.path.join(prefix, 'share', pkg_name, 'package.dsv')\n    if os.path.exists(package_dsv_path):\n        commands += process_dsv_file(\n            package_dsv_path, prefix, primary_extension, additional_extension)\n    return commands\ndef process_dsv_file(\n    dsv_path, prefix, primary_extension=None, additional_extension=None\n):",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "process_dsv_file",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def process_dsv_file(\n    dsv_path, prefix, primary_extension=None, additional_extension=None\n):\n    commands = []\n    if _include_comments():\n        commands.append(FORMAT_STR_COMMENT_LINE.format_map({'comment': dsv_path}))\n    with open(dsv_path, 'r') as h:\n        content = h.read()\n    lines = content.splitlines()\n    basenames = OrderedDict()",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "handle_dsv_types_except_source",
        "kind": 2,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "def handle_dsv_types_except_source(type_, remainder, prefix):\n    commands = []\n    if type_ in (DSV_TYPE_SET, DSV_TYPE_SET_IF_UNSET):\n        try:\n            env_name, value = remainder.split(';', 1)\n        except ValueError:\n            raise RuntimeError(\n                \"doesn't contain a semicolon separating the environment name \"\n                'from the value')\n        try_prefixed_value = os.path.join(prefix, value) if value else prefix",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_COMMENT_LINE",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "FORMAT_STR_COMMENT_LINE = '# {comment}'\nFORMAT_STR_SET_ENV_VAR = 'Set-Item -Path \"Env:{name}\" -Value \"{value}\"'\nFORMAT_STR_USE_ENV_VAR = '$env:{name}'\nFORMAT_STR_INVOKE_SCRIPT = '_colcon_prefix_powershell_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = ''  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = ''  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_SET_ENV_VAR",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "FORMAT_STR_SET_ENV_VAR = 'Set-Item -Path \"Env:{name}\" -Value \"{value}\"'\nFORMAT_STR_USE_ENV_VAR = '$env:{name}'\nFORMAT_STR_INVOKE_SCRIPT = '_colcon_prefix_powershell_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = ''  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = ''  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_USE_ENV_VAR",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "FORMAT_STR_USE_ENV_VAR = '$env:{name}'\nFORMAT_STR_INVOKE_SCRIPT = '_colcon_prefix_powershell_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = ''  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = ''  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_INVOKE_SCRIPT",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "FORMAT_STR_INVOKE_SCRIPT = '_colcon_prefix_powershell_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = ''  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = ''  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_REMOVE_LEADING_SEPARATOR",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "FORMAT_STR_REMOVE_LEADING_SEPARATOR = ''  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = ''  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_REMOVE_TRAILING_SEPARATOR",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "FORMAT_STR_REMOVE_TRAILING_SEPARATOR = ''  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_APPEND_NON_DUPLICATE",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "DSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_PREPEND_NON_DUPLICATE",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "DSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_SET",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "DSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_SET_IF_UNSET",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "DSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_SOURCE",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "DSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(\n        'additional_extension', nargs='?',",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "env_state",
        "kind": 5,
        "importPath": "install._local_setup_util_ps1",
        "description": "install._local_setup_util_ps1",
        "peekOfCode": "env_state = {}\ndef _append_unique_value(name, value):\n    global env_state\n    if name not in env_state:\n        if os.environ.get(name):\n            env_state[name] = set(os.environ[name].split(os.pathsep))\n        else:\n            env_state[name] = set()\n    # append even if the variable has not been set yet, in case a shell script sets the\n    # same variable without the knowledge of this Python script.",
        "detail": "install._local_setup_util_ps1",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(\n        'additional_extension', nargs='?',\n        help='The additional file extension to be considered')",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "get_packages",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def get_packages(prefix_path, merged_install):\n    \"\"\"\n    Find packages based on colcon-specific files created during installation.\n    :param Path prefix_path: The install prefix path of all packages\n    :param bool merged_install: The flag if the packages are all installed\n      directly in the prefix or if each package is installed in a subdirectory\n      named after the package\n    :returns: A mapping from the package name to the set of runtime\n      dependencies\n    :rtype: dict",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "add_package_runtime_dependencies",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def add_package_runtime_dependencies(path, packages):\n    \"\"\"\n    Check the path and if it exists extract the packages runtime dependencies.\n    :param Path path: The resource file containing the runtime dependencies\n    :param dict packages: A mapping from package names to the sets of runtime\n      dependencies to add to\n    \"\"\"\n    content = path.read_text()\n    dependencies = set(content.split(os.pathsep) if content else [])\n    packages[path.name] = dependencies",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "order_packages",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def order_packages(packages):\n    \"\"\"\n    Order packages topologically.\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies\n    :returns: The package names\n    :rtype: list\n    \"\"\"\n    # select packages with no dependencies in alphabetical order\n    to_be_ordered = list(packages.keys())",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "reduce_cycle_set",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def reduce_cycle_set(packages):\n    \"\"\"\n    Reduce the set of packages to the ones part of the circular dependency.\n    :param dict packages: A mapping from package name to the set of runtime\n      dependencies which is modified in place\n    \"\"\"\n    last_depended = None\n    while len(packages) > 0:\n        # get all remaining dependencies\n        depended = set()",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "get_commands",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def get_commands(pkg_name, prefix, primary_extension, additional_extension):\n    commands = []\n    package_dsv_path = os.path.join(prefix, 'share', pkg_name, 'package.dsv')\n    if os.path.exists(package_dsv_path):\n        commands += process_dsv_file(\n            package_dsv_path, prefix, primary_extension, additional_extension)\n    return commands\ndef process_dsv_file(\n    dsv_path, prefix, primary_extension=None, additional_extension=None\n):",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "process_dsv_file",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def process_dsv_file(\n    dsv_path, prefix, primary_extension=None, additional_extension=None\n):\n    commands = []\n    if _include_comments():\n        commands.append(FORMAT_STR_COMMENT_LINE.format_map({'comment': dsv_path}))\n    with open(dsv_path, 'r') as h:\n        content = h.read()\n    lines = content.splitlines()\n    basenames = OrderedDict()",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "handle_dsv_types_except_source",
        "kind": 2,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "def handle_dsv_types_except_source(type_, remainder, prefix):\n    commands = []\n    if type_ in (DSV_TYPE_SET, DSV_TYPE_SET_IF_UNSET):\n        try:\n            env_name, value = remainder.split(';', 1)\n        except ValueError:\n            raise RuntimeError(\n                \"doesn't contain a semicolon separating the environment name \"\n                'from the value')\n        try_prefixed_value = os.path.join(prefix, value) if value else prefix",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_COMMENT_LINE",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "FORMAT_STR_COMMENT_LINE = '# {comment}'\nFORMAT_STR_SET_ENV_VAR = 'export {name}=\"{value}\"'\nFORMAT_STR_USE_ENV_VAR = '${name}'\nFORMAT_STR_INVOKE_SCRIPT = 'COLCON_CURRENT_PREFIX=\"{prefix}\" _colcon_prefix_sh_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = 'if [ \"$(echo -n ${name} | head -c 1)\" = \":\" ]; then export {name}=${{{name}#?}} ; fi'  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = 'if [ \"$(echo -n ${name} | tail -c 1)\" = \":\" ]; then export {name}=${{{name}%?}} ; fi'  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_SET_ENV_VAR",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "FORMAT_STR_SET_ENV_VAR = 'export {name}=\"{value}\"'\nFORMAT_STR_USE_ENV_VAR = '${name}'\nFORMAT_STR_INVOKE_SCRIPT = 'COLCON_CURRENT_PREFIX=\"{prefix}\" _colcon_prefix_sh_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = 'if [ \"$(echo -n ${name} | head -c 1)\" = \":\" ]; then export {name}=${{{name}#?}} ; fi'  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = 'if [ \"$(echo -n ${name} | tail -c 1)\" = \":\" ]; then export {name}=${{{name}%?}} ; fi'  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_USE_ENV_VAR",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "FORMAT_STR_USE_ENV_VAR = '${name}'\nFORMAT_STR_INVOKE_SCRIPT = 'COLCON_CURRENT_PREFIX=\"{prefix}\" _colcon_prefix_sh_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = 'if [ \"$(echo -n ${name} | head -c 1)\" = \":\" ]; then export {name}=${{{name}#?}} ; fi'  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = 'if [ \"$(echo -n ${name} | tail -c 1)\" = \":\" ]; then export {name}=${{{name}%?}} ; fi'  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_INVOKE_SCRIPT",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "FORMAT_STR_INVOKE_SCRIPT = 'COLCON_CURRENT_PREFIX=\"{prefix}\" _colcon_prefix_sh_source_script \"{script_path}\"'  # noqa: E501\nFORMAT_STR_REMOVE_LEADING_SEPARATOR = 'if [ \"$(echo -n ${name} | head -c 1)\" = \":\" ]; then export {name}=${{{name}#?}} ; fi'  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = 'if [ \"$(echo -n ${name} | tail -c 1)\" = \":\" ]; then export {name}=${{{name}%?}} ; fi'  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_REMOVE_LEADING_SEPARATOR",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "FORMAT_STR_REMOVE_LEADING_SEPARATOR = 'if [ \"$(echo -n ${name} | head -c 1)\" = \":\" ]; then export {name}=${{{name}#?}} ; fi'  # noqa: E501\nFORMAT_STR_REMOVE_TRAILING_SEPARATOR = 'if [ \"$(echo -n ${name} | tail -c 1)\" = \":\" ]; then export {name}=${{{name}%?}} ; fi'  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "FORMAT_STR_REMOVE_TRAILING_SEPARATOR",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "FORMAT_STR_REMOVE_TRAILING_SEPARATOR = 'if [ \"$(echo -n ${name} | tail -c 1)\" = \":\" ]; then export {name}=${{{name}%?}} ; fi'  # noqa: E501\nDSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_APPEND_NON_DUPLICATE",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "DSV_TYPE_APPEND_NON_DUPLICATE = 'append-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_PREPEND_NON_DUPLICATE",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "DSV_TYPE_PREPEND_NON_DUPLICATE = 'prepend-non-duplicate'\nDSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "DSV_TYPE_PREPEND_NON_DUPLICATE_IF_EXISTS = 'prepend-non-duplicate-if-exists'\nDSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_SET",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "DSV_TYPE_SET = 'set'\nDSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_SET_IF_UNSET",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "DSV_TYPE_SET_IF_UNSET = 'set-if-unset'\nDSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "DSV_TYPE_SOURCE",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "DSV_TYPE_SOURCE = 'source'\ndef main(argv=sys.argv[1:]):  # noqa: D103\n    parser = argparse.ArgumentParser(\n        description='Output shell commands for the packages in topological '\n                    'order')\n    parser.add_argument(\n        'primary_extension',\n        help='The file extension of the primary shell')\n    parser.add_argument(\n        'additional_extension', nargs='?',",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "env_state",
        "kind": 5,
        "importPath": "install._local_setup_util_sh",
        "description": "install._local_setup_util_sh",
        "peekOfCode": "env_state = {}\ndef _append_unique_value(name, value):\n    global env_state\n    if name not in env_state:\n        if os.environ.get(name):\n            env_state[name] = set(os.environ[name].split(os.pathsep))\n        else:\n            env_state[name] = set()\n    # append even if the variable has not been set yet, in case a shell script sets the\n    # same variable without the knowledge of this Python script.",
        "detail": "install._local_setup_util_sh",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_executable",
        "description": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_executable",
        "peekOfCode": "def main(args=None):\n    writer = rosbag2_py.SequentialWriter()\n    storage_options = rosbag2_py._storage.StorageOptions(\n        uri='big_synthetic_bag',\n        storage_id='mcap')\n    converter_options = rosbag2_py._storage.ConverterOptions('', '')\n    writer.open(storage_options, converter_options)\n    topic_info = rosbag2_py._storage.TopicMetadata(\n        id=0,\n        name='synthetic',",
        "detail": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_executable",
        "documentation": {}
    },
    {
        "label": "DataGeneratorNode",
        "kind": 6,
        "importPath": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_node",
        "description": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_node",
        "peekOfCode": "class DataGeneratorNode(Node):\n    def __init__(self):\n        super().__init__('data_generator_node')\n        self.data = Int32()\n        self.data.data = 0\n        self.writer = rosbag2_py.SequentialWriter()\n        storage_options = rosbag2_py._storage.StorageOptions(\n            uri='timed_synthetic_bag',\n            storage_id='mcap')\n        converter_options = rosbag2_py._storage.ConverterOptions('', '')",
        "detail": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_node",
        "description": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_node",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    dgn = DataGeneratorNode()\n    rclpy.spin(dgn)\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.data_generator_node",
        "documentation": {}
    },
    {
        "label": "SimpleBagRecorder",
        "kind": 6,
        "importPath": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.simple_bag_recorder",
        "description": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.simple_bag_recorder",
        "peekOfCode": "class SimpleBagRecorder(Node):\n    def __init__(self):\n        super().__init__('simple_bag_recorder')\n        self.writer = rosbag2_py.SequentialWriter()\n        storage_options = rosbag2_py._storage.StorageOptions(\n            uri='/home/ubuntu/my_bag',\n            storage_id='mcap')\n        converter_options = rosbag2_py._storage.ConverterOptions('', '')\n        self.writer.open(storage_options, converter_options)\n        topic_info = rosbag2_py._storage.TopicMetadata(",
        "detail": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.simple_bag_recorder",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.simple_bag_recorder",
        "description": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.simple_bag_recorder",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    sbr = SimpleBagRecorder()\n    rclpy.spin(sbr)\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "src.bag_recorder_nodes_py.bag_recorder_nodes_py.simple_bag_recorder",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.bag_recorder_nodes_py.test.test_copyright",
        "description": "src.bag_recorder_nodes_py.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.bag_recorder_nodes_py.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.bag_recorder_nodes_py.test.test_flake8",
        "description": "src.bag_recorder_nodes_py.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.bag_recorder_nodes_py.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.bag_recorder_nodes_py.test.test_pep257",
        "description": "src.bag_recorder_nodes_py.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.bag_recorder_nodes_py.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.bag_recorder_nodes_py.setup",
        "description": "src.bag_recorder_nodes_py.setup",
        "peekOfCode": "package_name = 'bag_recorder_nodes_py'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],",
        "detail": "src.bag_recorder_nodes_py.setup",
        "documentation": {}
    },
    {
        "label": "SampleClass",
        "kind": 6,
        "importPath": "src.custom_msg.custom_msg.my_custom_msg._sample_class",
        "description": "src.custom_msg.custom_msg.my_custom_msg._sample_class",
        "peekOfCode": "class SampleClass:\n    \"\"\"A sample class to check how they can be imported by other ROS2 packages.\"\"\"\n    def __init__(self, name: str):\n        self._name = name\n    def get_name(self) -> str:\n        \"\"\"\n        Gets the name of this instance.\n        :return: This name.\n        \"\"\"\n        return self._name",
        "detail": "src.custom_msg.custom_msg.my_custom_msg._sample_class",
        "documentation": {}
    },
    {
        "label": "sample_function_for_square_of_sum",
        "kind": 2,
        "importPath": "src.custom_msg.custom_msg.my_custom_msg._sample_function",
        "description": "src.custom_msg.custom_msg.my_custom_msg._sample_function",
        "peekOfCode": "def sample_function_for_square_of_sum(a: float, b: float) -> float:\n    \"\"\"Returns the square of a sum (a + b)^2 = a^2 + 2ab + b^2\"\"\"\n    return a**2 + 2*a*b + b**2",
        "detail": "src.custom_msg.custom_msg.my_custom_msg._sample_function",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.custom_msg.test.test_copyright",
        "description": "src.custom_msg.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.custom_msg.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.custom_msg.test.test_flake8",
        "description": "src.custom_msg.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.custom_msg.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.custom_msg.test.test_pep257",
        "description": "src.custom_msg.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.custom_msg.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.custom_msg.setup",
        "description": "src.custom_msg.setup",
        "peekOfCode": "package_name = 'custom_msg'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],",
        "detail": "src.custom_msg.setup",
        "documentation": {}
    },
    {
        "label": "TurtleNode",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.TurtleNode",
        "description": "src.entity_controller.entity_controller.TurtleNode",
        "peekOfCode": "class TurtleNode(Node):\n    def __init__(self):\n        super().__init__('TurtleNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # msg = Person()\n        # msg.name = \"ROS User\"\n        # msg.age = 4  \n        # print(\">>>>>>>>>>>>>\",msg)      \n        # 声明参数\n        self.declare_parameter('node_name', 'TurtleNode')\n        self.declare_parameter('linear_speed', 0.5)",
        "detail": "src.entity_controller.entity_controller.TurtleNode",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.TurtleNode",
        "description": "src.entity_controller.entity_controller.TurtleNode",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    turtlenode = TurtleNode()\n    rclpy.spin(turtlenode)\n    turtlenode.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "src.entity_controller.entity_controller.TurtleNode",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.WarShip",
        "description": "src.entity_controller.entity_controller.WarShip",
        "peekOfCode": "def main():\n    print('Hi from entity_controller.')\nif __name__ == '__main__':\n    main()",
        "detail": "src.entity_controller.entity_controller.WarShip",
        "documentation": {}
    },
    {
        "label": "WarShipPublisher",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.WarShipPublisher",
        "description": "src.entity_controller.entity_controller.WarShipPublisher",
        "peekOfCode": "class WarShipPublisher(Node):\n    def __init__(self):\n        super().__init__('entity_controller_WarShip')\n        # 10: 这是发布者的质量服务（Quality of Service，QoS）设置。QoS设置定义了消息传递的可靠性和历史保持策略。在这里，10是QoS配置的整数表示，对应于rmw_qos_profile_sensor_data，这是一个适用于传感器数据的QoS配置，它提供了一定的可靠性保证和历史保持策略。\n        self.publisher_ = self.create_publisher(String, 'entity_controller/WarShip', 10)\n        timer_period = 0.5  # seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n    def timer_callback(self):\n        msg = String()\n        msg.data = 'Hello ROS2!'",
        "detail": "src.entity_controller.entity_controller.WarShipPublisher",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.WarShipPublisher",
        "description": "src.entity_controller.entity_controller.WarShipPublisher",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    publisher = WarShipPublisher()\n    rclpy.spin(publisher)\n    publisher.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "src.entity_controller.entity_controller.WarShipPublisher",
        "documentation": {}
    },
    {
        "label": "WarShipSubscriber",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.WarShipSubscriber",
        "description": "src.entity_controller.entity_controller.WarShipSubscriber",
        "peekOfCode": "class WarShipSubscriber(Node):\n    def __init__(self):\n        super().__init__('entity_controller_WarShip')\n        self.subscription = self.create_subscription(\n            String,\n            'entity_controller/WarShip', \n            self.listener_callback,\n            10)\n        self.subscription  # prevent unused variable warning\n    def listener_callback(self, msg):",
        "detail": "src.entity_controller.entity_controller.WarShipSubscriber",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.WarShipSubscriber",
        "description": "src.entity_controller.entity_controller.WarShipSubscriber",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    subscriber = WarShipSubscriber()\n    rclpy.spin(subscriber)\n    subscriber.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "src.entity_controller.entity_controller.WarShipSubscriber",
        "documentation": {}
    },
    {
        "label": "AmazingQuoteConfigurablePublisherNode",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.amazing_quote_configurable_publisher_node",
        "description": "src.entity_controller.entity_controller.amazing_quote_configurable_publisher_node",
        "peekOfCode": "class AmazingQuoteConfigurablePublisherNode(Node):\n    \"\"\"A configurable ROS2 Node that publishes a configurable amazing quote.\"\"\"\n    def __init__(self):\n        super().__init__('amazing_quote_configurable_publisher_node')\n        # Periodically-obtained parameters(周期性参数)\n        self.declare_parameter('quote', 'Use the force, Pikachu!')\n        self.declare_parameter('philosopher_name', 'Uncle Ben')\n        # One-off parameters(一次性参数)\n        self.declare_parameter('topic_name', 'amazing_quote')\n        topic_name: str = self.get_parameter('topic_name').get_parameter_value().string_value",
        "detail": "src.entity_controller.entity_controller.amazing_quote_configurable_publisher_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.amazing_quote_configurable_publisher_node",
        "description": "src.entity_controller.entity_controller.amazing_quote_configurable_publisher_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        amazing_quote_configurable_publisher_node = AmazingQuoteConfigurablePublisherNode()\n        rclpy.spin(amazing_quote_configurable_publisher_node)",
        "detail": "src.entity_controller.entity_controller.amazing_quote_configurable_publisher_node",
        "documentation": {}
    },
    {
        "label": "AmazingQuotePublisherNode",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.amazing_quote_publisher_node",
        "description": "src.entity_controller.entity_controller.amazing_quote_publisher_node",
        "peekOfCode": "class AmazingQuotePublisherNode(Node):\n    \"\"\"A ROS2 Node that publishes an amazing quote.\"\"\"\n    def __init__(self):\n        super().__init__('amazing_quote_publisher_node')\n        self.amazing_quote_publisher = self.create_publisher(\n            msg_type=AmazingQuote,\n            topic='/amazing_quote',\n            qos_profile=1)\n        timer_period: float = 0.5\n        self.timer = self.create_timer(timer_period, self.timer_callback)",
        "detail": "src.entity_controller.entity_controller.amazing_quote_publisher_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.amazing_quote_publisher_node",
        "description": "src.entity_controller.entity_controller.amazing_quote_publisher_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        amazing_quote_publisher_node = AmazingQuotePublisherNode()\n        rclpy.spin(amazing_quote_publisher_node)",
        "detail": "src.entity_controller.entity_controller.amazing_quote_publisher_node",
        "documentation": {}
    },
    {
        "label": "AmazingQuoteSubscriberNode",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.amazing_quote_subscriber_node",
        "description": "src.entity_controller.entity_controller.amazing_quote_subscriber_node",
        "peekOfCode": "class AmazingQuoteSubscriberNode(Node):\n    \"\"\"A ROS2 Node that receives and AmazingQuote and prints out its info.\"\"\"\n    def __init__(self):\n        super().__init__('amazing_quote_subscriber_node')\n        self.amazing_quote_subscriber = self.create_subscription(\n            msg_type=AmazingQuote,\n            topic='/amazing_quote',\n            callback=self.amazing_quote_subscriber_callback,\n            qos_profile=1)\n    def amazing_quote_subscriber_callback(self, msg: AmazingQuote):",
        "detail": "src.entity_controller.entity_controller.amazing_quote_subscriber_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.amazing_quote_subscriber_node",
        "description": "src.entity_controller.entity_controller.amazing_quote_subscriber_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        amazing_quote_subscriber_node = AmazingQuoteSubscriberNode()\n        rclpy.spin(amazing_quote_subscriber_node)",
        "detail": "src.entity_controller.entity_controller.amazing_quote_subscriber_node",
        "documentation": {}
    },
    {
        "label": "WhatIsThePointServiceClientNode",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.what_is_the_point_service_client_node",
        "description": "src.entity_controller.entity_controller.what_is_the_point_service_client_node",
        "peekOfCode": "class WhatIsThePointServiceClientNode(Node):\n    \"\"\"A ROS2 Node with a Service Client for WhatIsThePoint.\"\"\"\n    def __init__(self):\n        super().__init__('what_is_the_point_service_client')\n        self.service_client = self.create_client(\n            srv_type=WhatIsThePoint,\n            srv_name='/what_is_the_point')\n        while not self.service_client.wait_for_service(timeout_sec=1.0):\n            self.get_logger().info(f'service {self.service_client.srv_name} not available, waiting...')\n        self.future: Future = None",
        "detail": "src.entity_controller.entity_controller.what_is_the_point_service_client_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.what_is_the_point_service_client_node",
        "description": "src.entity_controller.entity_controller.what_is_the_point_service_client_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        what_is_the_point_service_client_node = WhatIsThePointServiceClientNode()\n        rclpy.spin(what_is_the_point_service_client_node)",
        "detail": "src.entity_controller.entity_controller.what_is_the_point_service_client_node",
        "documentation": {}
    },
    {
        "label": "WhatIsThePointServiceServerNode",
        "kind": 6,
        "importPath": "src.entity_controller.entity_controller.what_is_the_point_service_server_node",
        "description": "src.entity_controller.entity_controller.what_is_the_point_service_server_node",
        "peekOfCode": "class WhatIsThePointServiceServerNode(Node):\n    \"\"\"A ROS2 Node with a Service Server for WhatIsThePoint.\"\"\"\n    def __init__(self):\n        super().__init__('what_is_the_point_service_server')\n        self.service_server = self.create_service(\n            srv_type=WhatIsThePoint,\n            srv_name='/what_is_the_point',\n            callback=self.what_is_the_point_service_callback)\n        self.service_server_call_count: int = 0\n    def what_is_the_point_service_callback(self,",
        "detail": "src.entity_controller.entity_controller.what_is_the_point_service_server_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.entity_controller.entity_controller.what_is_the_point_service_server_node",
        "description": "src.entity_controller.entity_controller.what_is_the_point_service_server_node",
        "peekOfCode": "def main(args=None):\n    \"\"\"\n    The main function.\n    :param args: Not used directly by the user, but used by ROS2 to configure\n    certain aspects of the Node.\n    \"\"\"\n    try:\n        rclpy.init(args=args)\n        what_is_the_point_service_server_node = WhatIsThePointServiceServerNode()\n        rclpy.spin(what_is_the_point_service_server_node)",
        "detail": "src.entity_controller.entity_controller.what_is_the_point_service_server_node",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "src.entity_controller.launch.peanut_butter_falcon_quote_publisher_launch",
        "description": "src.entity_controller.launch.peanut_butter_falcon_quote_publisher_launch",
        "peekOfCode": "def generate_launch_description():\n    return LaunchDescription([\n        Node(\n            output='screen',\n            emulate_tty=True,\n            package='entity_controller',\n            executable='amazing_quote_configurable_publisher_node',\n            name='peanut_butter_falcon_quote_publisher_node',\n            parameters=[{\n                \"topic_name\": \"truly_inspirational_quote\",",
        "detail": "src.entity_controller.launch.peanut_butter_falcon_quote_publisher_launch",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "src.entity_controller.launch.turtlesim.launch",
        "description": "src.entity_controller.launch.turtlesim.launch",
        "peekOfCode": "def generate_launch_description():\n    # 声明启动参数\n    declare_node_name_prefix_arg = DeclareLaunchArgument(\n        'node_name_prefix', default_value='turtlenode')\n    declare_nums_for_node_arg = DeclareLaunchArgument(\n        'nums_for_node', default_value='2')\n    declare_linear_speed_arg = DeclareLaunchArgument(\n        'linear_speed', default_value='0.5')\n    declare_angular_speed_arg = DeclareLaunchArgument(\n        'angular_speed', default_value='0.2')",
        "detail": "src.entity_controller.launch.turtlesim.launch",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.entity_controller.test.test_copyright",
        "description": "src.entity_controller.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.entity_controller.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.entity_controller.test.test_flake8",
        "description": "src.entity_controller.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.entity_controller.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.entity_controller.test.test_pep257",
        "description": "src.entity_controller.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.entity_controller.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.entity_controller.setup",
        "description": "src.entity_controller.setup",
        "peekOfCode": "package_name = 'entity_controller'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n        (os.path.join('share', package_name, 'launch'), glob(os.path.join('launch', '*launch.[pxy][yma]*'))),",
        "detail": "src.entity_controller.setup",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.environment_simulator.environment_simulator.Weather",
        "description": "src.environment_simulator.environment_simulator.Weather",
        "peekOfCode": "def main():\n    print('Hi from environment_simulator.')\nif __name__ == '__main__':\n    main()",
        "detail": "src.environment_simulator.environment_simulator.Weather",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.environment_simulator.test.test_copyright",
        "description": "src.environment_simulator.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.environment_simulator.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.environment_simulator.test.test_flake8",
        "description": "src.environment_simulator.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.environment_simulator.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.environment_simulator.test.test_pep257",
        "description": "src.environment_simulator.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.environment_simulator.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.environment_simulator.setup",
        "description": "src.environment_simulator.setup",
        "peekOfCode": "package_name = 'environment_simulator'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],",
        "detail": "src.environment_simulator.setup",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.sensor_simulator.sensor_simulator.Radar",
        "description": "src.sensor_simulator.sensor_simulator.Radar",
        "peekOfCode": "def main():\n    print('Hi from sensor_simulator.')\nif __name__ == '__main__':\n    main()",
        "detail": "src.sensor_simulator.sensor_simulator.Radar",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.sensor_simulator.test.test_copyright",
        "description": "src.sensor_simulator.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.sensor_simulator.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.sensor_simulator.test.test_flake8",
        "description": "src.sensor_simulator.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.sensor_simulator.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.sensor_simulator.test.test_pep257",
        "description": "src.sensor_simulator.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.sensor_simulator.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.sensor_simulator.setup",
        "description": "src.sensor_simulator.setup",
        "peekOfCode": "package_name = 'sensor_simulator'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],",
        "detail": "src.sensor_simulator.setup",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.tactical_decision.tactical_decision.FireDecision",
        "description": "src.tactical_decision.tactical_decision.FireDecision",
        "peekOfCode": "def main():\n    print('Hi from tactical_decision.')\nif __name__ == '__main__':\n    main()",
        "detail": "src.tactical_decision.tactical_decision.FireDecision",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.tactical_decision.test.test_copyright",
        "description": "src.tactical_decision.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.tactical_decision.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.tactical_decision.test.test_flake8",
        "description": "src.tactical_decision.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.tactical_decision.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.tactical_decision.test.test_pep257",
        "description": "src.tactical_decision.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.tactical_decision.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.tactical_decision.setup",
        "description": "src.tactical_decision.setup",
        "peekOfCode": "package_name = 'tactical_decision'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],",
        "detail": "src.tactical_decision.setup",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "src.tesla_frames.launch.dual_ekf_navsat.launch",
        "description": "src.tesla_frames.launch.dual_ekf_navsat.launch",
        "peekOfCode": "def generate_launch_description():\n    tesla_frames_dir = get_package_share_directory(\"tesla_frames\")\n    parameters_file_dir = os.path.join(tesla_frames_dir, \"config\")\n    parameters_file_path = os.path.join(parameters_file_dir, \"dual_ekf_navsat.yaml\")\n    os.environ[\"FILE_PATH\"] = str(parameters_file_dir)\n    return LaunchDescription(\n        [\n            # launch.actions.DeclareLaunchArgument(\"output_final_position\", default_value=\"false\"),\n            # launch.actions.DeclareLaunchArgument(\n            #     \"output_location\", default_value=\"~/dual_ekf_navsat_debug.txt\"",
        "detail": "src.tesla_frames.launch.dual_ekf_navsat.launch",
        "documentation": {}
    },
    {
        "label": "TeslaMarkersNode",
        "kind": 6,
        "importPath": "src.tesla_frames.tesla_frames.tesla_markers_node",
        "description": "src.tesla_frames.tesla_frames.tesla_markers_node",
        "peekOfCode": "class TeslaMarkersNode(Node):\n    def __init__(self):\n        super().__init__(\"tesla_markers_node\")\n        self.publisher_ = self.create_publisher(Marker, \"visualization_marker\", 10)\n        timer_period = 10  # in seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n    def timer_callback(self):\n        marker = Marker()\n        marker.header.frame_id = \"base_footprint\"\n        marker.header.stamp = self.get_clock().now().to_msg()",
        "detail": "src.tesla_frames.tesla_frames.tesla_markers_node",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.tesla_frames.tesla_frames.tesla_markers_node",
        "description": "src.tesla_frames.tesla_frames.tesla_markers_node",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    mesh_marker_publisher = TeslaMarkersNode()\n    rclpy.spin(mesh_marker_publisher)\n    mesh_marker_publisher.destroy_node()\n    rclpy.shutdown()\nif __name__ == \"__main__\":\n    main()",
        "detail": "src.tesla_frames.tesla_frames.tesla_markers_node",
        "documentation": {}
    },
    {
        "label": "TeslaTf2Publisher",
        "kind": 6,
        "importPath": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "description": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "peekOfCode": "class TeslaTf2Publisher(Node):\n    def __init__(self):\n        super().__init__(\"tesla_tf2_publisher\")\n        self.broadcaster = StaticTransformBroadcaster(self)\n        self.publish_transforms()\n    def publish_transforms(self):\n        # Base Link to Base Footprint\n        base_link_to_footprint = TransformStamped()\n        base_link_to_footprint.header.stamp = self.get_clock().now().to_msg()\n        base_link_to_footprint.header.frame_id = \"base_footprint\"",
        "detail": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "documentation": {}
    },
    {
        "label": "quaternion_from_euler",
        "kind": 2,
        "importPath": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "description": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "peekOfCode": "def quaternion_from_euler(roll, pitch, yaw):\n    \"\"\"\n    Converts euler roll, pitch, yaw to quaternion\n    \"\"\"\n    cy = math.cos(yaw * 0.5)\n    sy = math.sin(yaw * 0.5)\n    cp = math.cos(pitch * 0.5)\n    sp = math.sin(pitch * 0.5)\n    cr = math.cos(roll * 0.5)\n    sr = math.sin(roll * 0.5)",
        "detail": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "description": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    node = TeslaTf2Publisher()\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        rclpy.shutdown()\nif __name__ == \"__main__\":",
        "detail": "src.tesla_frames.tesla_frames.tesla_tf2_publisher",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.tesla_frames.test.test_copyright",
        "description": "src.tesla_frames.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.tesla_frames.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.tesla_frames.test.test_flake8",
        "description": "src.tesla_frames.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.tesla_frames.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.tesla_frames.test.test_pep257",
        "description": "src.tesla_frames.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.tesla_frames.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.tesla_frames.setup",
        "description": "src.tesla_frames.setup",
        "peekOfCode": "package_name = \"tesla_frames\"\nsetup(\n    name=package_name,\n    version=\"0.0.0\",\n    packages=[package_name],\n    data_files=[\n        (\"share/ament_index/resource_index/packages\", [\"resource/\" + package_name]),\n        (\"share/\" + package_name, [\"package.xml\"]),\n        (\"share/\" + package_name + \"/launch\", [\"launch/dual_ekf_navsat.launch.py\"]),\n        (\"share/\" + package_name + \"/config\", [\"config/dual_ekf_navsat.yaml\"]),",
        "detail": "src.tesla_frames.setup",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.trader.test.test_copyright",
        "description": "src.trader.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.trader.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.trader.test.test_flake8",
        "description": "src.trader.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.trader.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.trader.test.test_pep257",
        "description": "src.trader.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.trader.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "AkshareDataCollector",
        "kind": 6,
        "importPath": "src.trader.trader.collector.akshare_data_collector",
        "description": "src.trader.trader.collector.akshare_data_collector",
        "peekOfCode": "class AkshareDataCollector(DataCollector):\n    def __init__(self):\n        # 初始化时获取热门行业的股票代码列表，并使用lru_cache装饰器缓存结果\n        self._hot_industry_stocks = self.get_hot_industry_stocks()\n    market_spot: pd.DataFrame = None\n    def slope_to_degrees(self, slope):\n        return math.degrees(math.atan(slope))\n    def __fetch_data__(self, symbol: str, start_date: str = None, end_date: str = None, adjust: str = \"\"):\n        start_date = (datetime.now() - timedelta(days=250)\n                      ).strftime('%Y%m%d') if not start_date else start_date",
        "detail": "src.trader.trader.collector.akshare_data_collector",
        "documentation": {}
    },
    {
        "label": "DataCollector",
        "kind": 6,
        "importPath": "src.trader.trader.collector.base",
        "description": "src.trader.trader.collector.base",
        "peekOfCode": "class DataCollector(ABC):\n    @abstractmethod\n    def get_data(self, symbol, start_date, end_date):\n        \"\"\"\n        Fetch data from the source.\n        :param symbol: The symbol of the stock.\n        :param start_date: The start date for fetching data.\n        :param end_date: The end date for fetching data.\n        :return: Data fetched from the source.\n        \"\"\"",
        "detail": "src.trader.trader.collector.base",
        "documentation": {}
    },
    {
        "label": "Constants",
        "kind": 6,
        "importPath": "src.trader.trader.core.constants",
        "description": "src.trader.trader.core.constants",
        "peekOfCode": "class Constants:\n    BAR_DAY_COLUMNS = [\"date\",\"open\", \"close\", \"high\",\n                       \"low\", \"volume\", \"amount\", \"amp\", \"pct\", \"turnover\"]\n    BAR_MINUTE_COLUMNS = [\"date\", \"open\", \"close\", \"high\",\n                          \"low\", \"volume\", \"amount\", \"amplitude\", \"pct\", \"turnover\"]\n    TA_INDIECT_NAMES = [\"cmf\", \"roc\", \"sma\", \"ema\", \"obv\", \"slope\"]\n    TA_INDIECT_LENTHES = [3, 5, 10]\n    SPOT_EM_COLUMNS = [\n        \"code\",\n        \"name\",",
        "detail": "src.trader.trader.core.constants",
        "documentation": {}
    },
    {
        "label": "FavorSignalTopic",
        "kind": 6,
        "importPath": "src.trader.trader.core.topic",
        "description": "src.trader.trader.core.topic",
        "peekOfCode": "class FavorSignalTopic(Enum):\n    UPDATE_FAVOR = 'update.favor.signal'\n    def __str__(self):\n        # 只返回枚举成员的名称，不包括类名\n        return self.value \nclass TradeSignalTopic(Enum):\n    BATCH_BUY = 'batch.buy.signal'\n    BUY = 'buy.signal'\n    SELL = 'sell.signal'\n    SELL_ALL = 'sell.all.signal'",
        "detail": "src.trader.trader.core.topic",
        "documentation": {}
    },
    {
        "label": "TradeSignalTopic",
        "kind": 6,
        "importPath": "src.trader.trader.core.topic",
        "description": "src.trader.trader.core.topic",
        "peekOfCode": "class TradeSignalTopic(Enum):\n    BATCH_BUY = 'batch.buy.signal'\n    BUY = 'buy.signal'\n    SELL = 'sell.signal'\n    SELL_ALL = 'sell.all.signal'\n    SELL_HALF = 'sell.half.signal'\n    SELL_QUARTER = 'sell.quarter.signal'\n    CANCEL_ORDER = 'cancel.order.signal'\n    def __str__(self):\n        # 只返回枚举成员的名称，不包括类名",
        "detail": "src.trader.trader.core.topic",
        "documentation": {}
    },
    {
        "label": "StockPool",
        "kind": 6,
        "importPath": "src.trader.trader.pool.base",
        "description": "src.trader.trader.pool.base",
        "peekOfCode": "class StockPool(ABC):\n    @abstractmethod\n    def get_symbols(self) -> List[str]:\n        pass\n    def get_data(self, symbols: List[str])->pd.DataFrame:\n        \"\"\"\n        从ADC数据源获取最新的数据。\n        Args:\n            symbols：股票代码列表\n        Returns:",
        "detail": "src.trader.trader.pool.base",
        "documentation": {}
    },
    {
        "label": "AmountStockPool",
        "kind": 6,
        "importPath": "src.trader.trader.pool.pool",
        "description": "src.trader.trader.pool.pool",
        "peekOfCode": "class AmountStockPool(StockPool):\n  def __init__(self):\n    self.adc = AkshareDataCollector()\n  def get_symbols(self,cloumn_name:str=\"amount\",k:int=100) -> List[str]:\n    \"\"\"\n    获取股票符号列表，默认为按成交额排序的前100只股票\n    Args:\n        cloumn_name (str, optional): 用于排序的列名，默认为'amount'。\n        k (int, optional): 返回的股票数量，默认为100。\n    Returns:",
        "detail": "src.trader.trader.pool.pool",
        "documentation": {}
    },
    {
        "label": "TurtleNode",
        "kind": 6,
        "importPath": "src.trader.trader.CCIndex",
        "description": "src.trader.trader.CCIndex",
        "peekOfCode": "class TurtleNode(Node):\n    def __init__(self):\n        super().__init__('TurtleNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # msg = Person()\n        # msg.name = \"ROS User\"\n        # msg.age = 4  \n        # print(\">>>>>>>>>>>>>\",msg)      \n        # 声明参数\n        self.declare_parameter('node_name', 'trader')\n        self.declare_parameter('linear_speed', 0.5)",
        "detail": "src.trader.trader.CCIndex",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.trader.trader.CCIndex",
        "description": "src.trader.trader.CCIndex",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    turtlenode = TurtleNode()\n    rclpy.spin(turtlenode)\n    turtlenode.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "src.trader.trader.CCIndex",
        "documentation": {}
    },
    {
        "label": "CCIndexNode",
        "kind": 6,
        "importPath": "src.trader.trader.CCIndex_marker",
        "description": "src.trader.trader.CCIndex_marker",
        "peekOfCode": "class CCIndexNode(Node):\n    def __init__(self):\n        super().__init__('CCIndexNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # 声明参数\n        self.declare_parameter('node_name', 'CCIndexNode')\n        self.declare_parameter('linear_speed', 0.5)\n        self.declare_parameter('angular_speed', 0.2)\n        # 获取参数\n        self.node_name = self.get_parameter('node_name').get_parameter_value().string_value\n        self.linear_speed = self.get_parameter('linear_speed').get_parameter_value().double_value",
        "detail": "src.trader.trader.CCIndex_marker",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.trader.trader.CCIndex_marker",
        "description": "src.trader.trader.CCIndex_marker",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    node = CCIndexNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':\n    main()",
        "detail": "src.trader.trader.CCIndex_marker",
        "documentation": {}
    },
    {
        "label": "data_points",
        "kind": 5,
        "importPath": "src.trader.trader.CCIndex_marker",
        "description": "src.trader.trader.CCIndex_marker",
        "peekOfCode": "data_points = []\nclass CCIndexNode(Node):\n    def __init__(self):\n        super().__init__('CCIndexNode')  # 使用固定的节点名称以避免与launch文件中的参数冲突\n        # 声明参数\n        self.declare_parameter('node_name', 'CCIndexNode')\n        self.declare_parameter('linear_speed', 0.5)\n        self.declare_parameter('angular_speed', 0.2)\n        # 获取参数\n        self.node_name = self.get_parameter('node_name').get_parameter_value().string_value",
        "detail": "src.trader.trader.CCIndex_marker",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.trader.setup",
        "description": "src.trader.setup",
        "peekOfCode": "package_name = 'trader'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],",
        "detail": "src.trader.setup",
        "documentation": {}
    },
    {
        "label": "generate_launch_description",
        "kind": 2,
        "importPath": "src.webots_demo.launch.robot_launch",
        "description": "src.webots_demo.launch.robot_launch",
        "peekOfCode": "def generate_launch_description():\n    package_dir = get_package_share_directory('webots_demo')\n    robot_description_path = os.path.join(package_dir, 'resource', 'my_robot.urdf')\n    webots = WebotsLauncher(\n        world=os.path.join(package_dir, 'worlds', 'my_world.wbt'),\n        ros2_supervisor=True\n    )\n    my_robot_driver = WebotsController(\n        robot_name='my_robot',\n        parameters=[",
        "detail": "src.webots_demo.launch.robot_launch",
        "documentation": {}
    },
    {
        "label": "test_copyright",
        "kind": 2,
        "importPath": "src.webots_demo.test.test_copyright",
        "description": "src.webots_demo.test.test_copyright",
        "peekOfCode": "def test_copyright():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found errors'",
        "detail": "src.webots_demo.test.test_copyright",
        "documentation": {}
    },
    {
        "label": "test_flake8",
        "kind": 2,
        "importPath": "src.webots_demo.test.test_flake8",
        "description": "src.webots_demo.test.test_flake8",
        "peekOfCode": "def test_flake8():\n    rc, errors = main_with_errors(argv=[])\n    assert rc == 0, \\\n        'Found %d code style errors / warnings:\\n' % len(errors) + \\\n        '\\n'.join(errors)",
        "detail": "src.webots_demo.test.test_flake8",
        "documentation": {}
    },
    {
        "label": "test_pep257",
        "kind": 2,
        "importPath": "src.webots_demo.test.test_pep257",
        "description": "src.webots_demo.test.test_pep257",
        "peekOfCode": "def test_pep257():\n    rc = main(argv=['.', 'test'])\n    assert rc == 0, 'Found code style errors / warnings'",
        "detail": "src.webots_demo.test.test_pep257",
        "documentation": {}
    },
    {
        "label": "MyRobotDriver",
        "kind": 6,
        "importPath": "src.webots_demo.webots_demo.my_robot_driver",
        "description": "src.webots_demo.webots_demo.my_robot_driver",
        "peekOfCode": "class MyRobotDriver:\n    def init(self, webots_node, properties):\n        self.__robot = webots_node.robot\n        self.__left_motor = self.__robot.getDevice('left wheel motor')\n        self.__right_motor = self.__robot.getDevice('right wheel motor')\n        self.__left_motor.setPosition(float('inf'))\n        self.__left_motor.setVelocity(0)\n        self.__right_motor.setPosition(float('inf'))\n        self.__right_motor.setVelocity(0)\n        self.__target_twist = Twist()",
        "detail": "src.webots_demo.webots_demo.my_robot_driver",
        "documentation": {}
    },
    {
        "label": "HALF_DISTANCE_BETWEEN_WHEELS",
        "kind": 5,
        "importPath": "src.webots_demo.webots_demo.my_robot_driver",
        "description": "src.webots_demo.webots_demo.my_robot_driver",
        "peekOfCode": "HALF_DISTANCE_BETWEEN_WHEELS = 0.045\nWHEEL_RADIUS = 0.025\nclass MyRobotDriver:\n    def init(self, webots_node, properties):\n        self.__robot = webots_node.robot\n        self.__left_motor = self.__robot.getDevice('left wheel motor')\n        self.__right_motor = self.__robot.getDevice('right wheel motor')\n        self.__left_motor.setPosition(float('inf'))\n        self.__left_motor.setVelocity(0)\n        self.__right_motor.setPosition(float('inf'))",
        "detail": "src.webots_demo.webots_demo.my_robot_driver",
        "documentation": {}
    },
    {
        "label": "WHEEL_RADIUS",
        "kind": 5,
        "importPath": "src.webots_demo.webots_demo.my_robot_driver",
        "description": "src.webots_demo.webots_demo.my_robot_driver",
        "peekOfCode": "WHEEL_RADIUS = 0.025\nclass MyRobotDriver:\n    def init(self, webots_node, properties):\n        self.__robot = webots_node.robot\n        self.__left_motor = self.__robot.getDevice('left wheel motor')\n        self.__right_motor = self.__robot.getDevice('right wheel motor')\n        self.__left_motor.setPosition(float('inf'))\n        self.__left_motor.setVelocity(0)\n        self.__right_motor.setPosition(float('inf'))\n        self.__right_motor.setVelocity(0)",
        "detail": "src.webots_demo.webots_demo.my_robot_driver",
        "documentation": {}
    },
    {
        "label": "ObstacleAvoider",
        "kind": 6,
        "importPath": "src.webots_demo.webots_demo.obstacle_avoider",
        "description": "src.webots_demo.webots_demo.obstacle_avoider",
        "peekOfCode": "class ObstacleAvoider(Node):\n    def __init__(self):\n        super().__init__('obstacle_avoider')\n        self.__publisher = self.create_publisher(Twist, 'cmd_vel', 1)\n        self.create_subscription(Range, 'left_sensor', self.__left_sensor_callback, 1)\n        self.create_subscription(Range, 'right_sensor', self.__right_sensor_callback, 1)\n    def __left_sensor_callback(self, message):\n        self.__left_sensor_value = message.range\n    def __right_sensor_callback(self, message):\n        self.__right_sensor_value = message.range",
        "detail": "src.webots_demo.webots_demo.obstacle_avoider",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.webots_demo.webots_demo.obstacle_avoider",
        "description": "src.webots_demo.webots_demo.obstacle_avoider",
        "peekOfCode": "def main(args=None):\n    rclpy.init(args=args)\n    avoider = ObstacleAvoider()\n    rclpy.spin(avoider)\n    # Destroy the node explicitly\n    # (optional - otherwise it will be done automatically\n    # when the garbage collector destroys the node object)\n    avoider.destroy_node()\n    rclpy.shutdown()\nif __name__ == '__main__':",
        "detail": "src.webots_demo.webots_demo.obstacle_avoider",
        "documentation": {}
    },
    {
        "label": "MAX_RANGE",
        "kind": 5,
        "importPath": "src.webots_demo.webots_demo.obstacle_avoider",
        "description": "src.webots_demo.webots_demo.obstacle_avoider",
        "peekOfCode": "MAX_RANGE = 0.15\nclass ObstacleAvoider(Node):\n    def __init__(self):\n        super().__init__('obstacle_avoider')\n        self.__publisher = self.create_publisher(Twist, 'cmd_vel', 1)\n        self.create_subscription(Range, 'left_sensor', self.__left_sensor_callback, 1)\n        self.create_subscription(Range, 'right_sensor', self.__right_sensor_callback, 1)\n    def __left_sensor_callback(self, message):\n        self.__left_sensor_value = message.range\n    def __right_sensor_callback(self, message):",
        "detail": "src.webots_demo.webots_demo.obstacle_avoider",
        "documentation": {}
    },
    {
        "label": "package_name",
        "kind": 5,
        "importPath": "src.webots_demo.setup",
        "description": "src.webots_demo.setup",
        "peekOfCode": "package_name = 'webots_demo'\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=find_packages(exclude=['test']),\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name + '/resource', ['resource/my_robot.urdf']),\n        ('share/' + package_name + '/launch', ['launch/robot_launch.py']),",
        "detail": "src.webots_demo.setup",
        "documentation": {}
    },
    {
        "label": "{{NODE_NAME}}Publisher",
        "kind": 6,
        "importPath": "node_template_publisher",
        "description": "node_template_publisher",
        "peekOfCode": "class {{NODE_NAME}}Publisher(Node):\n    def __init__(self):\n        super().__init__('{{PKG_NAME}}_{{NODE_NAME}}')\n        # 10: 这是发布者的质量服务（Quality of Service，QoS）设置。QoS设置定义了消息传递的可靠性和历史保持策略。在这里，10是QoS配置的整数表示，对应于rmw_qos_profile_sensor_data，这是一个适用于传感器数据的QoS配置，它提供了一定的可靠性保证和历史保持策略。\n        self.publisher_ = self.create_publisher(String, '{{PKG_NAME}}/{{NODE_NAME}}', 10)\n        timer_period = 0.5  # seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n    def timer_callback(self):\n        msg = String()\n        msg.data = 'Hello ROS2!'",
        "detail": "node_template_publisher",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "node_template_publisher",
        "description": "node_template_publisher",
        "peekOfCode": "def main(args=None):\n    try:\n        rclpy.init(args=args)\n        publisher = {{NODE_NAME}}Publisher()\n        rclpy.spin(publisher)\n        publisher.destroy_node()\n        rclpy.shutdown()\n    except KeyboardInterrupt:\n        pass        \n    except Exception as e:",
        "detail": "node_template_publisher",
        "documentation": {}
    },
    {
        "label": "{{NODE_NAME}}Subscriber",
        "kind": 6,
        "importPath": "node_template_subscriber",
        "description": "node_template_subscriber",
        "peekOfCode": "class {{NODE_NAME}}Subscriber(Node):\n    def __init__(self):\n        super().__init__('{{PKG_NAME}}_{{NODE_NAME}}')\n        self.subscription = self.create_subscription(\n            String,\n            '{{PKG_NAME}}/{{NODE_NAME}}', \n            self.listener_callback,\n            10)\n        self.subscription  # prevent unused variable warning\n    def listener_callback(self, msg):",
        "detail": "node_template_subscriber",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "node_template_subscriber",
        "description": "node_template_subscriber",
        "peekOfCode": "def main(args=None):\n    try:\n        rclpy.init(args=args)\n        subscriber = {{NODE_NAME}}Subscriber()\n        rclpy.spin(subscriber)\n        subscriber.destroy_node()\n        rclpy.shutdown()\n    except KeyboardInterrupt:\n        pass        \n    except Exception as e:",
        "detail": "node_template_subscriber",
        "documentation": {}
    }
]